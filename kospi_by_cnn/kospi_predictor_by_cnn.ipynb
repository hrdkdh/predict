{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"saved_model_cnn1\"\n",
    "cols = [\"KOSPI\", \"KOSPI_START\", \"KOSPI_HIGH\", \"KOSPI_LOW\", \"NASDAQ\", \"DOW\", \"CR\", \"GOLD\"]\n",
    "# cols = [\"KOSPI\", \"KOSPI_START\", \"KOSPI_HIGH\", \"KOSPI_LOW\"]\n",
    "len_x_ARMA = 60\n",
    "len_y_nextday = 1\n",
    "scale_method = \"minmax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kospi_predict import Crawler\n",
    "\n",
    "crawler = Crawler(crawl_page_max=30, perPage=100)\n",
    "# crawler.crawlData(cols, save=True)\n",
    "crawler.loadFromSavedFile(cols)\n",
    "df_crawled = crawler.removeNan()\n",
    "# df_crawled = df_crawled.loc[:2000]\n",
    "df_crawled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kospi_predict import DataPreprocessor\n",
    "from sklearn.preprocessing import MinMaxScaler as MinMaxScaler\n",
    "\n",
    "dpp = DataPreprocessor(df_crawled, cols, scale_method, model_save_path)\n",
    "dpp.sortByDate()\n",
    "# dpp.makeDiffByRange(1, len_x_ARMA)\n",
    "# dpp.makeDiffRatio()\n",
    "# dpp.makeAR(0, len_x_ARMA)\n",
    "# dpp.makeMA(2, len_x_ARMA)\n",
    "dpp.makeTargetYs(len_y_nextday)\n",
    "dpp.cutoffData(len_x_ARMA, len_y_nextday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = dpp.df[500:1500]\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "dpp.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def rescalingByMinMax(arr):\n",
    "    for col_idx in range(arr.shape[1]):\n",
    "        this_arr = arr[:, col_idx]\n",
    "        max_val = max(this_arr)\n",
    "        min_val = min(this_arr)\n",
    "        for row_idx, val in enumerate(this_arr):\n",
    "            new_val = (val - min_val) / (max_val - min_val)\n",
    "            arr[row_idx, col_idx] = new_val\n",
    "    return arr\n",
    "\n",
    "def makeImage3D(df, row_cnt = 8):\n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    date_list = []\n",
    "    y_list = []\n",
    "    for idx in range(len(df)):\n",
    "        if idx > 200:\n",
    "            this_mat = np.empty(shape=(row_cnt, len(cols), 3))\n",
    "            for i in range(1, 4):\n",
    "                this_ch = rescalingByMinMax(np.array(df.iloc[idx-(row_cnt*i):idx-(row_cnt*(i-1)), 1:len(cols)+1], dtype=np.float32))\n",
    "                this_mat[:, :, i-1] = this_ch\n",
    "            img_list.append(this_mat)\n",
    "\n",
    "            #라벨 체크\n",
    "            this_label = np.nan\n",
    "            if idx+1 < len(df): #0 1 2 ... 29 / 30\n",
    "                this_label = 0\n",
    "                if df.iloc[idx+1, 1] > df.iloc[idx, 1]: #item[0]+1 : 다음날\n",
    "                    this_label = 1\n",
    "            label_list.append(this_label)\n",
    "\n",
    "            #라벨값과 함께 이미지로 저장\n",
    "            cv2.imwrite(\"../data_cnn/{}_{}.png\".format(str(this_label), df.iloc[idx, 0]), this_mat * 255)\n",
    "\n",
    "            #날짜 리스트 입력\n",
    "            date_list.append(df.iloc[idx, 0])\n",
    "\n",
    "            #y_list 입력\n",
    "            y_list.append(df.iloc[idx, -1])\n",
    "\n",
    "    img_list = np.array(img_list[:-1])\n",
    "    label_list = np.array(label_list[:-1], dtype=np.uint8)\n",
    "    date_list = np.array(date_list[:-1])\n",
    "    y_list = np.array(y_list[:-1])\n",
    "    df_result = pd.DataFrame({\"date\" : date_list, \"label\" : label_list})\n",
    "\n",
    "    return img_list, label_list, date_list, y_list, df_result\n",
    "\n",
    "img_list, label_list, date_list, y_list, df_ref = makeImage3D(dpp.df, row_cnt=len(cols))\n",
    "img_list.shape, label_list.shape, date_list.shape, y_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeImage2D(df):\n",
    "    #행 : X_*_DIFF_AR, X_*_DIFF_MA  *  원천 X 갯수(8개라면 8*2 = 16행)\n",
    "    #열 : ARMA 갯수. 20이라면 20 = 20열\n",
    "    col_made_list = [\n",
    "        \"X_*_AR\", #8행\n",
    "        \"X_*_DIFF_AR\", #8행\n",
    "        \"X_*_MA\", #8행\n",
    "        \"X_*_DIFF_MA\" #8행\n",
    "    ]\n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    date_list = []\n",
    "    y_list = []\n",
    "    for item in df.iterrows():\n",
    "        this_mat_list = []\n",
    "        for col in cols: #8개 [\"KOSPI\", \"KOSPI_START\", \"KOSPI_HIGH\", \"KOSPI_LOW\", \"NASDAQ\", \"DOW\", \"CR\", \"GOLD\"]\n",
    "            for col_made in col_made_list: #4개 [\"X_*_AR\", \"X_*_DIFF_AR\", \"X_*_MA\", \"X_*_DIFF_MA\"]\n",
    "                this_col = col_made.replace(\"*\", col) #X_KOSPI_AR\n",
    "                this_row_list = []\n",
    "                for i in range(0, len_x_ARMA): #20개. 0~20\n",
    "                    if \"MA\" in this_col:\n",
    "                        i += 2\n",
    "                    this_col_made = \"{}{}\".format(this_col, i) #X_KOSPI_AR0\n",
    "                    this_row_list.append([df.loc[item[0], this_col_made]])\n",
    "                this_mat_list.append(this_row_list)\n",
    "        this_mat = np.array(this_mat_list)\n",
    "        this_mat = this_mat\n",
    "        img_list.append(this_mat)\n",
    "\n",
    "        #라벨 체크\n",
    "        this_label = np.nan\n",
    "        if item[0]+1 < len(df): #0 1 2 ... 29 / 30\n",
    "            this_label = 0\n",
    "            if df.loc[item[0]+1, \"KOSPI\"] > df.loc[item[0], \"KOSPI\"]: #item[0]+1 : 다음날\n",
    "                this_label = 1\n",
    "        label_list.append(this_label)\n",
    "\n",
    "        #라벨값과 함께 이미지로 저장\n",
    "        cv2.imwrite(\"data_cnn/{}_{}.png\".format(str(this_label), df.loc[item[0], \"date\"]), this_mat * 255)\n",
    "\n",
    "        #날짜 리스트 입력\n",
    "        date_list.append(df.loc[item[0], \"date\"])\n",
    "\n",
    "        #y_list 입력\n",
    "        this_y_list = []\n",
    "        for y in [x for x in df.columns.to_list() if \"Y_\" in x]:\n",
    "            this_y_list.append(df.loc[item[0], y])\n",
    "        y_list.append(this_y_list)\n",
    "\n",
    "    img_list = np.array(img_list)\n",
    "    label_list = np.array(label_list)\n",
    "    date_list = np.array(date_list)\n",
    "    y_list = np.array(y_list)\n",
    "    df_result = pd.DataFrame({\"date\" : date_list, \"label\" : label_list})\n",
    "\n",
    "    return img_list, label_list, date_list, y_list, df_result\n",
    "\n",
    "# img_list, label_list, date_list, y_list, _ = makeImage2D(dpp.df)\n",
    "# img_list.shape, label_list.shape, date_list.shape, y_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(img_list[:-1], label_list[:-1], test_size=0.2, shuffle=False, random_state=8699)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def resblock(x, filters, kernel_size):\n",
    "    fx = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, padding=\"same\", activation=\"relu\")(x)\n",
    "    fx = tf.keras.layers.BatchNormalization()(fx)\n",
    "    fx = tf.keras.layers.Conv2D(filters=x.shape[3], kernel_size=kernel_size, padding=\"same\")(fx)\n",
    "    out = tf.keras.layers.Add()([x, fx])\n",
    "    out = tf.keras.layers.ReLU()(out)\n",
    "    out = tf.keras.layers.BatchNormalization()(out)\n",
    "    return out\n",
    "\n",
    "input = tf.keras.layers.Input(shape=(img_list[0].shape[0], img_list[0].shape[1], img_list[0].shape[2]))\n",
    "output = resblock(x=input, filters = 32, kernel_size = (3,3))\n",
    "output = resblock(x=output, filters = 64, kernel_size = (3,3))\n",
    "output = resblock(x=output, filters = 128, kernel_size = (3,3))\n",
    "output = resblock(x=output, filters = 512, kernel_size = (3,3))\n",
    "output = tf.keras.layers.Flatten()(output)\n",
    "output = tf.keras.layers.Dense(units=512, activation=\"relu\")(output)\n",
    "output = tf.keras.layers.Dense(units=256, activation=\"relu\")(output)\n",
    "output = tf.keras.layers.Dense(units=2, activation=\"softmax\")(output)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input, outputs=output)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=200\n",
    "history = model.fit(\n",
    "  x_train,\n",
    "  y_train,\n",
    "  epochs=epochs,\n",
    "  batch_size = 32,\n",
    "  validation_split = 0.2,\n",
    "  verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(img_list[0].shape[0], img_list[0].shape[1], img_list[0].shape[2])),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=32, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=64, padding=\"same\", activation=\"relu\"),\n",
    "    # tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=128, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=256, padding= \"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(units=256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(units=2, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=200\n",
    "history = model.fit(\n",
    "  x_train,\n",
    "  y_train,\n",
    "  epochs=epochs,\n",
    "  batch_size = 32,\n",
    "  validation_split = 0.2,\n",
    "  verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history = pd.DataFrame(history.history)\n",
    "df_history.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test)\n",
    "test_results = []\n",
    "for idx, pred in enumerate(preds):\n",
    "    this_label = y_test[idx]\n",
    "    this_predict = np.argmax(pred)\n",
    "    acc = 0\n",
    "    if this_label == this_predict:\n",
    "        acc = 1\n",
    "    test_results.append({\"label\" : this_label, \"predict\" : this_predict, \"acc\" : acc})\n",
    "\n",
    "test_results = pd.DataFrame(test_results)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ratio = test_results[\"acc\"].sum() / len(test_results)\n",
    "print(\"테스트 정확도 : {}/{} ({:.2f})\".format(test_results[\"acc\"].sum(), len(test_results), acc_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최근 날짜로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler_pred = Crawler(crawl_page_max=1, perPage=100) #이전 추세도 볼겸 넉넉히 수집\n",
    "crawler_pred.crawlData(cols)\n",
    "df_crawled_pred = crawler_pred.removeNan()\n",
    "df_crawled_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#아래는 예측을 위한 전처리\n",
    "dpp_pred = DataPreprocessor(df_crawled_pred.loc[:100], cols, scale_method, model_save_path)\n",
    "dpp_pred.sortByDate()\n",
    "dpp_pred.makeDiffRatio()\n",
    "dpp_pred.scalingForPredict()\n",
    "dpp_pred.makeAR(0, len_x_ARMA)\n",
    "dpp_pred.makeMA(2, len_x_ARMA)\n",
    "dpp_pred.cutoffData(len_x_ARMA, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpp_pred.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred_list, label_pred_list, date_list, _ = makeImage2D(dpp_pred.df, cut_latest_data=False)\n",
    "len(img_pred_list), len(label_pred_list), len(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_day = 1\n",
    "img_pred = np.array([img_pred_list[-before_day]])\n",
    "pred = model.predict(img_pred)\n",
    "test_results = []\n",
    "predict = np.argmax(pred)\n",
    "print(\"{} predict : {}, real : {}\".format(date_list[-before_day], predict, label_pred_list[-before_day]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(img_list, y_list, test_size=0.2, shuffle=False, random_state=8699)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Input(shape=(24, 20, 1)),\n",
    "  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dense(20, activation=\"relu\")\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "epochs=5000\n",
    "history = model.fit(\n",
    "  x_train,\n",
    "  y_train,\n",
    "  epochs=epochs,\n",
    "  validation_split = 0.1,\n",
    "  verbose = 1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aaf533d5ae3a3d7a7fcdd7d995dbe2f3fcb3d854cc4805079aca601e58923c31"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv_tf_3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
