{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"saved_model_cnn1\"\n",
    "cols = [\"KOSPI\", \"KOSPI_START\", \"KOSPI_HIGH\", \"KOSPI_LOW\", \"NASDAQ\", \"DOW\", \"CR\", \"GOLD\"]\n",
    "# cols = [\"KOSPI\", \"KOSPI_START\", \"KOSPI_HIGH\", \"KOSPI_LOW\"]\n",
    "len_x_ARMA = 60\n",
    "len_y_nextday = 1\n",
    "scale_method = \"minmax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kospi_predict import Crawler\n",
    "\n",
    "crawler = Crawler(crawl_page_max=30, perPage=100)\n",
    "# crawler.crawlData(cols, save=True)\n",
    "crawler.loadFromSavedFile(cols)\n",
    "df_crawled = crawler.removeNan()\n",
    "df_crawled = df_crawled.loc[:2000]\n",
    "df_crawled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kospi_predict import DataPreprocessor\n",
    "from sklearn.preprocessing import MinMaxScaler as MinMaxScaler\n",
    "\n",
    "dpp = DataPreprocessor(df_crawled, cols, scale_method, model_save_path)\n",
    "dpp.sortByDate()\n",
    "# dpp.makeDiffByRange(1, len_x_ARMA)\n",
    "# dpp.makeDiffRatio()\n",
    "# dpp.makeAR(0, len_x_ARMA)\n",
    "# dpp.makeMA(2, len_x_ARMA)\n",
    "dpp.makeTargetYs(len_y_nextday)\n",
    "dpp.cutoffData(len_x_ARMA, len_y_nextday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = dpp.df[500:1500]\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "dpp.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1877, 8, 8, 3), (1877,), (1877,), (1877,))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def rescalingByMinMax(arr):\n",
    "    for col_idx in range(arr.shape[1]):\n",
    "        this_arr = arr[:, col_idx]\n",
    "        max_val = max(this_arr)\n",
    "        min_val = min(this_arr)\n",
    "        for row_idx, val in enumerate(this_arr):\n",
    "            new_val = (val - min_val) / (max_val - min_val)\n",
    "            arr[row_idx, col_idx] = new_val\n",
    "    return arr\n",
    "\n",
    "def makeImage3D(df, row_cnt = 8):\n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    date_list = []\n",
    "    y_list = []\n",
    "    for idx in range(len(df)):\n",
    "        if idx > 60:\n",
    "            this_mat = np.empty(shape=(row_cnt, len(cols), 3))\n",
    "            for i in range(1, 4):\n",
    "                this_ch = rescalingByMinMax(np.array(df.iloc[idx-(row_cnt*i):idx-(row_cnt*(i-1)), 1:len(cols)+1], dtype=np.float32))\n",
    "                this_mat[:, :, i-1] = this_ch\n",
    "            img_list.append(this_mat)\n",
    "\n",
    "            #라벨 체크\n",
    "            this_label = np.nan\n",
    "            if idx+1 < len(df): #0 1 2 ... 29 / 30\n",
    "                this_label = 0\n",
    "                if df.iloc[idx+1, 1] > df.iloc[idx, 1]: #item[0]+1 : 다음날\n",
    "                    this_label = 1\n",
    "            label_list.append(this_label)\n",
    "\n",
    "            #라벨값과 함께 이미지로 저장\n",
    "            cv2.imwrite(\"../data_cnn/{}_{}.png\".format(str(this_label), df.iloc[idx, 0]), this_mat * 255)\n",
    "\n",
    "            #날짜 리스트 입력\n",
    "            date_list.append(df.iloc[idx, 0])\n",
    "\n",
    "            #y_list 입력\n",
    "            y_list.append(df.iloc[idx, -1])\n",
    "\n",
    "    img_list = np.array(img_list[:-1])\n",
    "    label_list = np.array(label_list[:-1], dtype=np.uint8)\n",
    "    date_list = np.array(date_list[:-1])\n",
    "    y_list = np.array(y_list[:-1])\n",
    "    df_result = pd.DataFrame({\"date\" : date_list, \"label\" : label_list})\n",
    "\n",
    "    return img_list, label_list, date_list, y_list, df_result\n",
    "\n",
    "img_list, label_list, date_list, y_list, df_ref = makeImage3D(dpp.df, row_cnt=len(cols))\n",
    "img_list.shape, label_list.shape, date_list.shape, y_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeImage2D(df):\n",
    "    #행 : X_*_DIFF_AR, X_*_DIFF_MA  *  원천 X 갯수(8개라면 8*2 = 16행)\n",
    "    #열 : ARMA 갯수. 20이라면 20 = 20열\n",
    "    col_made_list = [\n",
    "        \"X_*_AR\", #8행\n",
    "        \"X_*_DIFF_AR\", #8행\n",
    "        \"X_*_MA\", #8행\n",
    "        \"X_*_DIFF_MA\" #8행\n",
    "    ]\n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    date_list = []\n",
    "    y_list = []\n",
    "    for item in df.iterrows():\n",
    "        this_mat_list = []\n",
    "        for col in cols: #8개 [\"KOSPI\", \"KOSPI_START\", \"KOSPI_HIGH\", \"KOSPI_LOW\", \"NASDAQ\", \"DOW\", \"CR\", \"GOLD\"]\n",
    "            for col_made in col_made_list: #4개 [\"X_*_AR\", \"X_*_DIFF_AR\", \"X_*_MA\", \"X_*_DIFF_MA\"]\n",
    "                this_col = col_made.replace(\"*\", col) #X_KOSPI_AR\n",
    "                this_row_list = []\n",
    "                for i in range(0, len_x_ARMA): #20개. 0~20\n",
    "                    if \"MA\" in this_col:\n",
    "                        i += 2\n",
    "                    this_col_made = \"{}{}\".format(this_col, i) #X_KOSPI_AR0\n",
    "                    this_row_list.append([df.loc[item[0], this_col_made]])\n",
    "                this_mat_list.append(this_row_list)\n",
    "        this_mat = np.array(this_mat_list)\n",
    "        this_mat = this_mat\n",
    "        img_list.append(this_mat)\n",
    "\n",
    "        #라벨 체크\n",
    "        this_label = np.nan\n",
    "        if item[0]+1 < len(df): #0 1 2 ... 29 / 30\n",
    "            this_label = 0\n",
    "            if df.loc[item[0]+1, \"KOSPI\"] > df.loc[item[0], \"KOSPI\"]: #item[0]+1 : 다음날\n",
    "                this_label = 1\n",
    "        label_list.append(this_label)\n",
    "\n",
    "        #라벨값과 함께 이미지로 저장\n",
    "        cv2.imwrite(\"data_cnn/{}_{}.png\".format(str(this_label), df.loc[item[0], \"date\"]), this_mat * 255)\n",
    "\n",
    "        #날짜 리스트 입력\n",
    "        date_list.append(df.loc[item[0], \"date\"])\n",
    "\n",
    "        #y_list 입력\n",
    "        this_y_list = []\n",
    "        for y in [x for x in df.columns.to_list() if \"Y_\" in x]:\n",
    "            this_y_list.append(df.loc[item[0], y])\n",
    "        y_list.append(this_y_list)\n",
    "\n",
    "    img_list = np.array(img_list)\n",
    "    label_list = np.array(label_list)\n",
    "    date_list = np.array(date_list)\n",
    "    y_list = np.array(y_list)\n",
    "    df_result = pd.DataFrame({\"date\" : date_list, \"label\" : label_list})\n",
    "\n",
    "    return img_list, label_list, date_list, y_list, df_result\n",
    "\n",
    "# img_list, label_list, date_list, y_list, _ = makeImage2D(dpp.df)\n",
    "# img_list.shape, label_list.shape, date_list.shape, y_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 8, 8, 3), (376, 8, 8, 3), (1500,), (376,))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(img_list[:-1], label_list[:-1], test_size=0.2, shuffle=False, random_state=8699)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_40 (Conv2D)          (None, 8, 8, 32)          896       \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 8, 8, 64)          18496     \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,617,922\n",
      "Trainable params: 2,617,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-09 19:24:52.990767: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 24ms/step - loss: 0.7029 - accuracy: 0.5133 - val_loss: 0.6903 - val_accuracy: 0.5833\n",
      "Epoch 2/200\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.6937 - accuracy: 0.5312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-09 19:24:53.938830: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6930 - accuracy: 0.5225 - val_loss: 0.6882 - val_accuracy: 0.5833\n",
      "Epoch 3/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5200 - val_loss: 0.6864 - val_accuracy: 0.5833\n",
      "Epoch 4/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6929 - accuracy: 0.5200 - val_loss: 0.6887 - val_accuracy: 0.5833\n",
      "Epoch 5/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6923 - accuracy: 0.5200 - val_loss: 0.6862 - val_accuracy: 0.5833\n",
      "Epoch 6/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6924 - accuracy: 0.5242 - val_loss: 0.6864 - val_accuracy: 0.5833\n",
      "Epoch 7/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6926 - accuracy: 0.5208 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 8/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6932 - accuracy: 0.5225 - val_loss: 0.6872 - val_accuracy: 0.5833\n",
      "Epoch 9/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6931 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 10/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6931 - accuracy: 0.5217 - val_loss: 0.6878 - val_accuracy: 0.5833\n",
      "Epoch 11/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6927 - accuracy: 0.5217 - val_loss: 0.6868 - val_accuracy: 0.5833\n",
      "Epoch 12/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6880 - val_accuracy: 0.5833\n",
      "Epoch 13/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6874 - val_accuracy: 0.5833\n",
      "Epoch 14/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6925 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 15/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6934 - accuracy: 0.5217 - val_loss: 0.6883 - val_accuracy: 0.5833\n",
      "Epoch 16/200\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6870 - val_accuracy: 0.5833\n",
      "Epoch 17/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6919 - accuracy: 0.5217 - val_loss: 0.6848 - val_accuracy: 0.5833\n",
      "Epoch 18/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6960 - accuracy: 0.4975 - val_loss: 0.6908 - val_accuracy: 0.5833\n",
      "Epoch 19/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6932 - accuracy: 0.5125 - val_loss: 0.6885 - val_accuracy: 0.5833\n",
      "Epoch 20/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6934 - accuracy: 0.5175 - val_loss: 0.6894 - val_accuracy: 0.5833\n",
      "Epoch 21/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6929 - accuracy: 0.5133 - val_loss: 0.6867 - val_accuracy: 0.5833\n",
      "Epoch 22/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6929 - accuracy: 0.5233 - val_loss: 0.6876 - val_accuracy: 0.5833\n",
      "Epoch 23/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6867 - val_accuracy: 0.5833\n",
      "Epoch 24/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6860 - val_accuracy: 0.5833\n",
      "Epoch 25/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6858 - val_accuracy: 0.5833\n",
      "Epoch 26/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6862 - val_accuracy: 0.5833\n",
      "Epoch 27/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6931 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 28/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6878 - val_accuracy: 0.5833\n",
      "Epoch 29/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6928 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 30/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 31/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 32/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6916 - accuracy: 0.5217 - val_loss: 0.6863 - val_accuracy: 0.5833\n",
      "Epoch 33/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6865 - val_accuracy: 0.5833\n",
      "Epoch 34/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6931 - accuracy: 0.5217 - val_loss: 0.6873 - val_accuracy: 0.5833\n",
      "Epoch 35/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6925 - accuracy: 0.5217 - val_loss: 0.6872 - val_accuracy: 0.5833\n",
      "Epoch 36/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6872 - val_accuracy: 0.5833\n",
      "Epoch 37/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6930 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 38/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6918 - accuracy: 0.5217 - val_loss: 0.6872 - val_accuracy: 0.5833\n",
      "Epoch 39/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6874 - val_accuracy: 0.5833\n",
      "Epoch 40/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6933 - accuracy: 0.5217 - val_loss: 0.6870 - val_accuracy: 0.5833\n",
      "Epoch 41/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6866 - val_accuracy: 0.5833\n",
      "Epoch 42/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6920 - accuracy: 0.5217 - val_loss: 0.6868 - val_accuracy: 0.5833\n",
      "Epoch 43/200\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6865 - val_accuracy: 0.5833\n",
      "Epoch 44/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6862 - val_accuracy: 0.5833\n",
      "Epoch 45/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6930 - accuracy: 0.5217 - val_loss: 0.6861 - val_accuracy: 0.5833\n",
      "Epoch 46/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6925 - accuracy: 0.5217 - val_loss: 0.6877 - val_accuracy: 0.5833\n",
      "Epoch 47/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 48/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6870 - val_accuracy: 0.5833\n",
      "Epoch 49/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6920 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 50/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6925 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 51/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6874 - val_accuracy: 0.5833\n",
      "Epoch 52/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 53/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6874 - val_accuracy: 0.5833\n",
      "Epoch 54/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6872 - val_accuracy: 0.5833\n",
      "Epoch 55/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6877 - val_accuracy: 0.5833\n",
      "Epoch 56/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6867 - val_accuracy: 0.5833\n",
      "Epoch 57/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6873 - val_accuracy: 0.5833\n",
      "Epoch 58/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6927 - accuracy: 0.5217 - val_loss: 0.6867 - val_accuracy: 0.5833\n",
      "Epoch 59/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 60/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 61/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6868 - val_accuracy: 0.5833\n",
      "Epoch 62/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6919 - accuracy: 0.5217 - val_loss: 0.6861 - val_accuracy: 0.5833\n",
      "Epoch 63/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6856 - val_accuracy: 0.5833\n",
      "Epoch 64/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6861 - val_accuracy: 0.5833\n",
      "Epoch 65/200\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.6929 - accuracy: 0.5217 - val_loss: 0.6870 - val_accuracy: 0.5833\n",
      "Epoch 66/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6866 - val_accuracy: 0.5833\n",
      "Epoch 67/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6866 - val_accuracy: 0.5833\n",
      "Epoch 68/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6865 - val_accuracy: 0.5833\n",
      "Epoch 69/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6860 - val_accuracy: 0.5833\n",
      "Epoch 70/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6865 - val_accuracy: 0.5833\n",
      "Epoch 71/200\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.6925 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 72/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6919 - accuracy: 0.5217 - val_loss: 0.6874 - val_accuracy: 0.5833\n",
      "Epoch 73/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 74/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6920 - accuracy: 0.5217 - val_loss: 0.6857 - val_accuracy: 0.5833\n",
      "Epoch 75/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6865 - val_accuracy: 0.5833\n",
      "Epoch 76/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6867 - val_accuracy: 0.5833\n",
      "Epoch 77/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 78/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 79/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6919 - accuracy: 0.5217 - val_loss: 0.6862 - val_accuracy: 0.5833\n",
      "Epoch 80/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6922 - accuracy: 0.5192 - val_loss: 0.6878 - val_accuracy: 0.5833\n",
      "Epoch 81/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6931 - accuracy: 0.5192 - val_loss: 0.6861 - val_accuracy: 0.5833\n",
      "Epoch 82/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6925 - accuracy: 0.5217 - val_loss: 0.6864 - val_accuracy: 0.5833\n",
      "Epoch 83/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6925 - accuracy: 0.5217 - val_loss: 0.6862 - val_accuracy: 0.5833\n",
      "Epoch 84/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6856 - val_accuracy: 0.5833\n",
      "Epoch 85/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6925 - accuracy: 0.5217 - val_loss: 0.6867 - val_accuracy: 0.5833\n",
      "Epoch 86/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6862 - val_accuracy: 0.5833\n",
      "Epoch 87/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6863 - val_accuracy: 0.5833\n",
      "Epoch 88/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6868 - val_accuracy: 0.5833\n",
      "Epoch 89/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6868 - val_accuracy: 0.5833\n",
      "Epoch 90/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6929 - accuracy: 0.5217 - val_loss: 0.6870 - val_accuracy: 0.5833\n",
      "Epoch 91/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6863 - val_accuracy: 0.5833\n",
      "Epoch 92/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6929 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 93/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6865 - val_accuracy: 0.5833\n",
      "Epoch 94/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6927 - accuracy: 0.5217 - val_loss: 0.6876 - val_accuracy: 0.5833\n",
      "Epoch 95/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6920 - accuracy: 0.5217 - val_loss: 0.6875 - val_accuracy: 0.5833\n",
      "Epoch 96/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6925 - accuracy: 0.5217 - val_loss: 0.6867 - val_accuracy: 0.5833\n",
      "Epoch 97/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 98/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6875 - val_accuracy: 0.5833\n",
      "Epoch 99/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 100/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6870 - val_accuracy: 0.5833\n",
      "Epoch 101/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6927 - accuracy: 0.5217 - val_loss: 0.6874 - val_accuracy: 0.5833\n",
      "Epoch 102/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6874 - val_accuracy: 0.5833\n",
      "Epoch 103/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 104/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6877 - val_accuracy: 0.5833\n",
      "Epoch 105/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6925 - accuracy: 0.5217 - val_loss: 0.6867 - val_accuracy: 0.5833\n",
      "Epoch 106/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6873 - val_accuracy: 0.5833\n",
      "Epoch 107/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6872 - val_accuracy: 0.5833\n",
      "Epoch 108/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6874 - val_accuracy: 0.5833\n",
      "Epoch 109/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6876 - val_accuracy: 0.5833\n",
      "Epoch 110/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6874 - val_accuracy: 0.5833\n",
      "Epoch 111/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6873 - val_accuracy: 0.5833\n",
      "Epoch 112/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 113/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 114/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6868 - val_accuracy: 0.5833\n",
      "Epoch 115/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 116/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6870 - val_accuracy: 0.5833\n",
      "Epoch 117/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6925 - accuracy: 0.5217 - val_loss: 0.6872 - val_accuracy: 0.5833\n",
      "Epoch 118/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 119/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 120/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 121/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6870 - val_accuracy: 0.5833\n",
      "Epoch 122/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 123/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6873 - val_accuracy: 0.5833\n",
      "Epoch 124/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6868 - val_accuracy: 0.5833\n",
      "Epoch 125/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 126/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 127/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6866 - val_accuracy: 0.5833\n",
      "Epoch 128/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6866 - val_accuracy: 0.5833\n",
      "Epoch 129/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 130/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6866 - val_accuracy: 0.5833\n",
      "Epoch 131/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6874 - val_accuracy: 0.5833\n",
      "Epoch 132/200\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6866 - val_accuracy: 0.5833\n",
      "Epoch 133/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6865 - val_accuracy: 0.5833\n",
      "Epoch 134/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6868 - val_accuracy: 0.5833\n",
      "Epoch 135/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6868 - val_accuracy: 0.5833\n",
      "Epoch 136/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 137/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 138/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6872 - val_accuracy: 0.5833\n",
      "Epoch 139/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6866 - val_accuracy: 0.5833\n",
      "Epoch 140/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6925 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 141/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 142/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6870 - val_accuracy: 0.5833\n",
      "Epoch 143/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6868 - val_accuracy: 0.5833\n",
      "Epoch 144/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6875 - val_accuracy: 0.5833\n",
      "Epoch 145/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6918 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 146/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6863 - val_accuracy: 0.5833\n",
      "Epoch 147/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6925 - accuracy: 0.5217 - val_loss: 0.6865 - val_accuracy: 0.5833\n",
      "Epoch 148/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6867 - val_accuracy: 0.5833\n",
      "Epoch 149/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6867 - val_accuracy: 0.5833\n",
      "Epoch 150/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6927 - accuracy: 0.5217 - val_loss: 0.6862 - val_accuracy: 0.5833\n",
      "Epoch 151/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6925 - accuracy: 0.5217 - val_loss: 0.6870 - val_accuracy: 0.5833\n",
      "Epoch 152/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6876 - val_accuracy: 0.5833\n",
      "Epoch 153/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 154/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 155/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6920 - accuracy: 0.5217 - val_loss: 0.6864 - val_accuracy: 0.5833\n",
      "Epoch 156/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6865 - val_accuracy: 0.5833\n",
      "Epoch 157/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6920 - accuracy: 0.5217 - val_loss: 0.6862 - val_accuracy: 0.5833\n",
      "Epoch 158/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6860 - val_accuracy: 0.5833\n",
      "Epoch 159/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6928 - accuracy: 0.5217 - val_loss: 0.6866 - val_accuracy: 0.5833\n",
      "Epoch 160/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6868 - val_accuracy: 0.5833\n",
      "Epoch 161/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6867 - val_accuracy: 0.5833\n",
      "Epoch 162/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6929 - accuracy: 0.5217 - val_loss: 0.6866 - val_accuracy: 0.5833\n",
      "Epoch 163/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 164/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6865 - val_accuracy: 0.5833\n",
      "Epoch 165/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6863 - val_accuracy: 0.5833\n",
      "Epoch 166/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6868 - val_accuracy: 0.5833\n",
      "Epoch 167/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6866 - val_accuracy: 0.5833\n",
      "Epoch 168/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6867 - val_accuracy: 0.5833\n",
      "Epoch 169/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6872 - val_accuracy: 0.5833\n",
      "Epoch 170/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6865 - val_accuracy: 0.5833\n",
      "Epoch 171/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6920 - accuracy: 0.5217 - val_loss: 0.6863 - val_accuracy: 0.5833\n",
      "Epoch 172/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6919 - accuracy: 0.5217 - val_loss: 0.6862 - val_accuracy: 0.5833\n",
      "Epoch 173/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6862 - val_accuracy: 0.5833\n",
      "Epoch 174/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6863 - val_accuracy: 0.5833\n",
      "Epoch 175/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6868 - val_accuracy: 0.5833\n",
      "Epoch 176/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6868 - val_accuracy: 0.5833\n",
      "Epoch 177/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6872 - val_accuracy: 0.5833\n",
      "Epoch 178/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6873 - val_accuracy: 0.5833\n",
      "Epoch 179/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6873 - val_accuracy: 0.5833\n",
      "Epoch 180/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6862 - val_accuracy: 0.5833\n",
      "Epoch 181/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6925 - accuracy: 0.5217 - val_loss: 0.6870 - val_accuracy: 0.5833\n",
      "Epoch 182/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6868 - val_accuracy: 0.5833\n",
      "Epoch 183/200\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 184/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6872 - val_accuracy: 0.5833\n",
      "Epoch 185/200\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 186/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6866 - val_accuracy: 0.5833\n",
      "Epoch 187/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6870 - val_accuracy: 0.5833\n",
      "Epoch 188/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6872 - val_accuracy: 0.5833\n",
      "Epoch 189/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6873 - val_accuracy: 0.5833\n",
      "Epoch 190/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6877 - val_accuracy: 0.5833\n",
      "Epoch 191/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6874 - val_accuracy: 0.5833\n",
      "Epoch 192/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6867 - val_accuracy: 0.5833\n",
      "Epoch 193/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6867 - val_accuracy: 0.5833\n",
      "Epoch 194/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6921 - accuracy: 0.5217 - val_loss: 0.6872 - val_accuracy: 0.5833\n",
      "Epoch 195/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6923 - accuracy: 0.5217 - val_loss: 0.6867 - val_accuracy: 0.5833\n",
      "Epoch 196/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6872 - val_accuracy: 0.5833\n",
      "Epoch 197/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6871 - val_accuracy: 0.5833\n",
      "Epoch 198/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6922 - accuracy: 0.5217 - val_loss: 0.6876 - val_accuracy: 0.5833\n",
      "Epoch 199/200\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6876 - val_accuracy: 0.5833\n",
      "Epoch 200/200\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6866 - val_accuracy: 0.5833\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(img_list[0].shape[0], img_list[0].shape[1], img_list[0].shape[2])),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=32, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=64, padding=\"same\", activation=\"relu\"),\n",
    "    # tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=128, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=256, padding= \"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(units=256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(units=2, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=200\n",
    "history = model.fit(\n",
    "  x_train,\n",
    "  y_train,\n",
    "  epochs=epochs,\n",
    "  batch_size = 32,\n",
    "  validation_split = 0.2,\n",
    "  verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history = pd.DataFrame(history.history)\n",
    "df_history.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test)\n",
    "test_results = []\n",
    "for idx, pred in enumerate(preds):\n",
    "    this_label = y_test[idx]\n",
    "    this_predict = np.argmax(pred)\n",
    "    acc = 0\n",
    "    if this_label == this_predict:\n",
    "        acc = 1\n",
    "    test_results.append({\"label\" : this_label, \"predict\" : this_predict, \"acc\" : acc})\n",
    "\n",
    "test_results = pd.DataFrame(test_results)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ratio = test_results[\"acc\"].sum() / len(test_results)\n",
    "print(\"테스트 정확도 : {}/{} ({:.2f})\".format(test_results[\"acc\"].sum(), len(test_results), acc_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최근 날짜로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler_pred = Crawler(crawl_page_max=1, perPage=100) #이전 추세도 볼겸 넉넉히 수집\n",
    "crawler_pred.crawlData(cols)\n",
    "df_crawled_pred = crawler_pred.removeNan()\n",
    "df_crawled_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#아래는 예측을 위한 전처리\n",
    "dpp_pred = DataPreprocessor(df_crawled_pred.loc[:100], cols, scale_method, model_save_path)\n",
    "dpp_pred.sortByDate()\n",
    "dpp_pred.makeDiffRatio()\n",
    "dpp_pred.scalingForPredict()\n",
    "dpp_pred.makeAR(0, len_x_ARMA)\n",
    "dpp_pred.makeMA(2, len_x_ARMA)\n",
    "dpp_pred.cutoffData(len_x_ARMA, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpp_pred.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred_list, label_pred_list, date_list, _ = makeImage2D(dpp_pred.df, cut_latest_data=False)\n",
    "len(img_pred_list), len(label_pred_list), len(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_day = 1\n",
    "img_pred = np.array([img_pred_list[-before_day]])\n",
    "pred = model.predict(img_pred)\n",
    "test_results = []\n",
    "predict = np.argmax(pred)\n",
    "print(\"{} predict : {}, real : {}\".format(date_list[-before_day], predict, label_pred_list[-before_day]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(img_list, y_list, test_size=0.2, shuffle=False, random_state=8699)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Input(shape=(24, 20, 1)),\n",
    "  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dense(20, activation=\"relu\")\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "epochs=5000\n",
    "history = model.fit(\n",
    "  x_train,\n",
    "  y_train,\n",
    "  epochs=epochs,\n",
    "  validation_split = 0.1,\n",
    "  verbose = 1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aaf533d5ae3a3d7a7fcdd7d995dbe2f3fcb3d854cc4805079aca601e58923c31"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv_tf_3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
