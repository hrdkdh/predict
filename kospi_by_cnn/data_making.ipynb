{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_x_ARMA = 60\n",
    "len_y_nextday = 1\n",
    "scale_method = \"minmax\"\n",
    "model_save_path = \"saved_model_cnn1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>KOSPI</th>\n",
       "      <th>KOSPI_START</th>\n",
       "      <th>KOSPI_HIGH</th>\n",
       "      <th>KOSPI_LOW</th>\n",
       "      <th>KOSPI_VOL</th>\n",
       "      <th>KOSPI_VAL</th>\n",
       "      <th>KOSPI_HIGH_LOW_GAP</th>\n",
       "      <th>NASDAQ</th>\n",
       "      <th>NASDAQ_START</th>\n",
       "      <th>...</th>\n",
       "      <th>SHANGHAI</th>\n",
       "      <th>SHANGHAI_START</th>\n",
       "      <th>SHANGHAI_HIGH</th>\n",
       "      <th>SHANGHAI_LOW</th>\n",
       "      <th>SHANGHAI_VOL</th>\n",
       "      <th>INDI</th>\n",
       "      <th>FOREIGN</th>\n",
       "      <th>ORG</th>\n",
       "      <th>CR</th>\n",
       "      <th>GOLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>2501.53</td>\n",
       "      <td>2511.79</td>\n",
       "      <td>2517.13</td>\n",
       "      <td>2489.58</td>\n",
       "      <td>777535095</td>\n",
       "      <td>14024831081451</td>\n",
       "      <td>-27.55</td>\n",
       "      <td>12142.238</td>\n",
       "      <td>12117.544</td>\n",
       "      <td>...</td>\n",
       "      <td>294.366</td>\n",
       "      <td>292.561</td>\n",
       "      <td>294.481</td>\n",
       "      <td>292.352</td>\n",
       "      <td>258384.0</td>\n",
       "      <td>1.360082e+11</td>\n",
       "      <td>3.004571e+11</td>\n",
       "      <td>-3.550564e+11</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>1983.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>2495.81</td>\n",
       "      <td>2484.31</td>\n",
       "      <td>2499.01</td>\n",
       "      <td>2465.83</td>\n",
       "      <td>733499935</td>\n",
       "      <td>11142114587400</td>\n",
       "      <td>-33.18</td>\n",
       "      <td>11854.351</td>\n",
       "      <td>11972.147</td>\n",
       "      <td>...</td>\n",
       "      <td>292.365</td>\n",
       "      <td>292.255</td>\n",
       "      <td>293.129</td>\n",
       "      <td>291.784</td>\n",
       "      <td>156092.0</td>\n",
       "      <td>1.868206e+11</td>\n",
       "      <td>2.826059e+11</td>\n",
       "      <td>-4.851069e+11</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>1998.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>2484.83</td>\n",
       "      <td>2489.49</td>\n",
       "      <td>2498.56</td>\n",
       "      <td>2481.38</td>\n",
       "      <td>1089215527</td>\n",
       "      <td>12397513675358</td>\n",
       "      <td>-17.18</td>\n",
       "      <td>11799.157</td>\n",
       "      <td>11913.232</td>\n",
       "      <td>...</td>\n",
       "      <td>292.308</td>\n",
       "      <td>291.216</td>\n",
       "      <td>292.645</td>\n",
       "      <td>290.786</td>\n",
       "      <td>186219.0</td>\n",
       "      <td>2.218766e+11</td>\n",
       "      <td>-9.139846e+10</td>\n",
       "      <td>-1.549624e+11</td>\n",
       "      <td>1338.5</td>\n",
       "      <td>1997.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>2489.02</td>\n",
       "      <td>2531.35</td>\n",
       "      <td>2531.35</td>\n",
       "      <td>2472.33</td>\n",
       "      <td>886421798</td>\n",
       "      <td>13681150419767</td>\n",
       "      <td>-59.02</td>\n",
       "      <td>12037.204</td>\n",
       "      <td>11968.808</td>\n",
       "      <td>...</td>\n",
       "      <td>291.401</td>\n",
       "      <td>292.199</td>\n",
       "      <td>293.163</td>\n",
       "      <td>289.257</td>\n",
       "      <td>186435.0</td>\n",
       "      <td>-2.256127e+09</td>\n",
       "      <td>8.622928e+09</td>\n",
       "      <td>5.870307e+07</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>1989.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>2523.50</td>\n",
       "      <td>2538.36</td>\n",
       "      <td>2541.89</td>\n",
       "      <td>2518.73</td>\n",
       "      <td>927191299</td>\n",
       "      <td>11589467033126</td>\n",
       "      <td>-23.16</td>\n",
       "      <td>12072.456</td>\n",
       "      <td>12053.467</td>\n",
       "      <td>...</td>\n",
       "      <td>292.260</td>\n",
       "      <td>292.013</td>\n",
       "      <td>293.438</td>\n",
       "      <td>291.557</td>\n",
       "      <td>203979.0</td>\n",
       "      <td>-8.280490e+10</td>\n",
       "      <td>-3.676363e+10</td>\n",
       "      <td>1.043359e+11</td>\n",
       "      <td>1334.5</td>\n",
       "      <td>1986.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>1997.25</td>\n",
       "      <td>2000.13</td>\n",
       "      <td>2001.26</td>\n",
       "      <td>1995.08</td>\n",
       "      <td>220913202</td>\n",
       "      <td>3990737053146</td>\n",
       "      <td>-6.18</td>\n",
       "      <td>4268.040</td>\n",
       "      <td>4281.607</td>\n",
       "      <td>...</td>\n",
       "      <td>227.157</td>\n",
       "      <td>226.886</td>\n",
       "      <td>228.049</td>\n",
       "      <td>226.687</td>\n",
       "      <td>201000.0</td>\n",
       "      <td>-9.404481e+10</td>\n",
       "      <td>5.607124e+10</td>\n",
       "      <td>4.699805e+10</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>1283.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>1991.98</td>\n",
       "      <td>1983.78</td>\n",
       "      <td>1991.98</td>\n",
       "      <td>1976.06</td>\n",
       "      <td>214641821</td>\n",
       "      <td>3928821531496</td>\n",
       "      <td>-15.92</td>\n",
       "      <td>4198.994</td>\n",
       "      <td>4219.873</td>\n",
       "      <td>...</td>\n",
       "      <td>227.100</td>\n",
       "      <td>225.025</td>\n",
       "      <td>227.245</td>\n",
       "      <td>224.782</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>-7.481867e+10</td>\n",
       "      <td>5.723630e+10</td>\n",
       "      <td>2.308877e+10</td>\n",
       "      <td>1058.1</td>\n",
       "      <td>1287.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>2014-03-31</td>\n",
       "      <td>1985.61</td>\n",
       "      <td>1988.73</td>\n",
       "      <td>1989.80</td>\n",
       "      <td>1973.05</td>\n",
       "      <td>241040678</td>\n",
       "      <td>4468746178897</td>\n",
       "      <td>-16.75</td>\n",
       "      <td>4155.759</td>\n",
       "      <td>4185.625</td>\n",
       "      <td>...</td>\n",
       "      <td>224.986</td>\n",
       "      <td>226.859</td>\n",
       "      <td>227.531</td>\n",
       "      <td>223.558</td>\n",
       "      <td>284000.0</td>\n",
       "      <td>3.480548e+10</td>\n",
       "      <td>-1.698837e+10</td>\n",
       "      <td>-7.795431e+09</td>\n",
       "      <td>1063.5</td>\n",
       "      <td>1292.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>2014-03-28</td>\n",
       "      <td>1981.00</td>\n",
       "      <td>1972.63</td>\n",
       "      <td>1985.50</td>\n",
       "      <td>1971.25</td>\n",
       "      <td>244600277</td>\n",
       "      <td>3446078839989</td>\n",
       "      <td>-14.25</td>\n",
       "      <td>4151.232</td>\n",
       "      <td>4163.175</td>\n",
       "      <td>...</td>\n",
       "      <td>226.795</td>\n",
       "      <td>226.691</td>\n",
       "      <td>227.502</td>\n",
       "      <td>225.625</td>\n",
       "      <td>403000.0</td>\n",
       "      <td>-1.673696e+11</td>\n",
       "      <td>2.335767e+11</td>\n",
       "      <td>-7.127617e+10</td>\n",
       "      <td>1068.7</td>\n",
       "      <td>1295.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>2014-03-27</td>\n",
       "      <td>1977.97</td>\n",
       "      <td>1963.66</td>\n",
       "      <td>1979.70</td>\n",
       "      <td>1963.10</td>\n",
       "      <td>218060994</td>\n",
       "      <td>3995923749784</td>\n",
       "      <td>-16.60</td>\n",
       "      <td>4173.579</td>\n",
       "      <td>4169.351</td>\n",
       "      <td>...</td>\n",
       "      <td>226.674</td>\n",
       "      <td>227.225</td>\n",
       "      <td>227.531</td>\n",
       "      <td>225.826</td>\n",
       "      <td>255000.0</td>\n",
       "      <td>4.179541e+10</td>\n",
       "      <td>-3.094872e+10</td>\n",
       "      <td>-2.798026e+09</td>\n",
       "      <td>1072.5</td>\n",
       "      <td>1295.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2238 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date    KOSPI  KOSPI_START  KOSPI_HIGH  KOSPI_LOW   KOSPI_VOL   \n",
       "0     2023-04-28  2501.53      2511.79     2517.13    2489.58   777535095  \\\n",
       "1     2023-04-27  2495.81      2484.31     2499.01    2465.83   733499935   \n",
       "2     2023-04-26  2484.83      2489.49     2498.56    2481.38  1089215527   \n",
       "3     2023-04-25  2489.02      2531.35     2531.35    2472.33   886421798   \n",
       "4     2023-04-24  2523.50      2538.36     2541.89    2518.73   927191299   \n",
       "...          ...      ...          ...         ...        ...         ...   \n",
       "2233  2014-04-02  1997.25      2000.13     2001.26    1995.08   220913202   \n",
       "2234  2014-04-01  1991.98      1983.78     1991.98    1976.06   214641821   \n",
       "2235  2014-03-31  1985.61      1988.73     1989.80    1973.05   241040678   \n",
       "2236  2014-03-28  1981.00      1972.63     1985.50    1971.25   244600277   \n",
       "2237  2014-03-27  1977.97      1963.66     1979.70    1963.10   218060994   \n",
       "\n",
       "           KOSPI_VAL  KOSPI_HIGH_LOW_GAP     NASDAQ  NASDAQ_START  ...   \n",
       "0     14024831081451              -27.55  12142.238     12117.544  ...  \\\n",
       "1     11142114587400              -33.18  11854.351     11972.147  ...   \n",
       "2     12397513675358              -17.18  11799.157     11913.232  ...   \n",
       "3     13681150419767              -59.02  12037.204     11968.808  ...   \n",
       "4     11589467033126              -23.16  12072.456     12053.467  ...   \n",
       "...              ...                 ...        ...           ...  ...   \n",
       "2233   3990737053146               -6.18   4268.040      4281.607  ...   \n",
       "2234   3928821531496              -15.92   4198.994      4219.873  ...   \n",
       "2235   4468746178897              -16.75   4155.759      4185.625  ...   \n",
       "2236   3446078839989              -14.25   4151.232      4163.175  ...   \n",
       "2237   3995923749784              -16.60   4173.579      4169.351  ...   \n",
       "\n",
       "      SHANGHAI  SHANGHAI_START  SHANGHAI_HIGH  SHANGHAI_LOW  SHANGHAI_VOL   \n",
       "0      294.366         292.561        294.481       292.352      258384.0  \\\n",
       "1      292.365         292.255        293.129       291.784      156092.0   \n",
       "2      292.308         291.216        292.645       290.786      186219.0   \n",
       "3      291.401         292.199        293.163       289.257      186435.0   \n",
       "4      292.260         292.013        293.438       291.557      203979.0   \n",
       "...        ...             ...            ...           ...           ...   \n",
       "2233   227.157         226.886        228.049       226.687      201000.0   \n",
       "2234   227.100         225.025        227.245       224.782      153000.0   \n",
       "2235   224.986         226.859        227.531       223.558      284000.0   \n",
       "2236   226.795         226.691        227.502       225.625      403000.0   \n",
       "2237   226.674         227.225        227.531       225.826      255000.0   \n",
       "\n",
       "              INDI       FOREIGN           ORG      CR     GOLD  \n",
       "0     1.360082e+11  3.004571e+11 -3.550564e+11  1341.0  1983.29  \n",
       "1     1.868206e+11  2.826059e+11 -4.851069e+11  1341.0  1998.14  \n",
       "2     2.218766e+11 -9.139846e+10 -1.549624e+11  1338.5  1997.63  \n",
       "3    -2.256127e+09  8.622928e+09  5.870307e+07  1341.0  1989.68  \n",
       "4    -8.280490e+10 -3.676363e+10  1.043359e+11  1334.5  1986.55  \n",
       "...            ...           ...           ...     ...      ...  \n",
       "2233 -9.404481e+10  5.607124e+10  4.699805e+10  1058.0  1283.00  \n",
       "2234 -7.481867e+10  5.723630e+10  2.308877e+10  1058.1  1287.68  \n",
       "2235  3.480548e+10 -1.698837e+10 -7.795431e+09  1063.5  1292.78  \n",
       "2236 -1.673696e+11  2.335767e+11 -7.127617e+10  1068.7  1295.98  \n",
       "2237  4.179541e+10 -3.094872e+10 -2.798026e+09  1072.5  1295.90  \n",
       "\n",
       "[2238 rows x 33 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kospi_predict import Crawler\n",
    "\n",
    "cols = [\n",
    "    \"KOSPI\", \"KOSPI_START\", \"KOSPI_HIGH\", \"KOSPI_LOW\", \"KOSPI_VOL\", \"KOSPI_VAL\", \"KOSPI_HIGH_LOW_GAP\",\n",
    "    \"NASDAQ\", \"NASDAQ_START\", \"NASDAQ_HIGH\", \"NASDAQ_LOW\", \"NASDAQ_VOL\",\n",
    "    \"DOW\", \"DOW_START\", \"DOW_HIGH\", \"DOW_LOW\", \"DOW_VOL\",\n",
    "    \"NIKKEI\", \"NIKKEI_START\", \"NIKKEI_HIGH\", \"NIKKEI_LOW\", \"NIKKEI_VOL\",\n",
    "    \"SHANGHAI\", \"SHANGHAI_START\", \"SHANGHAI_HIGH\", \"SHANGHAI_LOW\", \"SHANGHAI_VOL\",\n",
    "    \"INDI\", \"FOREIGN\", \"ORG\",\n",
    "    \"CR\",\n",
    "    \"GOLD\"\n",
    "]\n",
    "\n",
    "crawler = Crawler(crawl_page_max=30, perPage=100)\n",
    "# crawler.crawlData(cols, save=True)\n",
    "crawler.loadFromSavedFile(cols)\n",
    "df_crawled = crawler.removeNan()\n",
    "# df_crawled = df_crawled.loc[:2000]\n",
    "df_crawled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨 생성중... (100.00%)\r"
     ]
    }
   ],
   "source": [
    "from kospi_predict import DataPreprocessor\n",
    "from sklearn.preprocessing import MinMaxScaler as MinMaxScaler\n",
    "\n",
    "dpp = DataPreprocessor(df_crawled, cols, scale_method, model_save_path)\n",
    "dpp.sortByDate()\n",
    "# dpp.makeDiffByRange(1, len_x_ARMA)\n",
    "# dpp.makeDiffRatio()\n",
    "# dpp.makeAR(0, len_x_ARMA)\n",
    "# dpp.makeMA(2, len_x_ARMA)\n",
    "dpp.makeTargetYs(len_y_nextday)\n",
    "dpp.cutoffData(len_x_ARMA, len_y_nextday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>KOSPI</th>\n",
       "      <th>KOSPI_START</th>\n",
       "      <th>KOSPI_HIGH</th>\n",
       "      <th>KOSPI_LOW</th>\n",
       "      <th>KOSPI_VOL</th>\n",
       "      <th>KOSPI_VAL</th>\n",
       "      <th>KOSPI_HIGH_LOW_GAP</th>\n",
       "      <th>NASDAQ</th>\n",
       "      <th>NASDAQ_START</th>\n",
       "      <th>...</th>\n",
       "      <th>SHANGHAI_START</th>\n",
       "      <th>SHANGHAI_HIGH</th>\n",
       "      <th>SHANGHAI_LOW</th>\n",
       "      <th>SHANGHAI_VOL</th>\n",
       "      <th>INDI</th>\n",
       "      <th>FOREIGN</th>\n",
       "      <th>ORG</th>\n",
       "      <th>CR</th>\n",
       "      <th>GOLD</th>\n",
       "      <th>Y_KOSPI_nextday_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-06-27</td>\n",
       "      <td>1988.51</td>\n",
       "      <td>1990.90</td>\n",
       "      <td>1997.01</td>\n",
       "      <td>1983.88</td>\n",
       "      <td>218844990</td>\n",
       "      <td>3395118807857</td>\n",
       "      <td>-13.13</td>\n",
       "      <td>4379.046</td>\n",
       "      <td>4371.800</td>\n",
       "      <td>...</td>\n",
       "      <td>219.720</td>\n",
       "      <td>220.780</td>\n",
       "      <td>219.602</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>2.628406e+09</td>\n",
       "      <td>-3.999679e+09</td>\n",
       "      <td>4.493030e+09</td>\n",
       "      <td>1014.5</td>\n",
       "      <td>1316.08</td>\n",
       "      <td>2002.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>2002.21</td>\n",
       "      <td>1996.13</td>\n",
       "      <td>2002.21</td>\n",
       "      <td>1992.65</td>\n",
       "      <td>201128111</td>\n",
       "      <td>2989877070056</td>\n",
       "      <td>-9.56</td>\n",
       "      <td>4397.930</td>\n",
       "      <td>4398.366</td>\n",
       "      <td>...</td>\n",
       "      <td>220.673</td>\n",
       "      <td>221.522</td>\n",
       "      <td>220.400</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>-2.053198e+10</td>\n",
       "      <td>2.555607e+10</td>\n",
       "      <td>-2.518148e+09</td>\n",
       "      <td>1011.8</td>\n",
       "      <td>1312.50</td>\n",
       "      <td>1999.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>1999.00</td>\n",
       "      <td>1993.29</td>\n",
       "      <td>1999.00</td>\n",
       "      <td>1987.89</td>\n",
       "      <td>238870813</td>\n",
       "      <td>3004954923884</td>\n",
       "      <td>-11.11</td>\n",
       "      <td>4408.178</td>\n",
       "      <td>4424.706</td>\n",
       "      <td>...</td>\n",
       "      <td>221.181</td>\n",
       "      <td>222.013</td>\n",
       "      <td>220.857</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>-7.275962e+10</td>\n",
       "      <td>2.392553e+10</td>\n",
       "      <td>5.735100e+10</td>\n",
       "      <td>1011.2</td>\n",
       "      <td>1326.45</td>\n",
       "      <td>2015.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-02</td>\n",
       "      <td>2015.28</td>\n",
       "      <td>2008.00</td>\n",
       "      <td>2016.36</td>\n",
       "      <td>2002.40</td>\n",
       "      <td>318423490</td>\n",
       "      <td>3854654534211</td>\n",
       "      <td>-13.96</td>\n",
       "      <td>4458.651</td>\n",
       "      <td>4457.858</td>\n",
       "      <td>...</td>\n",
       "      <td>222.005</td>\n",
       "      <td>223.069</td>\n",
       "      <td>221.136</td>\n",
       "      <td>174000.0</td>\n",
       "      <td>-2.444938e+11</td>\n",
       "      <td>3.147873e+11</td>\n",
       "      <td>-4.995202e+10</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1325.40</td>\n",
       "      <td>2010.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-07-03</td>\n",
       "      <td>2010.97</td>\n",
       "      <td>2015.99</td>\n",
       "      <td>2015.99</td>\n",
       "      <td>2007.86</td>\n",
       "      <td>259913596</td>\n",
       "      <td>3515649244769</td>\n",
       "      <td>-8.13</td>\n",
       "      <td>4457.734</td>\n",
       "      <td>4472.891</td>\n",
       "      <td>...</td>\n",
       "      <td>222.966</td>\n",
       "      <td>223.748</td>\n",
       "      <td>222.450</td>\n",
       "      <td>266000.0</td>\n",
       "      <td>-2.376206e+10</td>\n",
       "      <td>1.591954e+11</td>\n",
       "      <td>-1.167735e+11</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>1322.38</td>\n",
       "      <td>2009.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>2023-04-21</td>\n",
       "      <td>2544.40</td>\n",
       "      <td>2556.70</td>\n",
       "      <td>2559.44</td>\n",
       "      <td>2532.32</td>\n",
       "      <td>970397971</td>\n",
       "      <td>12614672834698</td>\n",
       "      <td>-27.12</td>\n",
       "      <td>12059.558</td>\n",
       "      <td>12046.033</td>\n",
       "      <td>...</td>\n",
       "      <td>295.015</td>\n",
       "      <td>295.889</td>\n",
       "      <td>291.335</td>\n",
       "      <td>258731.0</td>\n",
       "      <td>-1.949021e+11</td>\n",
       "      <td>2.800835e+11</td>\n",
       "      <td>-8.406796e+10</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>1988.30</td>\n",
       "      <td>2523.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>2523.50</td>\n",
       "      <td>2538.36</td>\n",
       "      <td>2541.89</td>\n",
       "      <td>2518.73</td>\n",
       "      <td>927191299</td>\n",
       "      <td>11589467033126</td>\n",
       "      <td>-23.16</td>\n",
       "      <td>12072.456</td>\n",
       "      <td>12053.467</td>\n",
       "      <td>...</td>\n",
       "      <td>292.013</td>\n",
       "      <td>293.438</td>\n",
       "      <td>291.557</td>\n",
       "      <td>203979.0</td>\n",
       "      <td>-8.280490e+10</td>\n",
       "      <td>-3.676363e+10</td>\n",
       "      <td>1.043359e+11</td>\n",
       "      <td>1334.5</td>\n",
       "      <td>1986.55</td>\n",
       "      <td>2489.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>2489.02</td>\n",
       "      <td>2531.35</td>\n",
       "      <td>2531.35</td>\n",
       "      <td>2472.33</td>\n",
       "      <td>886421798</td>\n",
       "      <td>13681150419767</td>\n",
       "      <td>-59.02</td>\n",
       "      <td>12037.204</td>\n",
       "      <td>11968.808</td>\n",
       "      <td>...</td>\n",
       "      <td>292.199</td>\n",
       "      <td>293.163</td>\n",
       "      <td>289.257</td>\n",
       "      <td>186435.0</td>\n",
       "      <td>-2.256127e+09</td>\n",
       "      <td>8.622928e+09</td>\n",
       "      <td>5.870307e+07</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>1989.68</td>\n",
       "      <td>2484.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>2484.83</td>\n",
       "      <td>2489.49</td>\n",
       "      <td>2498.56</td>\n",
       "      <td>2481.38</td>\n",
       "      <td>1089215527</td>\n",
       "      <td>12397513675358</td>\n",
       "      <td>-17.18</td>\n",
       "      <td>11799.157</td>\n",
       "      <td>11913.232</td>\n",
       "      <td>...</td>\n",
       "      <td>291.216</td>\n",
       "      <td>292.645</td>\n",
       "      <td>290.786</td>\n",
       "      <td>186219.0</td>\n",
       "      <td>2.218766e+11</td>\n",
       "      <td>-9.139846e+10</td>\n",
       "      <td>-1.549624e+11</td>\n",
       "      <td>1338.5</td>\n",
       "      <td>1997.63</td>\n",
       "      <td>2495.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>2495.81</td>\n",
       "      <td>2484.31</td>\n",
       "      <td>2499.01</td>\n",
       "      <td>2465.83</td>\n",
       "      <td>733499935</td>\n",
       "      <td>11142114587400</td>\n",
       "      <td>-33.18</td>\n",
       "      <td>11854.351</td>\n",
       "      <td>11972.147</td>\n",
       "      <td>...</td>\n",
       "      <td>292.255</td>\n",
       "      <td>293.129</td>\n",
       "      <td>291.784</td>\n",
       "      <td>156092.0</td>\n",
       "      <td>1.868206e+11</td>\n",
       "      <td>2.826059e+11</td>\n",
       "      <td>-4.851069e+11</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>1998.14</td>\n",
       "      <td>2501.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2176 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date    KOSPI  KOSPI_START  KOSPI_HIGH  KOSPI_LOW   KOSPI_VOL   \n",
       "0     2014-06-27  1988.51      1990.90     1997.01    1983.88   218844990  \\\n",
       "1     2014-06-30  2002.21      1996.13     2002.21    1992.65   201128111   \n",
       "2     2014-07-01  1999.00      1993.29     1999.00    1987.89   238870813   \n",
       "3     2014-07-02  2015.28      2008.00     2016.36    2002.40   318423490   \n",
       "4     2014-07-03  2010.97      2015.99     2015.99    2007.86   259913596   \n",
       "...          ...      ...          ...         ...        ...         ...   \n",
       "2171  2023-04-21  2544.40      2556.70     2559.44    2532.32   970397971   \n",
       "2172  2023-04-24  2523.50      2538.36     2541.89    2518.73   927191299   \n",
       "2173  2023-04-25  2489.02      2531.35     2531.35    2472.33   886421798   \n",
       "2174  2023-04-26  2484.83      2489.49     2498.56    2481.38  1089215527   \n",
       "2175  2023-04-27  2495.81      2484.31     2499.01    2465.83   733499935   \n",
       "\n",
       "           KOSPI_VAL  KOSPI_HIGH_LOW_GAP     NASDAQ  NASDAQ_START  ...   \n",
       "0      3395118807857              -13.13   4379.046      4371.800  ...  \\\n",
       "1      2989877070056               -9.56   4397.930      4398.366  ...   \n",
       "2      3004954923884              -11.11   4408.178      4424.706  ...   \n",
       "3      3854654534211              -13.96   4458.651      4457.858  ...   \n",
       "4      3515649244769               -8.13   4457.734      4472.891  ...   \n",
       "...              ...                 ...        ...           ...  ...   \n",
       "2171  12614672834698              -27.12  12059.558     12046.033  ...   \n",
       "2172  11589467033126              -23.16  12072.456     12053.467  ...   \n",
       "2173  13681150419767              -59.02  12037.204     11968.808  ...   \n",
       "2174  12397513675358              -17.18  11799.157     11913.232  ...   \n",
       "2175  11142114587400              -33.18  11854.351     11972.147  ...   \n",
       "\n",
       "      SHANGHAI_START  SHANGHAI_HIGH  SHANGHAI_LOW  SHANGHAI_VOL          INDI   \n",
       "0            219.720        220.780       219.602      155000.0  2.628406e+09  \\\n",
       "1            220.673        221.522       220.400      200000.0 -2.053198e+10   \n",
       "2            221.181        222.013       220.857      160000.0 -7.275962e+10   \n",
       "3            222.005        223.069       221.136      174000.0 -2.444938e+11   \n",
       "4            222.966        223.748       222.450      266000.0 -2.376206e+10   \n",
       "...              ...            ...           ...           ...           ...   \n",
       "2171         295.015        295.889       291.335      258731.0 -1.949021e+11   \n",
       "2172         292.013        293.438       291.557      203979.0 -8.280490e+10   \n",
       "2173         292.199        293.163       289.257      186435.0 -2.256127e+09   \n",
       "2174         291.216        292.645       290.786      186219.0  2.218766e+11   \n",
       "2175         292.255        293.129       291.784      156092.0  1.868206e+11   \n",
       "\n",
       "           FOREIGN           ORG      CR     GOLD  Y_KOSPI_nextday_1  \n",
       "0    -3.999679e+09  4.493030e+09  1014.5  1316.08            2002.21  \n",
       "1     2.555607e+10 -2.518148e+09  1011.8  1312.50            1999.00  \n",
       "2     2.392553e+10  5.735100e+10  1011.2  1326.45            2015.28  \n",
       "3     3.147873e+11 -4.995202e+10  1008.0  1325.40            2010.97  \n",
       "4     1.591954e+11 -1.167735e+11  1008.8  1322.38            2009.66  \n",
       "...            ...           ...     ...      ...                ...  \n",
       "2171  2.800835e+11 -8.406796e+10  1332.0  1988.30            2523.50  \n",
       "2172 -3.676363e+10  1.043359e+11  1334.5  1986.55            2489.02  \n",
       "2173  8.622928e+09  5.870307e+07  1341.0  1989.68            2484.83  \n",
       "2174 -9.139846e+10 -1.549624e+11  1338.5  1997.63            2495.81  \n",
       "2175  2.826059e+11 -4.851069e+11  1341.0  1998.14            2501.53  \n",
       "\n",
       "[2176 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = dpp.df[500:1500]\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "dpp.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1974, 32, 32, 3), (1974,), (1974,), (1974,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def rescalingByMinMax(arr):\n",
    "    for col_idx in range(arr.shape[1]):\n",
    "        this_arr = arr[:, col_idx]\n",
    "        max_val = max(this_arr)\n",
    "        min_val = min(this_arr)\n",
    "        for row_idx, val in enumerate(this_arr):\n",
    "            new_val = (val - min_val) / (max_val - min_val)\n",
    "            arr[row_idx, col_idx] = new_val\n",
    "    return arr\n",
    "\n",
    "def makeImage3D(df, row_cnt = 8):\n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    date_list = []\n",
    "    y_list = []\n",
    "    for idx in range(len(df)):\n",
    "        if idx > 200:\n",
    "            this_mat = np.empty(shape=(row_cnt, len(cols), 3))\n",
    "            for i in range(1, 4):\n",
    "                this_ch = rescalingByMinMax(np.array(df.iloc[idx-(row_cnt*i):idx-(row_cnt*(i-1)), 1:len(cols)+1], dtype=np.float32))\n",
    "                this_mat[:, :, i-1] = this_ch\n",
    "            img_list.append(this_mat)\n",
    "\n",
    "            #라벨 체크\n",
    "            this_label = np.nan\n",
    "            if idx+1 < len(df): #0 1 2 ... 29 / 30\n",
    "                this_label = 0\n",
    "                if df.iloc[idx+1, 1] > df.iloc[idx, 1]: #item[0]+1 : 다음날\n",
    "                    this_label = 1\n",
    "            label_list.append(this_label)\n",
    "\n",
    "            #라벨값과 함께 이미지로 저장\n",
    "            cv2.imwrite(\"../data_cnn/{}_{}.png\".format(str(this_label), df.iloc[idx, 0]), this_mat * 255)\n",
    "\n",
    "            #날짜 리스트 입력\n",
    "            date_list.append(df.iloc[idx, 0])\n",
    "\n",
    "            #y_list 입력\n",
    "            y_list.append(df.iloc[idx, -1])\n",
    "\n",
    "    img_list = np.array(img_list[:-1])\n",
    "    label_list = np.array(label_list[:-1], dtype=np.uint8)\n",
    "    date_list = np.array(date_list[:-1])\n",
    "    y_list = np.array(y_list[:-1])\n",
    "    df_result = pd.DataFrame({\"date\" : date_list, \"label\" : label_list})\n",
    "\n",
    "    return img_list, label_list, date_list, y_list, df_result\n",
    "\n",
    "img_list, label_list, date_list, y_list, df_ref = makeImage3D(dpp.df, row_cnt=len(cols))\n",
    "img_list.shape, label_list.shape, date_list.shape, y_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-04-24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-04-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>2023-04-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>2023-04-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1974 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  label\n",
       "0     2015-04-22      1\n",
       "1     2015-04-23      0\n",
       "2     2015-04-24      0\n",
       "3     2015-04-27      0\n",
       "4     2015-04-28      0\n",
       "...          ...    ...\n",
       "1969  2023-04-20      0\n",
       "1970  2023-04-21      0\n",
       "1971  2023-04-24      0\n",
       "1972  2023-04-25      0\n",
       "1973  2023-04-26      1\n",
       "\n",
       "[1974 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1578, 32, 32, 3), (395, 32, 32, 3), (1578,), (395,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(img_list[:-1], label_list[:-1], test_size=0.2, shuffle=False, random_state=8699)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 22:00:01.958516: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-04-29 22:00:01.958655: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 38, 38, 3)    0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 16, 16, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 1, 1, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " max_pool (GlobalMaxPooling2D)  (None, 2048)         0           ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 22:00:03.600409: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-04-29 22:00:06.496502: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 11.3412 - accuracy: 0.0016    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 22:00:20.838386: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 20s 996ms/step - loss: 11.3412 - accuracy: 0.0016 - val_loss: 12.2424 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 8.3495 - accuracy: 0.0024 - val_loss: 12.3510 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 7.3115 - accuracy: 0.0016 - val_loss: 6.4055 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 6.8488 - accuracy: 0.0000e+00 - val_loss: 5.8584 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 6.1883 - accuracy: 0.0127 - val_loss: 5.6073 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 4.7194 - accuracy: 0.2298 - val_loss: 5.2284 - val_accuracy: 0.5886\n",
      "Epoch 7/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 3.5670 - accuracy: 0.3693 - val_loss: 4.3853 - val_accuracy: 0.5886\n",
      "Epoch 8/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 2.7423 - accuracy: 0.4231 - val_loss: 3.5953 - val_accuracy: 0.5886\n",
      "Epoch 9/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 2.1000 - accuracy: 0.4667 - val_loss: 3.2251 - val_accuracy: 0.5886\n",
      "Epoch 10/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 1.6922 - accuracy: 0.4739 - val_loss: 2.8876 - val_accuracy: 0.5886\n",
      "Epoch 11/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 1.4762 - accuracy: 0.4905 - val_loss: 2.5667 - val_accuracy: 0.5886\n",
      "Epoch 12/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 1.3176 - accuracy: 0.4913 - val_loss: 2.2031 - val_accuracy: 0.5886\n",
      "Epoch 13/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 1.3296 - accuracy: 0.5206 - val_loss: 1.8819 - val_accuracy: 0.5886\n",
      "Epoch 14/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 1.2274 - accuracy: 0.5166 - val_loss: 1.6662 - val_accuracy: 0.5886\n",
      "Epoch 15/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 1.1481 - accuracy: 0.5507 - val_loss: 1.4554 - val_accuracy: 0.5886\n",
      "Epoch 16/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 1.1161 - accuracy: 0.5658 - val_loss: 1.2926 - val_accuracy: 0.5886\n",
      "Epoch 17/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 1.1222 - accuracy: 0.5729 - val_loss: 1.0982 - val_accuracy: 0.5886\n",
      "Epoch 18/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 1.1716 - accuracy: 0.6117 - val_loss: 0.9885 - val_accuracy: 0.5886\n",
      "Epoch 19/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 1.1606 - accuracy: 0.6387 - val_loss: 0.8450 - val_accuracy: 0.5886\n",
      "Epoch 20/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 1.0521 - accuracy: 0.6727 - val_loss: 0.7862 - val_accuracy: 0.5886\n",
      "Epoch 21/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 1.0904 - accuracy: 0.7163 - val_loss: 0.7390 - val_accuracy: 0.5886\n",
      "Epoch 22/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.9862 - accuracy: 0.7393 - val_loss: 0.7261 - val_accuracy: 0.5886\n",
      "Epoch 23/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.8587 - accuracy: 0.7797 - val_loss: 0.7194 - val_accuracy: 0.5886\n",
      "Epoch 24/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.6552 - accuracy: 0.7853 - val_loss: 0.7408 - val_accuracy: 0.5886\n",
      "Epoch 25/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.6969 - accuracy: 0.8082 - val_loss: 0.7430 - val_accuracy: 0.5886\n",
      "Epoch 26/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.5684 - accuracy: 0.8796 - val_loss: 0.7648 - val_accuracy: 0.5886\n",
      "Epoch 27/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.4806 - accuracy: 0.9168 - val_loss: 0.7850 - val_accuracy: 0.5886\n",
      "Epoch 28/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.4160 - accuracy: 0.9469 - val_loss: 0.7991 - val_accuracy: 0.5886\n",
      "Epoch 29/2000\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.3432 - accuracy: 0.9532 - val_loss: 0.8239 - val_accuracy: 0.5886\n",
      "Epoch 30/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.3562 - accuracy: 0.9556 - val_loss: 0.8094 - val_accuracy: 0.5886\n",
      "Epoch 31/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.6484 - accuracy: 0.9374 - val_loss: 0.7879 - val_accuracy: 0.5886\n",
      "Epoch 32/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.9901 - accuracy: 0.6735 - val_loss: 0.7754 - val_accuracy: 0.4082\n",
      "Epoch 33/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 1.2615 - accuracy: 0.5079 - val_loss: 0.9745 - val_accuracy: 0.4177\n",
      "Epoch 34/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 1.1560 - accuracy: 0.5214 - val_loss: 0.8584 - val_accuracy: 0.5316\n",
      "Epoch 35/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 1.0569 - accuracy: 0.5642 - val_loss: 0.8297 - val_accuracy: 0.4747\n",
      "Epoch 36/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.9732 - accuracy: 0.6109 - val_loss: 0.7915 - val_accuracy: 0.4968\n",
      "Epoch 37/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.9426 - accuracy: 0.6410 - val_loss: 0.7551 - val_accuracy: 0.5728\n",
      "Epoch 38/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.8540 - accuracy: 0.6886 - val_loss: 0.7409 - val_accuracy: 0.5918\n",
      "Epoch 39/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.8319 - accuracy: 0.7401 - val_loss: 0.7192 - val_accuracy: 0.5854\n",
      "Epoch 40/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.7482 - accuracy: 0.7845 - val_loss: 0.7513 - val_accuracy: 0.5854\n",
      "Epoch 41/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.7161 - accuracy: 0.8439 - val_loss: 0.8381 - val_accuracy: 0.5791\n",
      "Epoch 42/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.6069 - accuracy: 0.8803 - val_loss: 0.7437 - val_accuracy: 0.5854\n",
      "Epoch 43/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.5369 - accuracy: 0.9065 - val_loss: 0.7502 - val_accuracy: 0.5886\n",
      "Epoch 44/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.5125 - accuracy: 0.9239 - val_loss: 0.7683 - val_accuracy: 0.5886\n",
      "Epoch 45/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.4974 - accuracy: 0.9160 - val_loss: 0.7844 - val_accuracy: 0.5854\n",
      "Epoch 46/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.5574 - accuracy: 0.9287 - val_loss: 0.7938 - val_accuracy: 0.5918\n",
      "Epoch 47/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.6254 - accuracy: 0.9073 - val_loss: 0.7575 - val_accuracy: 0.5759\n",
      "Epoch 48/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 1.0378 - accuracy: 0.7227 - val_loss: 1.6328 - val_accuracy: 0.4304\n",
      "Epoch 49/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.8095 - accuracy: 0.8146 - val_loss: 2.1893 - val_accuracy: 0.3924\n",
      "Epoch 50/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.6059 - accuracy: 0.8724 - val_loss: 1.3341 - val_accuracy: 0.4209\n",
      "Epoch 51/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.6318 - accuracy: 0.8661 - val_loss: 0.9216 - val_accuracy: 0.4684\n",
      "Epoch 52/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.4838 - accuracy: 0.9295 - val_loss: 0.7890 - val_accuracy: 0.5127\n",
      "Epoch 53/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.4368 - accuracy: 0.9319 - val_loss: 0.7647 - val_accuracy: 0.5443\n",
      "Epoch 54/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.3950 - accuracy: 0.9548 - val_loss: 0.8027 - val_accuracy: 0.5316\n",
      "Epoch 55/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.3110 - accuracy: 0.9580 - val_loss: 0.8402 - val_accuracy: 0.5285\n",
      "Epoch 56/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.3667 - accuracy: 0.9572 - val_loss: 0.8677 - val_accuracy: 0.5127\n",
      "Epoch 57/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.3050 - accuracy: 0.9588 - val_loss: 0.8638 - val_accuracy: 0.5063\n",
      "Epoch 58/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.2809 - accuracy: 0.9628 - val_loss: 0.8830 - val_accuracy: 0.4937\n",
      "Epoch 59/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.2505 - accuracy: 0.9667 - val_loss: 0.9238 - val_accuracy: 0.4747\n",
      "Epoch 60/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.2348 - accuracy: 0.9707 - val_loss: 0.9589 - val_accuracy: 0.4684\n",
      "Epoch 61/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.2777 - accuracy: 0.9643 - val_loss: 0.9900 - val_accuracy: 0.4652\n",
      "Epoch 62/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.2320 - accuracy: 0.9723 - val_loss: 0.9799 - val_accuracy: 0.5063\n",
      "Epoch 63/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.2188 - accuracy: 0.9723 - val_loss: 1.0277 - val_accuracy: 0.5222\n",
      "Epoch 64/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.1771 - accuracy: 0.9754 - val_loss: 1.0478 - val_accuracy: 0.5380\n",
      "Epoch 65/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.2261 - accuracy: 0.9754 - val_loss: 1.0872 - val_accuracy: 0.5190\n",
      "Epoch 66/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.1843 - accuracy: 0.9746 - val_loss: 1.3297 - val_accuracy: 0.4873\n",
      "Epoch 67/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.1384 - accuracy: 0.9826 - val_loss: 1.4234 - val_accuracy: 0.5000\n",
      "Epoch 68/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1860 - accuracy: 0.9802 - val_loss: 1.2523 - val_accuracy: 0.5253\n",
      "Epoch 69/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1240 - accuracy: 0.9818 - val_loss: 1.2277 - val_accuracy: 0.5285\n",
      "Epoch 70/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1361 - accuracy: 0.9810 - val_loss: 1.4117 - val_accuracy: 0.4937\n",
      "Epoch 71/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.1821 - accuracy: 0.9810 - val_loss: 1.8851 - val_accuracy: 0.4557\n",
      "Epoch 72/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.5051 - accuracy: 0.8867 - val_loss: 2.3597 - val_accuracy: 0.4177\n",
      "Epoch 73/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.5481 - accuracy: 0.8423 - val_loss: 1.8578 - val_accuracy: 0.4082\n",
      "Epoch 74/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.3963 - accuracy: 0.8946 - val_loss: 1.8383 - val_accuracy: 0.4051\n",
      "Epoch 75/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.3375 - accuracy: 0.9231 - val_loss: 1.7395 - val_accuracy: 0.4209\n",
      "Epoch 76/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.4043 - accuracy: 0.9120 - val_loss: 1.7933 - val_accuracy: 0.4241\n",
      "Epoch 77/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.3133 - accuracy: 0.9469 - val_loss: 1.9667 - val_accuracy: 0.3576\n",
      "Epoch 78/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.2749 - accuracy: 0.9620 - val_loss: 1.6583 - val_accuracy: 0.4335\n",
      "Epoch 79/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.2261 - accuracy: 0.9715 - val_loss: 1.3843 - val_accuracy: 0.4177\n",
      "Epoch 80/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.2294 - accuracy: 0.9707 - val_loss: 1.3255 - val_accuracy: 0.4335\n",
      "Epoch 81/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.1981 - accuracy: 0.9723 - val_loss: 1.3776 - val_accuracy: 0.4462\n",
      "Epoch 82/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.2055 - accuracy: 0.9723 - val_loss: 1.3720 - val_accuracy: 0.4968\n",
      "Epoch 83/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.1401 - accuracy: 0.9778 - val_loss: 1.7214 - val_accuracy: 0.4937\n",
      "Epoch 84/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1873 - accuracy: 0.9715 - val_loss: 1.7094 - val_accuracy: 0.5222\n",
      "Epoch 85/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.2722 - accuracy: 0.9445 - val_loss: 2.0448 - val_accuracy: 0.2753\n",
      "Epoch 86/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.2298 - accuracy: 0.9540 - val_loss: 1.8118 - val_accuracy: 0.3956\n",
      "Epoch 87/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.2558 - accuracy: 0.9398 - val_loss: 1.9623 - val_accuracy: 0.4209\n",
      "Epoch 88/2000\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.2127 - accuracy: 0.9604 - val_loss: 1.7536 - val_accuracy: 0.5380\n",
      "Epoch 89/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.1775 - accuracy: 0.9612 - val_loss: 1.6276 - val_accuracy: 0.5601\n",
      "Epoch 90/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.1581 - accuracy: 0.9667 - val_loss: 1.5377 - val_accuracy: 0.5348\n",
      "Epoch 91/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.1690 - accuracy: 0.9683 - val_loss: 1.4858 - val_accuracy: 0.5475\n",
      "Epoch 92/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.1657 - accuracy: 0.9691 - val_loss: 1.4385 - val_accuracy: 0.5506\n",
      "Epoch 93/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.1948 - accuracy: 0.9699 - val_loss: 1.5371 - val_accuracy: 0.4905\n",
      "Epoch 94/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.1587 - accuracy: 0.9683 - val_loss: 1.4121 - val_accuracy: 0.5380\n",
      "Epoch 95/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.1716 - accuracy: 0.9739 - val_loss: 1.4305 - val_accuracy: 0.5411\n",
      "Epoch 96/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.1564 - accuracy: 0.9739 - val_loss: 1.4855 - val_accuracy: 0.5190\n",
      "Epoch 97/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.1548 - accuracy: 0.9715 - val_loss: 1.6781 - val_accuracy: 0.5285\n",
      "Epoch 98/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.1460 - accuracy: 0.9731 - val_loss: 1.9354 - val_accuracy: 0.5032\n",
      "Epoch 99/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.1362 - accuracy: 0.9715 - val_loss: 2.1435 - val_accuracy: 0.5063\n",
      "Epoch 100/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.4976 - accuracy: 0.8843 - val_loss: 1.7881 - val_accuracy: 0.5000\n",
      "Epoch 101/2000\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.5155 - accuracy: 0.8415 - val_loss: 1.9909 - val_accuracy: 0.5000\n",
      "Epoch 102/2000\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.5587 - accuracy: 0.8391 - val_loss: 1.8631 - val_accuracy: 0.5759\n",
      "Epoch 103/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.3756 - accuracy: 0.9168 - val_loss: 1.8731 - val_accuracy: 0.4684\n",
      "Epoch 104/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.2732 - accuracy: 0.9350 - val_loss: 1.9971 - val_accuracy: 0.4905\n",
      "Epoch 105/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.2103 - accuracy: 0.9540 - val_loss: 2.0188 - val_accuracy: 0.5063\n",
      "Epoch 106/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.1817 - accuracy: 0.9596 - val_loss: 1.8803 - val_accuracy: 0.5127\n",
      "Epoch 107/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.1729 - accuracy: 0.9683 - val_loss: 1.7374 - val_accuracy: 0.5253\n",
      "Epoch 108/2000\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.1516 - accuracy: 0.9659 - val_loss: 1.7884 - val_accuracy: 0.4968\n",
      "Epoch 109/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.1424 - accuracy: 0.9731 - val_loss: 1.9226 - val_accuracy: 0.5000\n",
      "Epoch 110/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.2091 - accuracy: 0.9628 - val_loss: 1.2628 - val_accuracy: 0.4810\n",
      "Epoch 111/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.5059 - accuracy: 0.8399 - val_loss: 2.2833 - val_accuracy: 0.1962\n",
      "Epoch 112/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.4021 - accuracy: 0.8938 - val_loss: 2.6553 - val_accuracy: 0.3797\n",
      "Epoch 113/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.3565 - accuracy: 0.9303 - val_loss: 2.3151 - val_accuracy: 0.4873\n",
      "Epoch 114/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.3776 - accuracy: 0.9461 - val_loss: 2.1678 - val_accuracy: 0.5127\n",
      "Epoch 115/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.2685 - accuracy: 0.9532 - val_loss: 2.8782 - val_accuracy: 0.4873\n",
      "Epoch 116/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.1895 - accuracy: 0.9604 - val_loss: 1.7034 - val_accuracy: 0.3987\n",
      "Epoch 117/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.2457 - accuracy: 0.9548 - val_loss: 1.5271 - val_accuracy: 0.4051\n",
      "Epoch 118/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.2319 - accuracy: 0.9525 - val_loss: 1.7608 - val_accuracy: 0.4589\n",
      "Epoch 119/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.1499 - accuracy: 0.9667 - val_loss: 3.3402 - val_accuracy: 0.4905\n",
      "Epoch 120/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.1895 - accuracy: 0.9699 - val_loss: 3.9996 - val_accuracy: 0.5728\n",
      "Epoch 121/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.2074 - accuracy: 0.9493 - val_loss: 3.3472 - val_accuracy: 0.5063\n",
      "Epoch 122/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.2653 - accuracy: 0.9350 - val_loss: 3.5890 - val_accuracy: 0.5316\n",
      "Epoch 123/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.2302 - accuracy: 0.9509 - val_loss: 3.9556 - val_accuracy: 0.5380\n",
      "Epoch 124/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1919 - accuracy: 0.9643 - val_loss: 4.8502 - val_accuracy: 0.2816\n",
      "Epoch 125/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.1371 - accuracy: 0.9723 - val_loss: 4.4427 - val_accuracy: 0.4557\n",
      "Epoch 126/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.1316 - accuracy: 0.9731 - val_loss: 4.9821 - val_accuracy: 0.5570\n",
      "Epoch 127/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1624 - accuracy: 0.9683 - val_loss: 5.1096 - val_accuracy: 0.5285\n",
      "Epoch 128/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1806 - accuracy: 0.9715 - val_loss: 4.3791 - val_accuracy: 0.4652\n",
      "Epoch 129/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.1347 - accuracy: 0.9770 - val_loss: 3.6493 - val_accuracy: 0.5475\n",
      "Epoch 130/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.1278 - accuracy: 0.9786 - val_loss: 3.9712 - val_accuracy: 0.5570\n",
      "Epoch 131/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1057 - accuracy: 0.9826 - val_loss: 3.6392 - val_accuracy: 0.5601\n",
      "Epoch 132/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.1187 - accuracy: 0.9826 - val_loss: 3.4087 - val_accuracy: 0.5665\n",
      "Epoch 133/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1127 - accuracy: 0.9818 - val_loss: 3.4793 - val_accuracy: 0.5633\n",
      "Epoch 134/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.1212 - accuracy: 0.9802 - val_loss: 3.5690 - val_accuracy: 0.5570\n",
      "Epoch 135/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.1145 - accuracy: 0.9818 - val_loss: 3.8236 - val_accuracy: 0.5665\n",
      "Epoch 136/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.1097 - accuracy: 0.9842 - val_loss: 3.7757 - val_accuracy: 0.5570\n",
      "Epoch 137/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.1077 - accuracy: 0.9834 - val_loss: 2.9944 - val_accuracy: 0.5570\n",
      "Epoch 138/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.1128 - accuracy: 0.9802 - val_loss: 3.3190 - val_accuracy: 0.5411\n",
      "Epoch 139/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.1259 - accuracy: 0.9810 - val_loss: 3.4092 - val_accuracy: 0.5633\n",
      "Epoch 140/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.1371 - accuracy: 0.9715 - val_loss: 1.3159 - val_accuracy: 0.5538\n",
      "Epoch 141/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.1043 - accuracy: 0.9810 - val_loss: 1.2915 - val_accuracy: 0.5475\n",
      "Epoch 142/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.1155 - accuracy: 0.9826 - val_loss: 1.4044 - val_accuracy: 0.5443\n",
      "Epoch 143/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.0931 - accuracy: 0.9865 - val_loss: 1.9220 - val_accuracy: 0.5791\n",
      "Epoch 144/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.0949 - accuracy: 0.9857 - val_loss: 2.2639 - val_accuracy: 0.5696\n",
      "Epoch 145/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.0932 - accuracy: 0.9842 - val_loss: 2.4825 - val_accuracy: 0.5570\n",
      "Epoch 146/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.1247 - accuracy: 0.9810 - val_loss: 2.4482 - val_accuracy: 0.5285\n",
      "Epoch 147/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.0882 - accuracy: 0.9818 - val_loss: 2.2429 - val_accuracy: 0.5127\n",
      "Epoch 148/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.0979 - accuracy: 0.9834 - val_loss: 2.4501 - val_accuracy: 0.5158\n",
      "Epoch 149/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.0860 - accuracy: 0.9857 - val_loss: 3.2775 - val_accuracy: 0.5380\n",
      "Epoch 150/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.0923 - accuracy: 0.9849 - val_loss: 3.4400 - val_accuracy: 0.5570\n",
      "Epoch 151/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.0773 - accuracy: 0.9873 - val_loss: 3.4633 - val_accuracy: 0.5285\n",
      "Epoch 152/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.0772 - accuracy: 0.9865 - val_loss: 3.4445 - val_accuracy: 0.5222\n",
      "Epoch 153/2000\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.0855 - accuracy: 0.9881 - val_loss: 3.3328 - val_accuracy: 0.5316\n",
      "Epoch 154/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.0898 - accuracy: 0.9873 - val_loss: 3.3326 - val_accuracy: 0.5285\n",
      "Epoch 155/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.0938 - accuracy: 0.9881 - val_loss: 3.4132 - val_accuracy: 0.5158\n",
      "Epoch 156/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.0778 - accuracy: 0.9881 - val_loss: 2.8675 - val_accuracy: 0.4937\n",
      "Epoch 157/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.0735 - accuracy: 0.9889 - val_loss: 2.7872 - val_accuracy: 0.5032\n",
      "Epoch 158/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.0758 - accuracy: 0.9905 - val_loss: 2.8131 - val_accuracy: 0.4937\n",
      "Epoch 159/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.0755 - accuracy: 0.9897 - val_loss: 2.8820 - val_accuracy: 0.4873\n",
      "Epoch 160/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.0786 - accuracy: 0.9865 - val_loss: 3.2108 - val_accuracy: 0.5032\n",
      "Epoch 161/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.0826 - accuracy: 0.9905 - val_loss: 3.4395 - val_accuracy: 0.5032\n",
      "Epoch 162/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.0728 - accuracy: 0.9913 - val_loss: 3.7278 - val_accuracy: 0.5158\n",
      "Epoch 163/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.3324 - accuracy: 0.9810 - val_loss: 7.7340 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 2.1049 - accuracy: 0.4762 - val_loss: 7.6123 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 1.0814 - accuracy: 0.4818 - val_loss: 7.6089 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.9543 - accuracy: 0.5008 - val_loss: 7.6099 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.9097 - accuracy: 0.5460 - val_loss: 7.6099 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.9143 - accuracy: 0.5499 - val_loss: 7.6099 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.8689 - accuracy: 0.5689 - val_loss: 7.6123 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8865 - accuracy: 0.5705 - val_loss: 7.6118 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.8740 - accuracy: 0.5658 - val_loss: 7.6109 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.8398 - accuracy: 0.5689 - val_loss: 7.5332 - val_accuracy: 0.0032\n",
      "Epoch 173/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.8618 - accuracy: 0.5697 - val_loss: 5.8991 - val_accuracy: 0.1424\n",
      "Epoch 174/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.7811 - accuracy: 0.6014 - val_loss: 2.8204 - val_accuracy: 0.4525\n",
      "Epoch 175/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.7711 - accuracy: 0.6117 - val_loss: 1.3806 - val_accuracy: 0.5696\n",
      "Epoch 176/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.7578 - accuracy: 0.6268 - val_loss: 1.0254 - val_accuracy: 0.5886\n",
      "Epoch 177/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7455 - accuracy: 0.6506 - val_loss: 1.0690 - val_accuracy: 0.5886\n",
      "Epoch 178/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7869 - accuracy: 0.6482 - val_loss: 1.1376 - val_accuracy: 0.5823\n",
      "Epoch 179/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.8104 - accuracy: 0.6418 - val_loss: 0.9760 - val_accuracy: 0.5886\n",
      "Epoch 180/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.7600 - accuracy: 0.6696 - val_loss: 1.1633 - val_accuracy: 0.5886\n",
      "Epoch 181/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.7460 - accuracy: 0.7147 - val_loss: 1.4953 - val_accuracy: 0.5854\n",
      "Epoch 182/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7389 - accuracy: 0.7258 - val_loss: 1.5309 - val_accuracy: 0.5823\n",
      "Epoch 183/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.6921 - accuracy: 0.7837 - val_loss: 1.3850 - val_accuracy: 0.5886\n",
      "Epoch 184/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7973 - accuracy: 0.7528 - val_loss: 1.7120 - val_accuracy: 0.5886\n",
      "Epoch 185/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.8758 - accuracy: 0.7155 - val_loss: 1.7211 - val_accuracy: 0.5854\n",
      "Epoch 186/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.8199 - accuracy: 0.7464 - val_loss: 1.7253 - val_accuracy: 0.5854\n",
      "Epoch 187/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7384 - accuracy: 0.7718 - val_loss: 1.6714 - val_accuracy: 0.5886\n",
      "Epoch 188/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.6608 - accuracy: 0.8106 - val_loss: 1.2936 - val_accuracy: 0.5886\n",
      "Epoch 189/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.5539 - accuracy: 0.8542 - val_loss: 1.4712 - val_accuracy: 0.5886\n",
      "Epoch 190/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.5451 - accuracy: 0.8859 - val_loss: 1.3634 - val_accuracy: 0.5886\n",
      "Epoch 191/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.4841 - accuracy: 0.8922 - val_loss: 1.2786 - val_accuracy: 0.5886\n",
      "Epoch 192/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.4721 - accuracy: 0.8978 - val_loss: 1.2439 - val_accuracy: 0.5823\n",
      "Epoch 193/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.4848 - accuracy: 0.9041 - val_loss: 1.7344 - val_accuracy: 0.5918\n",
      "Epoch 194/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.4132 - accuracy: 0.9223 - val_loss: 1.6984 - val_accuracy: 0.5759\n",
      "Epoch 195/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.4327 - accuracy: 0.9176 - val_loss: 1.7947 - val_accuracy: 0.5601\n",
      "Epoch 196/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.4469 - accuracy: 0.9223 - val_loss: 1.7568 - val_accuracy: 0.3671\n",
      "Epoch 197/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.3959 - accuracy: 0.9160 - val_loss: 1.5001 - val_accuracy: 0.5759\n",
      "Epoch 198/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.4195 - accuracy: 0.9223 - val_loss: 1.5282 - val_accuracy: 0.5728\n",
      "Epoch 199/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.3803 - accuracy: 0.9192 - val_loss: 1.5399 - val_accuracy: 0.5791\n",
      "Epoch 200/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.3353 - accuracy: 0.9326 - val_loss: 1.7537 - val_accuracy: 0.5538\n",
      "Epoch 201/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.3163 - accuracy: 0.9358 - val_loss: 1.6388 - val_accuracy: 0.5633\n",
      "Epoch 202/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.5439 - accuracy: 0.8724 - val_loss: 2.0432 - val_accuracy: 0.2975\n",
      "Epoch 203/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.8547 - accuracy: 0.7448 - val_loss: 5.4364 - val_accuracy: 0.4968\n",
      "Epoch 204/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 1.2661 - accuracy: 0.5800 - val_loss: 6.3038 - val_accuracy: 0.4082\n",
      "Epoch 205/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 1.0976 - accuracy: 0.6189 - val_loss: 5.6812 - val_accuracy: 0.3829\n",
      "Epoch 206/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.9814 - accuracy: 0.6577 - val_loss: 4.6843 - val_accuracy: 0.4684\n",
      "Epoch 207/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.9091 - accuracy: 0.7456 - val_loss: 3.6346 - val_accuracy: 0.5158\n",
      "Epoch 208/2000\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 0.9171 - accuracy: 0.7433 - val_loss: 2.3333 - val_accuracy: 0.5411\n",
      "Epoch 209/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.7434 - accuracy: 0.8233 - val_loss: 2.6047 - val_accuracy: 0.5380\n",
      "Epoch 210/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.7465 - accuracy: 0.8209 - val_loss: 2.6136 - val_accuracy: 0.4462\n",
      "Epoch 211/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.6370 - accuracy: 0.8732 - val_loss: 2.1483 - val_accuracy: 0.5633\n",
      "Epoch 212/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.5468 - accuracy: 0.8883 - val_loss: 2.3643 - val_accuracy: 0.4715\n",
      "Epoch 213/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.5971 - accuracy: 0.8700 - val_loss: 2.3425 - val_accuracy: 0.5791\n",
      "Epoch 214/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.4998 - accuracy: 0.8803 - val_loss: 2.7861 - val_accuracy: 0.2627\n",
      "Epoch 215/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.4727 - accuracy: 0.9025 - val_loss: 2.4687 - val_accuracy: 0.5633\n",
      "Epoch 216/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.4376 - accuracy: 0.9192 - val_loss: 2.0190 - val_accuracy: 0.5791\n",
      "Epoch 217/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.4213 - accuracy: 0.9295 - val_loss: 1.6717 - val_accuracy: 0.5601\n",
      "Epoch 218/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.4090 - accuracy: 0.9208 - val_loss: 1.6005 - val_accuracy: 0.5823\n",
      "Epoch 219/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.4848 - accuracy: 0.9136 - val_loss: 1.4576 - val_accuracy: 0.5665\n",
      "Epoch 220/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.5100 - accuracy: 0.9120 - val_loss: 1.4471 - val_accuracy: 0.5570\n",
      "Epoch 221/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.3983 - accuracy: 0.9208 - val_loss: 1.3637 - val_accuracy: 0.5253\n",
      "Epoch 222/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.4353 - accuracy: 0.9271 - val_loss: 1.7213 - val_accuracy: 0.5063\n",
      "Epoch 223/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.4115 - accuracy: 0.9414 - val_loss: 1.8885 - val_accuracy: 0.5285\n",
      "Epoch 224/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.3830 - accuracy: 0.9525 - val_loss: 2.6625 - val_accuracy: 0.5095\n",
      "Epoch 225/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.5029 - accuracy: 0.9469 - val_loss: 3.7228 - val_accuracy: 0.5127\n",
      "Epoch 226/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.3811 - accuracy: 0.9477 - val_loss: 3.6919 - val_accuracy: 0.5127\n",
      "Epoch 227/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.4681 - accuracy: 0.9081 - val_loss: 1.9673 - val_accuracy: 0.4652\n",
      "Epoch 228/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.4136 - accuracy: 0.9176 - val_loss: 1.6321 - val_accuracy: 0.5506\n",
      "Epoch 229/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.3339 - accuracy: 0.9342 - val_loss: 2.0748 - val_accuracy: 0.4747\n",
      "Epoch 230/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.3687 - accuracy: 0.9216 - val_loss: 2.2369 - val_accuracy: 0.4873\n",
      "Epoch 231/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.3463 - accuracy: 0.9168 - val_loss: 1.8645 - val_accuracy: 0.5475\n",
      "Epoch 232/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.3698 - accuracy: 0.9105 - val_loss: 1.6659 - val_accuracy: 0.5633\n",
      "Epoch 233/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.3673 - accuracy: 0.9279 - val_loss: 1.5036 - val_accuracy: 0.5506\n",
      "Epoch 234/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.3263 - accuracy: 0.9342 - val_loss: 1.4838 - val_accuracy: 0.5601\n",
      "Epoch 235/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.3475 - accuracy: 0.9422 - val_loss: 1.7492 - val_accuracy: 0.5380\n",
      "Epoch 236/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.3034 - accuracy: 0.9501 - val_loss: 1.8679 - val_accuracy: 0.4968\n",
      "Epoch 237/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.2994 - accuracy: 0.9525 - val_loss: 1.6750 - val_accuracy: 0.4905\n",
      "Epoch 238/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.2984 - accuracy: 0.9414 - val_loss: 1.6388 - val_accuracy: 0.5095\n",
      "Epoch 239/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.3303 - accuracy: 0.9374 - val_loss: 1.4527 - val_accuracy: 0.5316\n",
      "Epoch 240/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.3774 - accuracy: 0.9374 - val_loss: 1.5369 - val_accuracy: 0.5411\n",
      "Epoch 241/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.3062 - accuracy: 0.9358 - val_loss: 1.7053 - val_accuracy: 0.5665\n",
      "Epoch 242/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.3012 - accuracy: 0.9548 - val_loss: 2.2744 - val_accuracy: 0.4652\n",
      "Epoch 243/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.2977 - accuracy: 0.9501 - val_loss: 2.3117 - val_accuracy: 0.3766\n",
      "Epoch 244/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.2964 - accuracy: 0.9485 - val_loss: 2.5058 - val_accuracy: 0.3956\n",
      "Epoch 245/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.2761 - accuracy: 0.9548 - val_loss: 2.1776 - val_accuracy: 0.4905\n",
      "Epoch 246/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.2808 - accuracy: 0.9628 - val_loss: 2.0833 - val_accuracy: 0.4937\n",
      "Epoch 247/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.2894 - accuracy: 0.9453 - val_loss: 2.1166 - val_accuracy: 0.3956\n",
      "Epoch 248/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.3213 - accuracy: 0.9366 - val_loss: 2.6280 - val_accuracy: 0.3829\n",
      "Epoch 249/2000\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.3097 - accuracy: 0.9501 - val_loss: 2.6110 - val_accuracy: 0.3797\n",
      "Epoch 250/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.3044 - accuracy: 0.9612 - val_loss: 2.7159 - val_accuracy: 0.3892\n",
      "Epoch 251/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.2795 - accuracy: 0.9540 - val_loss: 2.5824 - val_accuracy: 0.4272\n",
      "Epoch 252/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.2662 - accuracy: 0.9525 - val_loss: 2.5899 - val_accuracy: 0.3987\n",
      "Epoch 253/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.2692 - accuracy: 0.9548 - val_loss: 2.5101 - val_accuracy: 0.3987\n",
      "Epoch 254/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.2541 - accuracy: 0.9604 - val_loss: 2.5852 - val_accuracy: 0.4842\n",
      "Epoch 255/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.2540 - accuracy: 0.9628 - val_loss: 3.7598 - val_accuracy: 0.4747\n",
      "Epoch 256/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.2401 - accuracy: 0.9643 - val_loss: 3.8017 - val_accuracy: 0.4304\n",
      "Epoch 257/2000\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 0.2227 - accuracy: 0.9643 - val_loss: 4.0930 - val_accuracy: 0.4620\n",
      "Epoch 258/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.2393 - accuracy: 0.9683 - val_loss: 3.9091 - val_accuracy: 0.2120\n",
      "Epoch 259/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.2399 - accuracy: 0.9643 - val_loss: 3.5381 - val_accuracy: 0.3006\n",
      "Epoch 260/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.2245 - accuracy: 0.9683 - val_loss: 3.8946 - val_accuracy: 0.4494\n",
      "Epoch 261/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.2124 - accuracy: 0.9691 - val_loss: 4.0457 - val_accuracy: 0.3101\n",
      "Epoch 262/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.2208 - accuracy: 0.9643 - val_loss: 4.4626 - val_accuracy: 0.3608\n",
      "Epoch 263/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 1.6923 - accuracy: 0.7504 - val_loss: 17.0530 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 1.3947 - accuracy: 0.4477 - val_loss: 7.5679 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.9895 - accuracy: 0.4731 - val_loss: 7.5689 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.9550 - accuracy: 0.4849 - val_loss: 7.5637 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.9058 - accuracy: 0.4739 - val_loss: 7.5632 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.8417 - accuracy: 0.5182 - val_loss: 7.5658 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.8500 - accuracy: 0.5317 - val_loss: 7.5627 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.8332 - accuracy: 0.5127 - val_loss: 7.5622 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.8345 - accuracy: 0.5333 - val_loss: 7.5627 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.8240 - accuracy: 0.5531 - val_loss: 7.5616 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.8425 - accuracy: 0.5301 - val_loss: 7.5658 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8124 - accuracy: 0.5420 - val_loss: 7.5652 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/2000\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.8103 - accuracy: 0.5396 - val_loss: 7.5575 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8434 - accuracy: 0.5349 - val_loss: 7.5591 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.8055 - accuracy: 0.5404 - val_loss: 7.5278 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7752 - accuracy: 0.5539 - val_loss: 7.3561 - val_accuracy: 0.0063\n",
      "Epoch 279/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.7971 - accuracy: 0.5523 - val_loss: 6.2342 - val_accuracy: 0.0981\n",
      "Epoch 280/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.7725 - accuracy: 0.5372 - val_loss: 4.3979 - val_accuracy: 0.2120\n",
      "Epoch 281/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7796 - accuracy: 0.5380 - val_loss: 3.2126 - val_accuracy: 0.3070\n",
      "Epoch 282/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7849 - accuracy: 0.5468 - val_loss: 1.7266 - val_accuracy: 0.3924\n",
      "Epoch 283/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7763 - accuracy: 0.5658 - val_loss: 1.1715 - val_accuracy: 0.4019\n",
      "Epoch 284/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.7926 - accuracy: 0.5634 - val_loss: 1.0770 - val_accuracy: 0.4430\n",
      "Epoch 285/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7677 - accuracy: 0.5483 - val_loss: 0.9796 - val_accuracy: 0.4335\n",
      "Epoch 286/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7964 - accuracy: 0.5674 - val_loss: 0.9726 - val_accuracy: 0.4684\n",
      "Epoch 287/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.7602 - accuracy: 0.5610 - val_loss: 1.3778 - val_accuracy: 0.4747\n",
      "Epoch 288/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.7433 - accuracy: 0.5745 - val_loss: 1.6041 - val_accuracy: 0.0380\n",
      "Epoch 289/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.7370 - accuracy: 0.5769 - val_loss: 1.4791 - val_accuracy: 0.4715\n",
      "Epoch 290/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7458 - accuracy: 0.5832 - val_loss: 1.2435 - val_accuracy: 0.5000\n",
      "Epoch 291/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.7657 - accuracy: 0.5943 - val_loss: 1.1053 - val_accuracy: 0.4810\n",
      "Epoch 292/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.7477 - accuracy: 0.6022 - val_loss: 0.9935 - val_accuracy: 0.4620\n",
      "Epoch 293/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.7431 - accuracy: 0.6086 - val_loss: 0.9023 - val_accuracy: 0.4968\n",
      "Epoch 294/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7145 - accuracy: 0.6109 - val_loss: 0.8366 - val_accuracy: 0.5127\n",
      "Epoch 295/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7520 - accuracy: 0.6252 - val_loss: 0.8060 - val_accuracy: 0.4335\n",
      "Epoch 296/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.7014 - accuracy: 0.6339 - val_loss: 1.0942 - val_accuracy: 0.4209\n",
      "Epoch 297/2000\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.7696 - accuracy: 0.6315 - val_loss: 1.5492 - val_accuracy: 0.4114\n",
      "Epoch 298/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.8178 - accuracy: 0.5571 - val_loss: 1.8019 - val_accuracy: 0.3639\n",
      "Epoch 299/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.8883 - accuracy: 0.5689 - val_loss: 1.5348 - val_accuracy: 0.3956\n",
      "Epoch 300/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.8390 - accuracy: 0.5705 - val_loss: 1.3756 - val_accuracy: 0.4367\n",
      "Epoch 301/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.9159 - accuracy: 0.5515 - val_loss: 1.4060 - val_accuracy: 0.4905\n",
      "Epoch 302/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8676 - accuracy: 0.5872 - val_loss: 1.7818 - val_accuracy: 0.3354\n",
      "Epoch 303/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7979 - accuracy: 0.5872 - val_loss: 1.5905 - val_accuracy: 0.2595\n",
      "Epoch 304/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7901 - accuracy: 0.5927 - val_loss: 1.5394 - val_accuracy: 0.4494\n",
      "Epoch 305/2000\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.7925 - accuracy: 0.6101 - val_loss: 1.8894 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.7717 - accuracy: 0.6189 - val_loss: 1.7791 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7494 - accuracy: 0.6331 - val_loss: 1.9642 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.7440 - accuracy: 0.6490 - val_loss: 2.2069 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.7262 - accuracy: 0.6434 - val_loss: 1.9525 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/2000\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.7313 - accuracy: 0.6624 - val_loss: 1.8158 - val_accuracy: 0.4652\n",
      "Epoch 311/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7067 - accuracy: 0.6616 - val_loss: 1.5462 - val_accuracy: 0.5158\n",
      "Epoch 312/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.6979 - accuracy: 0.6648 - val_loss: 1.4663 - val_accuracy: 0.5253\n",
      "Epoch 313/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.6693 - accuracy: 0.6854 - val_loss: 1.3866 - val_accuracy: 0.5063\n",
      "Epoch 314/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.7020 - accuracy: 0.7036 - val_loss: 1.1893 - val_accuracy: 0.5791\n",
      "Epoch 315/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.7496 - accuracy: 0.6395 - val_loss: 1.1030 - val_accuracy: 0.5823\n",
      "Epoch 316/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7112 - accuracy: 0.6933 - val_loss: 1.8388 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.6658 - accuracy: 0.7108 - val_loss: 2.5283 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.6316 - accuracy: 0.7290 - val_loss: 2.1588 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.6318 - accuracy: 0.7290 - val_loss: 2.1133 - val_accuracy: 0.2943\n",
      "Epoch 320/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6101 - accuracy: 0.7322 - val_loss: 2.0879 - val_accuracy: 0.4367\n",
      "Epoch 321/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.6152 - accuracy: 0.7567 - val_loss: 2.1383 - val_accuracy: 0.4209\n",
      "Epoch 322/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.6050 - accuracy: 0.7433 - val_loss: 1.9052 - val_accuracy: 0.4905\n",
      "Epoch 323/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.5929 - accuracy: 0.7559 - val_loss: 2.0982 - val_accuracy: 0.4304\n",
      "Epoch 324/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.5633 - accuracy: 0.7670 - val_loss: 1.6047 - val_accuracy: 0.4810\n",
      "Epoch 325/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.5210 - accuracy: 0.7884 - val_loss: 1.5204 - val_accuracy: 0.4557\n",
      "Epoch 326/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.5138 - accuracy: 0.8138 - val_loss: 1.8801 - val_accuracy: 0.4082\n",
      "Epoch 327/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.5304 - accuracy: 0.7964 - val_loss: 2.3162 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.5347 - accuracy: 0.8043 - val_loss: 2.4745 - val_accuracy: 0.0380\n",
      "Epoch 329/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.4782 - accuracy: 0.8304 - val_loss: 2.2834 - val_accuracy: 0.0190\n",
      "Epoch 330/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.5299 - accuracy: 0.8122 - val_loss: 2.2897 - val_accuracy: 0.4430\n",
      "Epoch 331/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.6419 - accuracy: 0.7322 - val_loss: 2.1327 - val_accuracy: 0.4525\n",
      "Epoch 332/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.6324 - accuracy: 0.7385 - val_loss: 2.4363 - val_accuracy: 0.3766\n",
      "Epoch 333/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.6117 - accuracy: 0.7567 - val_loss: 1.7845 - val_accuracy: 0.4589\n",
      "Epoch 334/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.5417 - accuracy: 0.7956 - val_loss: 1.8894 - val_accuracy: 0.3101\n",
      "Epoch 335/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.4752 - accuracy: 0.8201 - val_loss: 2.0967 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.4452 - accuracy: 0.8415 - val_loss: 2.6482 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.3951 - accuracy: 0.8669 - val_loss: 2.1644 - val_accuracy: 0.1076\n",
      "Epoch 338/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.4311 - accuracy: 0.8526 - val_loss: 1.8764 - val_accuracy: 0.4462\n",
      "Epoch 339/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.5048 - accuracy: 0.8098 - val_loss: 1.4497 - val_accuracy: 0.5538\n",
      "Epoch 340/2000\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.3985 - accuracy: 0.8708 - val_loss: 1.2470 - val_accuracy: 0.5601\n",
      "Epoch 341/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.3629 - accuracy: 0.8954 - val_loss: 1.8446 - val_accuracy: 0.1424\n",
      "Epoch 342/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.3843 - accuracy: 0.8732 - val_loss: 2.7068 - val_accuracy: 0.1804\n",
      "Epoch 343/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.4431 - accuracy: 0.8685 - val_loss: 2.9812 - val_accuracy: 0.1044\n",
      "Epoch 344/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.4086 - accuracy: 0.8740 - val_loss: 3.1890 - val_accuracy: 0.1266\n",
      "Epoch 345/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.3871 - accuracy: 0.8875 - val_loss: 2.9811 - val_accuracy: 0.3196\n",
      "Epoch 346/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.3371 - accuracy: 0.9231 - val_loss: 2.8617 - val_accuracy: 0.3924\n",
      "Epoch 347/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.3341 - accuracy: 0.9128 - val_loss: 2.7343 - val_accuracy: 0.5190\n",
      "Epoch 348/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.2491 - accuracy: 0.9350 - val_loss: 2.4619 - val_accuracy: 0.4810\n",
      "Epoch 349/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.2089 - accuracy: 0.9509 - val_loss: 2.6418 - val_accuracy: 0.3703\n",
      "Epoch 350/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.3670 - accuracy: 0.9041 - val_loss: 2.7225 - val_accuracy: 0.3354\n",
      "Epoch 351/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.4396 - accuracy: 0.9049 - val_loss: 3.2895 - val_accuracy: 0.5095\n",
      "Epoch 352/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.5670 - accuracy: 0.7662 - val_loss: 2.9376 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.9066 - accuracy: 0.5174 - val_loss: 2.8851 - val_accuracy: 0.0348\n",
      "Epoch 354/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8453 - accuracy: 0.5222 - val_loss: 2.7077 - val_accuracy: 0.3386\n",
      "Epoch 355/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.9353 - accuracy: 0.5325 - val_loss: 2.8727 - val_accuracy: 0.3418\n",
      "Epoch 356/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8829 - accuracy: 0.5261 - val_loss: 2.5299 - val_accuracy: 0.4652\n",
      "Epoch 357/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8586 - accuracy: 0.5261 - val_loss: 2.3693 - val_accuracy: 0.5095\n",
      "Epoch 358/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.8502 - accuracy: 0.5269 - val_loss: 2.2637 - val_accuracy: 0.4747\n",
      "Epoch 359/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.8530 - accuracy: 0.5285 - val_loss: 1.9528 - val_accuracy: 0.5570\n",
      "Epoch 360/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.8702 - accuracy: 0.5309 - val_loss: 1.7090 - val_accuracy: 0.5728\n",
      "Epoch 361/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.8385 - accuracy: 0.5309 - val_loss: 1.4490 - val_accuracy: 0.5759\n",
      "Epoch 362/2000\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.8579 - accuracy: 0.5277 - val_loss: 1.1787 - val_accuracy: 0.5791\n",
      "Epoch 363/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8233 - accuracy: 0.5309 - val_loss: 1.0249 - val_accuracy: 0.5633\n",
      "Epoch 364/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.8193 - accuracy: 0.5396 - val_loss: 1.2934 - val_accuracy: 0.0791\n",
      "Epoch 365/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8334 - accuracy: 0.5396 - val_loss: 1.2747 - val_accuracy: 0.0443\n",
      "Epoch 366/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.8722 - accuracy: 0.5412 - val_loss: 1.1326 - val_accuracy: 0.3924\n",
      "Epoch 367/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.8342 - accuracy: 0.5341 - val_loss: 1.3483 - val_accuracy: 0.5633\n",
      "Epoch 368/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.8464 - accuracy: 0.5436 - val_loss: 1.5772 - val_accuracy: 0.5222\n",
      "Epoch 369/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.8577 - accuracy: 0.5531 - val_loss: 1.4321 - val_accuracy: 0.5285\n",
      "Epoch 370/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.8577 - accuracy: 0.5531 - val_loss: 1.8797 - val_accuracy: 0.0190\n",
      "Epoch 371/2000\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.8381 - accuracy: 0.5666 - val_loss: 1.6458 - val_accuracy: 0.4304\n",
      "Epoch 372/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.8478 - accuracy: 0.5745 - val_loss: 1.6809 - val_accuracy: 0.4304\n",
      "Epoch 373/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8012 - accuracy: 0.5832 - val_loss: 1.8883 - val_accuracy: 0.0348\n",
      "Epoch 374/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7760 - accuracy: 0.5967 - val_loss: 1.7154 - val_accuracy: 0.4399\n",
      "Epoch 375/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.7767 - accuracy: 0.6014 - val_loss: 1.5565 - val_accuracy: 0.5127\n",
      "Epoch 376/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.7470 - accuracy: 0.6403 - val_loss: 1.5465 - val_accuracy: 0.2943\n",
      "Epoch 377/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7984 - accuracy: 0.6212 - val_loss: 1.2106 - val_accuracy: 0.4905\n",
      "Epoch 378/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.8287 - accuracy: 0.6268 - val_loss: 1.7458 - val_accuracy: 0.3513\n",
      "Epoch 379/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.8608 - accuracy: 0.5895 - val_loss: 2.5812 - val_accuracy: 0.0190\n",
      "Epoch 380/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.9107 - accuracy: 0.6220 - val_loss: 2.3954 - val_accuracy: 0.0633\n",
      "Epoch 381/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8484 - accuracy: 0.6537 - val_loss: 2.5623 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.8254 - accuracy: 0.6648 - val_loss: 2.4703 - val_accuracy: 0.0190\n",
      "Epoch 383/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.7814 - accuracy: 0.6815 - val_loss: 2.1891 - val_accuracy: 0.3703\n",
      "Epoch 384/2000\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.7724 - accuracy: 0.6981 - val_loss: 2.0708 - val_accuracy: 0.4715\n",
      "Epoch 385/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.7469 - accuracy: 0.7021 - val_loss: 2.0978 - val_accuracy: 0.5095\n",
      "Epoch 386/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7233 - accuracy: 0.7298 - val_loss: 2.3325 - val_accuracy: 0.0380\n",
      "Epoch 387/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7171 - accuracy: 0.7266 - val_loss: 2.5144 - val_accuracy: 0.0222\n",
      "Epoch 388/2000\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.7009 - accuracy: 0.7472 - val_loss: 2.6490 - val_accuracy: 0.0222\n",
      "Epoch 389/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.6720 - accuracy: 0.7678 - val_loss: 2.1626 - val_accuracy: 0.4209\n",
      "Epoch 390/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.6799 - accuracy: 0.7559 - val_loss: 1.9379 - val_accuracy: 0.3987\n",
      "Epoch 391/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.6905 - accuracy: 0.7567 - val_loss: 2.8206 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.6927 - accuracy: 0.7567 - val_loss: 2.0725 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.7427 - accuracy: 0.7409 - val_loss: 2.8407 - val_accuracy: 0.0032\n",
      "Epoch 394/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7540 - accuracy: 0.7441 - val_loss: 1.9938 - val_accuracy: 0.3038\n",
      "Epoch 395/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.6951 - accuracy: 0.7219 - val_loss: 2.0005 - val_accuracy: 0.0949\n",
      "Epoch 396/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.7027 - accuracy: 0.7417 - val_loss: 1.9551 - val_accuracy: 0.3481\n",
      "Epoch 397/2000\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.7041 - accuracy: 0.7607 - val_loss: 2.1154 - val_accuracy: 0.1930\n",
      "Epoch 398/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.7227 - accuracy: 0.7464 - val_loss: 2.3210 - val_accuracy: 0.0633\n",
      "Epoch 399/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.6615 - accuracy: 0.7750 - val_loss: 1.9957 - val_accuracy: 0.4146\n",
      "Epoch 400/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7352 - accuracy: 0.7655 - val_loss: 2.6890 - val_accuracy: 0.0032\n",
      "Epoch 401/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.7802 - accuracy: 0.7520 - val_loss: 2.3817 - val_accuracy: 0.1582\n",
      "Epoch 402/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.8608 - accuracy: 0.7029 - val_loss: 2.4196 - val_accuracy: 0.3766\n",
      "Epoch 403/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.8716 - accuracy: 0.6759 - val_loss: 2.7731 - val_accuracy: 0.1487\n",
      "Epoch 404/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.8001 - accuracy: 0.7242 - val_loss: 3.0044 - val_accuracy: 0.0791\n",
      "Epoch 405/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.7189 - accuracy: 0.7615 - val_loss: 2.7138 - val_accuracy: 0.1994\n",
      "Epoch 406/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.6484 - accuracy: 0.7908 - val_loss: 3.0586 - val_accuracy: 0.1835\n",
      "Epoch 407/2000\n",
      "10/10 [==============================] - 4s 381ms/step - loss: 0.6449 - accuracy: 0.7995 - val_loss: 2.7615 - val_accuracy: 0.4177\n",
      "Epoch 408/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.8524 - accuracy: 0.7322 - val_loss: 11.6190 - val_accuracy: 0.1962\n",
      "Epoch 409/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.9140 - accuracy: 0.6823 - val_loss: 11.7088 - val_accuracy: 0.2184\n",
      "Epoch 410/2000\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 0.8073 - accuracy: 0.6823 - val_loss: 9.0412 - val_accuracy: 0.3228\n",
      "Epoch 411/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.8246 - accuracy: 0.6886 - val_loss: 6.9567 - val_accuracy: 0.4114\n",
      "Epoch 412/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.7606 - accuracy: 0.7306 - val_loss: 4.6113 - val_accuracy: 0.5032\n",
      "Epoch 413/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7521 - accuracy: 0.7615 - val_loss: 4.7766 - val_accuracy: 0.4810\n",
      "Epoch 414/2000\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.6601 - accuracy: 0.7773 - val_loss: 3.5197 - val_accuracy: 0.3734\n",
      "Epoch 415/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.6311 - accuracy: 0.8051 - val_loss: 3.4433 - val_accuracy: 0.4209\n",
      "Epoch 416/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.6665 - accuracy: 0.7813 - val_loss: 3.3265 - val_accuracy: 0.4114\n",
      "Epoch 417/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.6393 - accuracy: 0.7726 - val_loss: 3.2280 - val_accuracy: 0.4051\n",
      "Epoch 418/2000\n",
      "10/10 [==============================] - 4s 417ms/step - loss: 0.6067 - accuracy: 0.8074 - val_loss: 3.3994 - val_accuracy: 0.4082\n",
      "Epoch 419/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.5676 - accuracy: 0.8154 - val_loss: 4.7050 - val_accuracy: 0.2690\n",
      "Epoch 420/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.5853 - accuracy: 0.8217 - val_loss: 3.8672 - val_accuracy: 0.2468\n",
      "Epoch 421/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.5702 - accuracy: 0.8146 - val_loss: 4.2609 - val_accuracy: 0.2627\n",
      "Epoch 422/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.4925 - accuracy: 0.8637 - val_loss: 5.0618 - val_accuracy: 0.3291\n",
      "Epoch 423/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.6311 - accuracy: 0.7670 - val_loss: 6.1514 - val_accuracy: 0.5285\n",
      "Epoch 424/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.8647 - accuracy: 0.6030 - val_loss: 3.2823 - val_accuracy: 0.4177\n",
      "Epoch 425/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8540 - accuracy: 0.6149 - val_loss: 2.5299 - val_accuracy: 0.1456\n",
      "Epoch 426/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7608 - accuracy: 0.6569 - val_loss: 3.2145 - val_accuracy: 0.0348\n",
      "Epoch 427/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.7508 - accuracy: 0.6767 - val_loss: 2.7591 - val_accuracy: 0.1297\n",
      "Epoch 428/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.6869 - accuracy: 0.7195 - val_loss: 2.5054 - val_accuracy: 0.2025\n",
      "Epoch 429/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.6480 - accuracy: 0.7655 - val_loss: 2.8121 - val_accuracy: 0.0506\n",
      "Epoch 430/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.6412 - accuracy: 0.7789 - val_loss: 3.0744 - val_accuracy: 0.1962\n",
      "Epoch 431/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.6343 - accuracy: 0.7956 - val_loss: 5.9779 - val_accuracy: 0.1234\n",
      "Epoch 432/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.6264 - accuracy: 0.8122 - val_loss: 3.5459 - val_accuracy: 0.2025\n",
      "Epoch 433/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.5364 - accuracy: 0.8455 - val_loss: 3.5458 - val_accuracy: 0.1108\n",
      "Epoch 434/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.5210 - accuracy: 0.8542 - val_loss: 4.1925 - val_accuracy: 0.0380\n",
      "Epoch 435/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.5484 - accuracy: 0.8526 - val_loss: 8.0582 - val_accuracy: 0.0443\n",
      "Epoch 436/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6182 - accuracy: 0.8043 - val_loss: 7.2602 - val_accuracy: 0.0886\n",
      "Epoch 437/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.9037 - accuracy: 0.6418 - val_loss: 7.5169 - val_accuracy: 0.0222\n",
      "Epoch 438/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.9531 - accuracy: 0.6268 - val_loss: 7.6771 - val_accuracy: 0.0854\n",
      "Epoch 439/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.9034 - accuracy: 0.6410 - val_loss: 6.6826 - val_accuracy: 0.1424\n",
      "Epoch 440/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.8592 - accuracy: 0.6743 - val_loss: 4.7523 - val_accuracy: 0.3196\n",
      "Epoch 441/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.8523 - accuracy: 0.6926 - val_loss: 3.1202 - val_accuracy: 0.4778\n",
      "Epoch 442/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.8223 - accuracy: 0.7124 - val_loss: 3.4536 - val_accuracy: 0.0158\n",
      "Epoch 443/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7751 - accuracy: 0.7298 - val_loss: 2.4763 - val_accuracy: 0.1930\n",
      "Epoch 444/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.7619 - accuracy: 0.7314 - val_loss: 1.9361 - val_accuracy: 0.4367\n",
      "Epoch 445/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7444 - accuracy: 0.7338 - val_loss: 2.6009 - val_accuracy: 0.3418\n",
      "Epoch 446/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.6852 - accuracy: 0.7488 - val_loss: 3.2984 - val_accuracy: 0.4494\n",
      "Epoch 447/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.8438 - accuracy: 0.7029 - val_loss: 1.8061 - val_accuracy: 0.5475\n",
      "Epoch 448/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.8433 - accuracy: 0.6918 - val_loss: 2.4375 - val_accuracy: 0.3228\n",
      "Epoch 449/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.7767 - accuracy: 0.7369 - val_loss: 2.7567 - val_accuracy: 0.2184\n",
      "Epoch 450/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.7344 - accuracy: 0.7781 - val_loss: 2.6200 - val_accuracy: 0.1424\n",
      "Epoch 451/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.6847 - accuracy: 0.7948 - val_loss: 2.6111 - val_accuracy: 0.1234\n",
      "Epoch 452/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.7452 - accuracy: 0.8035 - val_loss: 2.2203 - val_accuracy: 0.0728\n",
      "Epoch 453/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.6796 - accuracy: 0.8090 - val_loss: 1.9786 - val_accuracy: 0.2310\n",
      "Epoch 454/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6798 - accuracy: 0.8288 - val_loss: 1.5752 - val_accuracy: 0.5032\n",
      "Epoch 455/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.6466 - accuracy: 0.8471 - val_loss: 2.1672 - val_accuracy: 0.2405\n",
      "Epoch 456/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.5615 - accuracy: 0.8653 - val_loss: 2.0738 - val_accuracy: 0.1171\n",
      "Epoch 457/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.5787 - accuracy: 0.8740 - val_loss: 2.0025 - val_accuracy: 0.2247\n",
      "Epoch 458/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.6353 - accuracy: 0.8645 - val_loss: 2.2307 - val_accuracy: 0.2658\n",
      "Epoch 459/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.5518 - accuracy: 0.8550 - val_loss: 4.7244 - val_accuracy: 0.1171\n",
      "Epoch 460/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.5496 - accuracy: 0.8597 - val_loss: 6.0300 - val_accuracy: 0.1772\n",
      "Epoch 461/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.5199 - accuracy: 0.8360 - val_loss: 3.4475 - val_accuracy: 0.5443\n",
      "Epoch 462/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.5231 - accuracy: 0.8566 - val_loss: 6.1424 - val_accuracy: 0.1741\n",
      "Epoch 463/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.4540 - accuracy: 0.8827 - val_loss: 5.4040 - val_accuracy: 0.2184\n",
      "Epoch 464/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.5316 - accuracy: 0.8463 - val_loss: 6.4427 - val_accuracy: 0.1994\n",
      "Epoch 465/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.5113 - accuracy: 0.8653 - val_loss: 8.1184 - val_accuracy: 0.2342\n",
      "Epoch 466/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.4983 - accuracy: 0.8566 - val_loss: 7.0557 - val_accuracy: 0.4525\n",
      "Epoch 467/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.4791 - accuracy: 0.8566 - val_loss: 6.0985 - val_accuracy: 0.4177\n",
      "Epoch 468/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.4526 - accuracy: 0.8906 - val_loss: 8.7684 - val_accuracy: 0.4051\n",
      "Epoch 469/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.4048 - accuracy: 0.8883 - val_loss: 9.2113 - val_accuracy: 0.4209\n",
      "Epoch 470/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.8377 - accuracy: 0.6331 - val_loss: 0.8575 - val_accuracy: 0.5854\n",
      "Epoch 471/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.9408 - accuracy: 0.5238 - val_loss: 0.9804 - val_accuracy: 0.5791\n",
      "Epoch 472/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.9866 - accuracy: 0.5206 - val_loss: 1.0552 - val_accuracy: 0.5791\n",
      "Epoch 473/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.9573 - accuracy: 0.5309 - val_loss: 1.2244 - val_accuracy: 0.5791\n",
      "Epoch 474/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.9265 - accuracy: 0.5190 - val_loss: 1.8861 - val_accuracy: 0.0032\n",
      "Epoch 475/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.8838 - accuracy: 0.5301 - val_loss: 2.0500 - val_accuracy: 0.0000e+00\n",
      "Epoch 476/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.9238 - accuracy: 0.5309 - val_loss: 2.4545 - val_accuracy: 0.0000e+00\n",
      "Epoch 477/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.8904 - accuracy: 0.5372 - val_loss: 2.2102 - val_accuracy: 0.0063\n",
      "Epoch 478/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.8709 - accuracy: 0.5349 - val_loss: 2.4672 - val_accuracy: 0.0000e+00\n",
      "Epoch 479/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.8588 - accuracy: 0.5254 - val_loss: 2.5235 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.8618 - accuracy: 0.5388 - val_loss: 2.4472 - val_accuracy: 0.0000e+00\n",
      "Epoch 481/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.8561 - accuracy: 0.5507 - val_loss: 2.4862 - val_accuracy: 0.0063\n",
      "Epoch 482/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.8454 - accuracy: 0.5365 - val_loss: 2.5119 - val_accuracy: 0.0127\n",
      "Epoch 483/2000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.9136 - accuracy: 0.5317 - val_loss: 2.4687 - val_accuracy: 0.0000e+00\n",
      "Epoch 484/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.8722 - accuracy: 0.5761 - val_loss: 2.5492 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 1.0769 - accuracy: 0.5325 - val_loss: 3.6011 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 1.0044 - accuracy: 0.5230 - val_loss: 4.1893 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.9508 - accuracy: 0.5277 - val_loss: 4.0421 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.9375 - accuracy: 0.5261 - val_loss: 3.8152 - val_accuracy: 0.0063\n",
      "Epoch 489/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.9545 - accuracy: 0.5158 - val_loss: 4.2990 - val_accuracy: 0.0000e+00\n",
      "Epoch 490/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.9235 - accuracy: 0.5380 - val_loss: 4.1070 - val_accuracy: 0.0000e+00\n",
      "Epoch 491/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.9807 - accuracy: 0.5222 - val_loss: 3.7071 - val_accuracy: 0.0000e+00\n",
      "Epoch 492/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.9278 - accuracy: 0.5396 - val_loss: 3.3338 - val_accuracy: 0.0000e+00\n",
      "Epoch 493/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.9415 - accuracy: 0.5491 - val_loss: 3.1374 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.9184 - accuracy: 0.5571 - val_loss: 3.3476 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.9047 - accuracy: 0.5396 - val_loss: 3.5078 - val_accuracy: 0.0000e+00\n",
      "Epoch 496/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.8548 - accuracy: 0.5634 - val_loss: 3.4834 - val_accuracy: 0.0000e+00\n",
      "Epoch 497/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.9115 - accuracy: 0.5626 - val_loss: 3.4414 - val_accuracy: 0.0000e+00\n",
      "Epoch 498/2000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.8522 - accuracy: 0.5721 - val_loss: 3.1198 - val_accuracy: 0.0127\n",
      "Epoch 499/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.8105 - accuracy: 0.5967 - val_loss: 2.7219 - val_accuracy: 0.0222\n",
      "Epoch 500/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.8243 - accuracy: 0.6157 - val_loss: 2.6021 - val_accuracy: 0.3892\n",
      "Epoch 501/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.8536 - accuracy: 0.5983 - val_loss: 2.3700 - val_accuracy: 0.5886\n",
      "Epoch 502/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7989 - accuracy: 0.6228 - val_loss: 2.0797 - val_accuracy: 0.5886\n",
      "Epoch 503/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.8586 - accuracy: 0.5959 - val_loss: 2.2587 - val_accuracy: 0.3481\n",
      "Epoch 504/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.8060 - accuracy: 0.6252 - val_loss: 2.3063 - val_accuracy: 0.1234\n",
      "Epoch 505/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7680 - accuracy: 0.6521 - val_loss: 2.3359 - val_accuracy: 0.3671\n",
      "Epoch 506/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7791 - accuracy: 0.6482 - val_loss: 2.5316 - val_accuracy: 0.0000e+00\n",
      "Epoch 507/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7634 - accuracy: 0.6656 - val_loss: 2.7066 - val_accuracy: 0.0000e+00\n",
      "Epoch 508/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.7392 - accuracy: 0.7036 - val_loss: 3.2283 - val_accuracy: 0.0032\n",
      "Epoch 509/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.9095 - accuracy: 0.6807 - val_loss: 2.9546 - val_accuracy: 0.0000e+00\n",
      "Epoch 510/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 1.0193 - accuracy: 0.5618 - val_loss: 3.9973 - val_accuracy: 0.0000e+00\n",
      "Epoch 511/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 1.0573 - accuracy: 0.5277 - val_loss: 4.4895 - val_accuracy: 0.0000e+00\n",
      "Epoch 512/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.9672 - accuracy: 0.5515 - val_loss: 3.8948 - val_accuracy: 0.0000e+00\n",
      "Epoch 513/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.8583 - accuracy: 0.5396 - val_loss: 3.5020 - val_accuracy: 0.0063\n",
      "Epoch 514/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.8784 - accuracy: 0.5254 - val_loss: 2.9895 - val_accuracy: 0.0000e+00\n",
      "Epoch 515/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.8101 - accuracy: 0.5293 - val_loss: 2.7833 - val_accuracy: 0.0000e+00\n",
      "Epoch 516/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.9151 - accuracy: 0.5317 - val_loss: 2.4913 - val_accuracy: 0.1361\n",
      "Epoch 517/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.8239 - accuracy: 0.5285 - val_loss: 2.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 518/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.8338 - accuracy: 0.5341 - val_loss: 2.5918 - val_accuracy: 0.0000e+00\n",
      "Epoch 519/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8090 - accuracy: 0.5452 - val_loss: 2.4641 - val_accuracy: 0.0000e+00\n",
      "Epoch 520/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7909 - accuracy: 0.5444 - val_loss: 2.4783 - val_accuracy: 0.0000e+00\n",
      "Epoch 521/2000\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.8400 - accuracy: 0.5491 - val_loss: 2.5349 - val_accuracy: 0.0000e+00\n",
      "Epoch 522/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8493 - accuracy: 0.5539 - val_loss: 2.6441 - val_accuracy: 0.0000e+00\n",
      "Epoch 523/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8034 - accuracy: 0.5483 - val_loss: 2.3435 - val_accuracy: 0.0000e+00\n",
      "Epoch 524/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7953 - accuracy: 0.5563 - val_loss: 2.2943 - val_accuracy: 0.0000e+00\n",
      "Epoch 525/2000\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.7750 - accuracy: 0.5943 - val_loss: 2.3028 - val_accuracy: 0.0000e+00\n",
      "Epoch 526/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.7816 - accuracy: 0.6062 - val_loss: 2.2423 - val_accuracy: 0.0000e+00\n",
      "Epoch 527/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.8181 - accuracy: 0.5975 - val_loss: 2.2799 - val_accuracy: 0.2943\n",
      "Epoch 528/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.8230 - accuracy: 0.5087 - val_loss: 2.3649 - val_accuracy: 0.5886\n",
      "Epoch 529/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.7965 - accuracy: 0.5238 - val_loss: 2.5396 - val_accuracy: 0.5886\n",
      "Epoch 530/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.8060 - accuracy: 0.5261 - val_loss: 2.4948 - val_accuracy: 0.5791\n",
      "Epoch 531/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7858 - accuracy: 0.5246 - val_loss: 2.7114 - val_accuracy: 0.5886\n",
      "Epoch 532/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7893 - accuracy: 0.5166 - val_loss: 2.9519 - val_accuracy: 0.0000e+00\n",
      "Epoch 533/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7899 - accuracy: 0.5293 - val_loss: 2.9912 - val_accuracy: 0.0000e+00\n",
      "Epoch 534/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.8144 - accuracy: 0.5143 - val_loss: 3.4629 - val_accuracy: 0.0000e+00\n",
      "Epoch 535/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.8241 - accuracy: 0.5151 - val_loss: 3.0611 - val_accuracy: 0.0000e+00\n",
      "Epoch 536/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.8112 - accuracy: 0.5222 - val_loss: 2.8934 - val_accuracy: 0.0000e+00\n",
      "Epoch 537/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.8309 - accuracy: 0.5230 - val_loss: 2.4961 - val_accuracy: 0.0000e+00\n",
      "Epoch 538/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.8091 - accuracy: 0.5214 - val_loss: 2.5971 - val_accuracy: 0.0000e+00\n",
      "Epoch 539/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.7904 - accuracy: 0.5230 - val_loss: 2.7873 - val_accuracy: 0.0000e+00\n",
      "Epoch 540/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.8274 - accuracy: 0.5127 - val_loss: 2.8952 - val_accuracy: 0.0000e+00\n",
      "Epoch 541/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.7792 - accuracy: 0.5230 - val_loss: 2.9081 - val_accuracy: 0.0000e+00\n",
      "Epoch 542/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.7798 - accuracy: 0.5269 - val_loss: 2.9636 - val_accuracy: 0.0000e+00\n",
      "Epoch 543/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.7818 - accuracy: 0.5254 - val_loss: 3.2782 - val_accuracy: 0.0000e+00\n",
      "Epoch 544/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7732 - accuracy: 0.5293 - val_loss: 3.6440 - val_accuracy: 0.2437\n",
      "Epoch 545/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7749 - accuracy: 0.5269 - val_loss: 2.2882 - val_accuracy: 0.5823\n",
      "Epoch 546/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.7713 - accuracy: 0.5254 - val_loss: 1.7386 - val_accuracy: 0.0000e+00\n",
      "Epoch 547/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.7639 - accuracy: 0.5222 - val_loss: 1.5392 - val_accuracy: 0.0000e+00\n",
      "Epoch 548/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7763 - accuracy: 0.5238 - val_loss: 1.8087 - val_accuracy: 0.0000e+00\n",
      "Epoch 549/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7800 - accuracy: 0.5182 - val_loss: 1.7350 - val_accuracy: 0.0000e+00\n",
      "Epoch 550/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7925 - accuracy: 0.5190 - val_loss: 1.6749 - val_accuracy: 0.5791\n",
      "Epoch 551/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.7944 - accuracy: 0.5182 - val_loss: 2.2614 - val_accuracy: 0.0000e+00\n",
      "Epoch 552/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.7854 - accuracy: 0.5190 - val_loss: 2.1875 - val_accuracy: 0.0000e+00\n",
      "Epoch 553/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7678 - accuracy: 0.5325 - val_loss: 1.9895 - val_accuracy: 0.0000e+00\n",
      "Epoch 554/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7783 - accuracy: 0.5301 - val_loss: 1.7424 - val_accuracy: 0.5728\n",
      "Epoch 555/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.7637 - accuracy: 0.5317 - val_loss: 1.3531 - val_accuracy: 0.5886\n",
      "Epoch 556/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7681 - accuracy: 0.5214 - val_loss: 1.4165 - val_accuracy: 0.5886\n",
      "Epoch 557/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.7656 - accuracy: 0.5333 - val_loss: 1.5276 - val_accuracy: 0.0000e+00\n",
      "Epoch 558/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7757 - accuracy: 0.5285 - val_loss: 1.6620 - val_accuracy: 0.0000e+00\n",
      "Epoch 559/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.7781 - accuracy: 0.5293 - val_loss: 1.9759 - val_accuracy: 0.0000e+00\n",
      "Epoch 560/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.7640 - accuracy: 0.5317 - val_loss: 2.0389 - val_accuracy: 0.0000e+00\n",
      "Epoch 561/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7687 - accuracy: 0.5396 - val_loss: 2.1195 - val_accuracy: 0.0000e+00\n",
      "Epoch 562/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7756 - accuracy: 0.5293 - val_loss: 2.1951 - val_accuracy: 0.0000e+00\n",
      "Epoch 563/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7710 - accuracy: 0.5333 - val_loss: 2.2290 - val_accuracy: 0.0000e+00\n",
      "Epoch 564/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.7803 - accuracy: 0.5261 - val_loss: 2.1185 - val_accuracy: 0.0000e+00\n",
      "Epoch 565/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.7657 - accuracy: 0.5388 - val_loss: 2.0927 - val_accuracy: 0.0000e+00\n",
      "Epoch 566/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7854 - accuracy: 0.5301 - val_loss: 2.1120 - val_accuracy: 0.0000e+00\n",
      "Epoch 567/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7836 - accuracy: 0.5388 - val_loss: 2.9781 - val_accuracy: 0.0000e+00\n",
      "Epoch 568/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.7583 - accuracy: 0.5301 - val_loss: 3.1793 - val_accuracy: 0.0000e+00\n",
      "Epoch 569/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.7730 - accuracy: 0.5317 - val_loss: 3.3290 - val_accuracy: 0.0000e+00\n",
      "Epoch 570/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7936 - accuracy: 0.5293 - val_loss: 3.5668 - val_accuracy: 0.0000e+00\n",
      "Epoch 571/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7784 - accuracy: 0.5333 - val_loss: 3.3855 - val_accuracy: 0.0000e+00\n",
      "Epoch 572/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.8236 - accuracy: 0.5174 - val_loss: 3.1497 - val_accuracy: 0.0000e+00\n",
      "Epoch 573/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.9321 - accuracy: 0.5143 - val_loss: 2.8320 - val_accuracy: 0.0316\n",
      "Epoch 574/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.8799 - accuracy: 0.5032 - val_loss: 6.7029 - val_accuracy: 0.0158\n",
      "Epoch 575/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8752 - accuracy: 0.5158 - val_loss: 6.7363 - val_accuracy: 0.0222\n",
      "Epoch 576/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8899 - accuracy: 0.5055 - val_loss: 5.3875 - val_accuracy: 0.0601\n",
      "Epoch 577/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.8460 - accuracy: 0.5230 - val_loss: 4.0096 - val_accuracy: 0.2247\n",
      "Epoch 578/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.8201 - accuracy: 0.5182 - val_loss: 3.0387 - val_accuracy: 0.3481\n",
      "Epoch 579/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8012 - accuracy: 0.5222 - val_loss: 2.5008 - val_accuracy: 0.3671\n",
      "Epoch 580/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8116 - accuracy: 0.5261 - val_loss: 1.8568 - val_accuracy: 0.4146\n",
      "Epoch 581/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.7916 - accuracy: 0.5151 - val_loss: 1.7315 - val_accuracy: 0.4589\n",
      "Epoch 582/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.7931 - accuracy: 0.5230 - val_loss: 1.9241 - val_accuracy: 0.0253\n",
      "Epoch 583/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7857 - accuracy: 0.5198 - val_loss: 1.9189 - val_accuracy: 0.0380\n",
      "Epoch 584/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7805 - accuracy: 0.5254 - val_loss: 1.9411 - val_accuracy: 0.5665\n",
      "Epoch 585/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.7569 - accuracy: 0.5309 - val_loss: 2.0831 - val_accuracy: 0.5854\n",
      "Epoch 586/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7753 - accuracy: 0.5285 - val_loss: 2.2906 - val_accuracy: 0.5981\n",
      "Epoch 587/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7562 - accuracy: 0.5380 - val_loss: 2.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 588/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7621 - accuracy: 0.5349 - val_loss: 2.8182 - val_accuracy: 0.0000e+00\n",
      "Epoch 589/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7656 - accuracy: 0.5404 - val_loss: 3.7174 - val_accuracy: 0.0000e+00\n",
      "Epoch 590/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.7636 - accuracy: 0.5365 - val_loss: 4.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 591/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7782 - accuracy: 0.5333 - val_loss: 3.4801 - val_accuracy: 0.0000e+00\n",
      "Epoch 592/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7681 - accuracy: 0.5325 - val_loss: 2.9274 - val_accuracy: 0.0000e+00\n",
      "Epoch 593/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7463 - accuracy: 0.5531 - val_loss: 2.4201 - val_accuracy: 0.0000e+00\n",
      "Epoch 594/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.7450 - accuracy: 0.5547 - val_loss: 2.5110 - val_accuracy: 0.5728\n",
      "Epoch 595/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 1.0713 - accuracy: 0.5428 - val_loss: 2.3229 - val_accuracy: 0.4905\n",
      "Epoch 596/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.7879 - accuracy: 0.5333 - val_loss: 3.4401 - val_accuracy: 0.0000e+00\n",
      "Epoch 597/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7927 - accuracy: 0.5119 - val_loss: 3.5991 - val_accuracy: 0.3101\n",
      "Epoch 598/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.7971 - accuracy: 0.5135 - val_loss: 3.3339 - val_accuracy: 0.3291\n",
      "Epoch 599/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.7880 - accuracy: 0.5261 - val_loss: 2.6180 - val_accuracy: 0.3608\n",
      "Epoch 600/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7952 - accuracy: 0.5103 - val_loss: 1.9681 - val_accuracy: 0.3924\n",
      "Epoch 601/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.7719 - accuracy: 0.5293 - val_loss: 1.5930 - val_accuracy: 0.4241\n",
      "Epoch 602/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.7664 - accuracy: 0.5032 - val_loss: 1.3383 - val_accuracy: 0.4367\n",
      "Epoch 603/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.7729 - accuracy: 0.5087 - val_loss: 1.1845 - val_accuracy: 0.4241\n",
      "Epoch 604/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.7568 - accuracy: 0.5277 - val_loss: 1.1061 - val_accuracy: 0.4525\n",
      "Epoch 605/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.7707 - accuracy: 0.5238 - val_loss: 1.0983 - val_accuracy: 0.4462\n",
      "Epoch 606/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7730 - accuracy: 0.5317 - val_loss: 0.9355 - val_accuracy: 0.5380\n",
      "Epoch 607/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.7734 - accuracy: 0.5349 - val_loss: 1.1183 - val_accuracy: 0.5633\n",
      "Epoch 608/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7551 - accuracy: 0.5341 - val_loss: 1.2846 - val_accuracy: 0.5759\n",
      "Epoch 609/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7661 - accuracy: 0.5357 - val_loss: 1.2653 - val_accuracy: 0.5665\n",
      "Epoch 610/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.8526 - accuracy: 0.5396 - val_loss: 1.9310 - val_accuracy: 0.0000e+00\n",
      "Epoch 611/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.8374 - accuracy: 0.5111 - val_loss: 2.1325 - val_accuracy: 0.0000e+00\n",
      "Epoch 612/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.8294 - accuracy: 0.5135 - val_loss: 1.7561 - val_accuracy: 0.5886\n",
      "Epoch 613/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.7976 - accuracy: 0.5182 - val_loss: 1.5702 - val_accuracy: 0.5886\n",
      "Epoch 614/2000\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.7904 - accuracy: 0.5254 - val_loss: 1.3535 - val_accuracy: 0.5886\n",
      "Epoch 615/2000\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.8030 - accuracy: 0.5190 - val_loss: 2.2059 - val_accuracy: 0.5886\n",
      "Epoch 616/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.7832 - accuracy: 0.5238 - val_loss: 3.4784 - val_accuracy: 0.5696\n",
      "Epoch 617/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.7621 - accuracy: 0.5182 - val_loss: 4.4871 - val_accuracy: 0.0633\n",
      "Epoch 618/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.7627 - accuracy: 0.5293 - val_loss: 5.1118 - val_accuracy: 0.0032\n",
      "Epoch 619/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.7622 - accuracy: 0.5349 - val_loss: 5.4716 - val_accuracy: 0.0063\n",
      "Epoch 620/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.7917 - accuracy: 0.5246 - val_loss: 5.6239 - val_accuracy: 0.0063\n",
      "Epoch 621/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7522 - accuracy: 0.5372 - val_loss: 5.3513 - val_accuracy: 0.0095\n",
      "Epoch 622/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7700 - accuracy: 0.5365 - val_loss: 5.4207 - val_accuracy: 0.0095\n",
      "Epoch 623/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7732 - accuracy: 0.5317 - val_loss: 5.4086 - val_accuracy: 0.0063\n",
      "Epoch 624/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.7629 - accuracy: 0.5261 - val_loss: 5.4847 - val_accuracy: 0.0127\n",
      "Epoch 625/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7607 - accuracy: 0.5357 - val_loss: 5.5016 - val_accuracy: 0.0190\n",
      "Epoch 626/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.7504 - accuracy: 0.5428 - val_loss: 5.6590 - val_accuracy: 0.0222\n",
      "Epoch 627/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.7539 - accuracy: 0.5531 - val_loss: 5.5689 - val_accuracy: 0.0222\n",
      "Epoch 628/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7520 - accuracy: 0.5428 - val_loss: 5.2561 - val_accuracy: 0.0032\n",
      "Epoch 629/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7491 - accuracy: 0.5483 - val_loss: 5.4472 - val_accuracy: 0.0000e+00\n",
      "Epoch 630/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7390 - accuracy: 0.5452 - val_loss: 5.6188 - val_accuracy: 0.0127\n",
      "Epoch 631/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.7516 - accuracy: 0.5475 - val_loss: 5.7720 - val_accuracy: 0.0063\n",
      "Epoch 632/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.7673 - accuracy: 0.5539 - val_loss: 5.2944 - val_accuracy: 0.0032\n",
      "Epoch 633/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.7896 - accuracy: 0.5483 - val_loss: 2.0113 - val_accuracy: 0.4114\n",
      "Epoch 634/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.7724 - accuracy: 0.5372 - val_loss: 1.6105 - val_accuracy: 0.4399\n",
      "Epoch 635/2000\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.7925 - accuracy: 0.5404 - val_loss: 2.6298 - val_accuracy: 0.0000e+00\n",
      "Epoch 636/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.7685 - accuracy: 0.5380 - val_loss: 2.5738 - val_accuracy: 0.0063\n",
      "Epoch 637/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7755 - accuracy: 0.5380 - val_loss: 2.2981 - val_accuracy: 0.2089\n",
      "Epoch 638/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.7676 - accuracy: 0.5412 - val_loss: 2.0489 - val_accuracy: 0.5158\n",
      "Epoch 639/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.7552 - accuracy: 0.5507 - val_loss: 1.7575 - val_accuracy: 0.5981\n",
      "Epoch 640/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7505 - accuracy: 0.5499 - val_loss: 1.6587 - val_accuracy: 0.5949\n",
      "Epoch 641/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.7390 - accuracy: 0.5563 - val_loss: 1.4728 - val_accuracy: 0.5949\n",
      "Epoch 642/2000\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.7421 - accuracy: 0.5697 - val_loss: 1.3776 - val_accuracy: 0.5918\n",
      "Epoch 643/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.7536 - accuracy: 0.5610 - val_loss: 1.7316 - val_accuracy: 0.5918\n",
      "Epoch 644/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7358 - accuracy: 0.5808 - val_loss: 2.3047 - val_accuracy: 0.5665\n",
      "Epoch 645/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.8029 - accuracy: 0.5674 - val_loss: 2.2529 - val_accuracy: 0.3987\n",
      "Epoch 646/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.7578 - accuracy: 0.5689 - val_loss: 2.4311 - val_accuracy: 0.0854\n",
      "Epoch 647/2000\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.7393 - accuracy: 0.5935 - val_loss: 2.5749 - val_accuracy: 0.1582\n",
      "Epoch 648/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7325 - accuracy: 0.5983 - val_loss: 4.3669 - val_accuracy: 0.2627\n",
      "Epoch 649/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7498 - accuracy: 0.6030 - val_loss: 10.4561 - val_accuracy: 0.1392\n",
      "Epoch 650/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.7365 - accuracy: 0.6165 - val_loss: 10.3758 - val_accuracy: 0.2722\n",
      "Epoch 651/2000\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 0.7534 - accuracy: 0.5856 - val_loss: 11.1882 - val_accuracy: 0.0759\n",
      "Epoch 652/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.7219 - accuracy: 0.6070 - val_loss: 11.3030 - val_accuracy: 0.0601\n",
      "Epoch 653/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.7088 - accuracy: 0.6141 - val_loss: 8.9220 - val_accuracy: 0.0854\n",
      "Epoch 654/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.7075 - accuracy: 0.6197 - val_loss: 3.1956 - val_accuracy: 0.1013\n",
      "Epoch 655/2000\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 0.7031 - accuracy: 0.6117 - val_loss: 2.6703 - val_accuracy: 0.3671\n",
      "Epoch 656/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.7195 - accuracy: 0.5998 - val_loss: 2.0830 - val_accuracy: 0.5728\n",
      "Epoch 657/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.7102 - accuracy: 0.6181 - val_loss: 1.9893 - val_accuracy: 0.5538\n",
      "Epoch 658/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.7000 - accuracy: 0.6395 - val_loss: 1.8485 - val_accuracy: 0.5475\n",
      "Epoch 659/2000\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 0.6862 - accuracy: 0.6561 - val_loss: 1.6839 - val_accuracy: 0.5696\n",
      "Epoch 660/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.6864 - accuracy: 0.6577 - val_loss: 1.9830 - val_accuracy: 0.0506\n",
      "Epoch 661/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.6782 - accuracy: 0.6537 - val_loss: 1.7282 - val_accuracy: 0.2848\n",
      "Epoch 662/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.6833 - accuracy: 0.6656 - val_loss: 1.5093 - val_accuracy: 0.5475\n",
      "Epoch 663/2000\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 0.6824 - accuracy: 0.6585 - val_loss: 1.2718 - val_accuracy: 0.5949\n",
      "Epoch 664/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.6562 - accuracy: 0.6719 - val_loss: 1.3145 - val_accuracy: 0.5095\n",
      "Epoch 665/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.6667 - accuracy: 0.7036 - val_loss: 1.2842 - val_accuracy: 0.4652\n",
      "Epoch 666/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.6397 - accuracy: 0.6910 - val_loss: 1.0717 - val_accuracy: 0.5032\n",
      "Epoch 667/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.6128 - accuracy: 0.7353 - val_loss: 1.0600 - val_accuracy: 0.4937\n",
      "Epoch 668/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.5767 - accuracy: 0.7203 - val_loss: 1.1152 - val_accuracy: 0.4747\n",
      "Epoch 669/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.5928 - accuracy: 0.7393 - val_loss: 1.2889 - val_accuracy: 0.4715\n",
      "Epoch 670/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.6861 - accuracy: 0.6807 - val_loss: 0.9674 - val_accuracy: 0.4778\n",
      "Epoch 671/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.7386 - accuracy: 0.5983 - val_loss: 0.8761 - val_accuracy: 0.4715\n",
      "Epoch 672/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7408 - accuracy: 0.5935 - val_loss: 0.8755 - val_accuracy: 0.4525\n",
      "Epoch 673/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7459 - accuracy: 0.5816 - val_loss: 0.8588 - val_accuracy: 0.4652\n",
      "Epoch 674/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7448 - accuracy: 0.5705 - val_loss: 0.9031 - val_accuracy: 0.4810\n",
      "Epoch 675/2000\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.7455 - accuracy: 0.5848 - val_loss: 0.8197 - val_accuracy: 0.4937\n",
      "Epoch 676/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7378 - accuracy: 0.5990 - val_loss: 0.7118 - val_accuracy: 0.5158\n",
      "Epoch 677/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7460 - accuracy: 0.5935 - val_loss: 0.8663 - val_accuracy: 0.5506\n",
      "Epoch 678/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.7385 - accuracy: 0.6149 - val_loss: 1.7210 - val_accuracy: 0.5696\n",
      "Epoch 679/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.7191 - accuracy: 0.6276 - val_loss: 2.0254 - val_accuracy: 0.5633\n",
      "Epoch 680/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7468 - accuracy: 0.6220 - val_loss: 2.2202 - val_accuracy: 0.0095\n",
      "Epoch 681/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7386 - accuracy: 0.6315 - val_loss: 1.8495 - val_accuracy: 0.0285\n",
      "Epoch 682/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.8028 - accuracy: 0.6133 - val_loss: 1.8439 - val_accuracy: 0.0411\n",
      "Epoch 683/2000\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.7553 - accuracy: 0.5959 - val_loss: 2.4541 - val_accuracy: 0.0380\n",
      "Epoch 684/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7130 - accuracy: 0.6006 - val_loss: 3.0629 - val_accuracy: 0.0411\n",
      "Epoch 685/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.6871 - accuracy: 0.6347 - val_loss: 4.8374 - val_accuracy: 0.0285\n",
      "Epoch 686/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.6761 - accuracy: 0.6672 - val_loss: 4.2657 - val_accuracy: 0.0348\n",
      "Epoch 687/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.6637 - accuracy: 0.6593 - val_loss: 3.8488 - val_accuracy: 0.0823\n",
      "Epoch 688/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.6243 - accuracy: 0.7108 - val_loss: 2.3443 - val_accuracy: 0.2848\n",
      "Epoch 689/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.5998 - accuracy: 0.7100 - val_loss: 2.0399 - val_accuracy: 0.5791\n",
      "Epoch 690/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.5861 - accuracy: 0.7211 - val_loss: 1.8350 - val_accuracy: 0.5886\n",
      "Epoch 691/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.5606 - accuracy: 0.7496 - val_loss: 2.0485 - val_accuracy: 0.5728\n",
      "Epoch 692/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7988 - accuracy: 0.6442 - val_loss: 1.8370 - val_accuracy: 0.5791\n",
      "Epoch 693/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.7124 - accuracy: 0.6236 - val_loss: 1.8104 - val_accuracy: 0.5823\n",
      "Epoch 694/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.7162 - accuracy: 0.6173 - val_loss: 1.4638 - val_accuracy: 0.5728\n",
      "Epoch 695/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7115 - accuracy: 0.6474 - val_loss: 2.2469 - val_accuracy: 0.5759\n",
      "Epoch 696/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.6845 - accuracy: 0.6624 - val_loss: 5.2575 - val_accuracy: 0.5665\n",
      "Epoch 697/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.6529 - accuracy: 0.6743 - val_loss: 6.8679 - val_accuracy: 0.5032\n",
      "Epoch 698/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.6296 - accuracy: 0.6878 - val_loss: 7.7348 - val_accuracy: 0.4430\n",
      "Epoch 699/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.6024 - accuracy: 0.7163 - val_loss: 6.1177 - val_accuracy: 0.3861\n",
      "Epoch 700/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.5625 - accuracy: 0.7361 - val_loss: 6.2770 - val_accuracy: 0.5222\n",
      "Epoch 701/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.6402 - accuracy: 0.7124 - val_loss: 2.9534 - val_accuracy: 0.5506\n",
      "Epoch 702/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.8208 - accuracy: 0.5063 - val_loss: 4.3540 - val_accuracy: 0.2753\n",
      "Epoch 703/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.7807 - accuracy: 0.4746 - val_loss: 4.8735 - val_accuracy: 0.2247\n",
      "Epoch 704/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.7708 - accuracy: 0.4746 - val_loss: 4.1736 - val_accuracy: 0.2848\n",
      "Epoch 705/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.7552 - accuracy: 0.4984 - val_loss: 3.4345 - val_accuracy: 0.3481\n",
      "Epoch 706/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.7460 - accuracy: 0.5214 - val_loss: 2.9655 - val_accuracy: 0.1108\n",
      "Epoch 707/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7475 - accuracy: 0.5238 - val_loss: 2.5528 - val_accuracy: 0.1171\n",
      "Epoch 708/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7465 - accuracy: 0.5238 - val_loss: 2.2724 - val_accuracy: 0.1835\n",
      "Epoch 709/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.7426 - accuracy: 0.5269 - val_loss: 1.9969 - val_accuracy: 0.5380\n",
      "Epoch 710/2000\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.7481 - accuracy: 0.5222 - val_loss: 1.7105 - val_accuracy: 0.5570\n",
      "Epoch 711/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7464 - accuracy: 0.5277 - val_loss: 1.9783 - val_accuracy: 0.5791\n",
      "Epoch 712/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7501 - accuracy: 0.5396 - val_loss: 2.8280 - val_accuracy: 0.5886\n",
      "Epoch 713/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7524 - accuracy: 0.5254 - val_loss: 2.8939 - val_accuracy: 0.0475\n",
      "Epoch 714/2000\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.7464 - accuracy: 0.5333 - val_loss: 2.8286 - val_accuracy: 0.1108\n",
      "Epoch 715/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7481 - accuracy: 0.5491 - val_loss: 2.9541 - val_accuracy: 0.5411\n",
      "Epoch 716/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.8284 - accuracy: 0.5444 - val_loss: 0.9268 - val_accuracy: 0.5886\n",
      "Epoch 717/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.7859 - accuracy: 0.5372 - val_loss: 1.7488 - val_accuracy: 0.5823\n",
      "Epoch 718/2000\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 0.7460 - accuracy: 0.5325 - val_loss: 1.9244 - val_accuracy: 0.5854\n",
      "Epoch 719/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.7509 - accuracy: 0.5269 - val_loss: 1.6697 - val_accuracy: 0.5886\n",
      "Epoch 720/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.7446 - accuracy: 0.5428 - val_loss: 1.4129 - val_accuracy: 0.5886\n",
      "Epoch 721/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.7616 - accuracy: 0.5269 - val_loss: 1.2168 - val_accuracy: 0.5886\n",
      "Epoch 722/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.7559 - accuracy: 0.5325 - val_loss: 1.3879 - val_accuracy: 0.5886\n",
      "Epoch 723/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7408 - accuracy: 0.5269 - val_loss: 1.2971 - val_accuracy: 0.5886\n",
      "Epoch 724/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7474 - accuracy: 0.5309 - val_loss: 0.9836 - val_accuracy: 0.5854\n",
      "Epoch 725/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7447 - accuracy: 0.5285 - val_loss: 0.8474 - val_accuracy: 0.5886\n",
      "Epoch 726/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.7420 - accuracy: 0.5380 - val_loss: 0.7697 - val_accuracy: 0.5886\n",
      "Epoch 727/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7395 - accuracy: 0.5444 - val_loss: 0.7399 - val_accuracy: 0.5886\n",
      "Epoch 728/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.7429 - accuracy: 0.5404 - val_loss: 0.7453 - val_accuracy: 0.5886\n",
      "Epoch 729/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.7410 - accuracy: 0.5349 - val_loss: 0.7625 - val_accuracy: 0.5886\n",
      "Epoch 730/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7728 - accuracy: 0.5269 - val_loss: 1.0323 - val_accuracy: 0.5728\n",
      "Epoch 731/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7469 - accuracy: 0.5333 - val_loss: 1.4355 - val_accuracy: 0.0095\n",
      "Epoch 732/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7465 - accuracy: 0.5357 - val_loss: 1.4139 - val_accuracy: 0.2089\n",
      "Epoch 733/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.7403 - accuracy: 0.5357 - val_loss: 1.4513 - val_accuracy: 0.5570\n",
      "Epoch 734/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.7396 - accuracy: 0.5428 - val_loss: 1.3546 - val_accuracy: 0.5570\n",
      "Epoch 735/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7494 - accuracy: 0.5333 - val_loss: 1.1640 - val_accuracy: 0.5222\n",
      "Epoch 736/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7501 - accuracy: 0.5444 - val_loss: 1.0339 - val_accuracy: 0.5253\n",
      "Epoch 737/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.7383 - accuracy: 0.5396 - val_loss: 0.9091 - val_accuracy: 0.5222\n",
      "Epoch 738/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.7341 - accuracy: 0.5452 - val_loss: 1.1343 - val_accuracy: 0.5348\n",
      "Epoch 739/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.7382 - accuracy: 0.5523 - val_loss: 1.2513 - val_accuracy: 0.5348\n",
      "Epoch 740/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7322 - accuracy: 0.5547 - val_loss: 1.1409 - val_accuracy: 0.5253\n",
      "Epoch 741/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.7321 - accuracy: 0.5571 - val_loss: 1.0085 - val_accuracy: 0.5285\n",
      "Epoch 742/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7294 - accuracy: 0.5507 - val_loss: 0.8858 - val_accuracy: 0.5000\n",
      "Epoch 743/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7320 - accuracy: 0.5642 - val_loss: 0.8373 - val_accuracy: 0.4747\n",
      "Epoch 744/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7231 - accuracy: 0.5681 - val_loss: 0.7819 - val_accuracy: 0.4557\n",
      "Epoch 745/2000\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 0.7189 - accuracy: 0.5840 - val_loss: 0.7640 - val_accuracy: 0.4810\n",
      "Epoch 746/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7206 - accuracy: 0.5872 - val_loss: 0.9475 - val_accuracy: 0.4747\n",
      "Epoch 747/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.7147 - accuracy: 0.5872 - val_loss: 0.8400 - val_accuracy: 0.4842\n",
      "Epoch 748/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7117 - accuracy: 0.5769 - val_loss: 1.0670 - val_accuracy: 0.5285\n",
      "Epoch 749/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.7089 - accuracy: 0.6149 - val_loss: 1.2427 - val_accuracy: 0.5285\n",
      "Epoch 750/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7010 - accuracy: 0.6046 - val_loss: 1.0318 - val_accuracy: 0.5095\n",
      "Epoch 751/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7052 - accuracy: 0.6181 - val_loss: 0.9601 - val_accuracy: 0.4810\n",
      "Epoch 752/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.6894 - accuracy: 0.6109 - val_loss: 0.9355 - val_accuracy: 0.5285\n",
      "Epoch 753/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.6814 - accuracy: 0.6403 - val_loss: 1.0551 - val_accuracy: 0.5253\n",
      "Epoch 754/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.6718 - accuracy: 0.6410 - val_loss: 1.2781 - val_accuracy: 0.5190\n",
      "Epoch 755/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.6553 - accuracy: 0.6561 - val_loss: 1.1424 - val_accuracy: 0.4968\n",
      "Epoch 756/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.6522 - accuracy: 0.6672 - val_loss: 0.9256 - val_accuracy: 0.4589\n",
      "Epoch 757/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.6444 - accuracy: 0.6712 - val_loss: 0.8023 - val_accuracy: 0.5316\n",
      "Epoch 758/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.7342 - accuracy: 0.5800 - val_loss: 1.1560 - val_accuracy: 0.4241\n",
      "Epoch 759/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7522 - accuracy: 0.5151 - val_loss: 1.0253 - val_accuracy: 0.4114\n",
      "Epoch 760/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.7463 - accuracy: 0.5087 - val_loss: 0.9953 - val_accuracy: 0.4114\n",
      "Epoch 761/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.7449 - accuracy: 0.5301 - val_loss: 1.3682 - val_accuracy: 0.0000e+00\n",
      "Epoch 762/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.7397 - accuracy: 0.5357 - val_loss: 1.2943 - val_accuracy: 0.0000e+00\n",
      "Epoch 763/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7379 - accuracy: 0.5396 - val_loss: 1.1787 - val_accuracy: 0.5000\n",
      "Epoch 764/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7392 - accuracy: 0.5428 - val_loss: 1.0389 - val_accuracy: 0.4968\n",
      "Epoch 765/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7370 - accuracy: 0.5499 - val_loss: 0.9065 - val_accuracy: 0.5443\n",
      "Epoch 766/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.7361 - accuracy: 0.5491 - val_loss: 1.1112 - val_accuracy: 0.5570\n",
      "Epoch 767/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.7387 - accuracy: 0.5412 - val_loss: 1.0197 - val_accuracy: 0.5506\n",
      "Epoch 768/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.7383 - accuracy: 0.5396 - val_loss: 0.9057 - val_accuracy: 0.5759\n",
      "Epoch 769/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.7395 - accuracy: 0.5428 - val_loss: 1.1022 - val_accuracy: 0.5759\n",
      "Epoch 770/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7559 - accuracy: 0.5444 - val_loss: 0.6926 - val_accuracy: 0.5443\n",
      "Epoch 771/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.7488 - accuracy: 0.5182 - val_loss: 0.7339 - val_accuracy: 0.4810\n",
      "Epoch 772/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.7421 - accuracy: 0.5333 - val_loss: 0.7842 - val_accuracy: 0.4873\n",
      "Epoch 773/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.7503 - accuracy: 0.5412 - val_loss: 0.7829 - val_accuracy: 0.4905\n",
      "Epoch 774/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.7537 - accuracy: 0.5499 - val_loss: 0.8053 - val_accuracy: 0.4842\n",
      "Epoch 775/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.7477 - accuracy: 0.5523 - val_loss: 0.7118 - val_accuracy: 0.5158\n",
      "Epoch 776/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7371 - accuracy: 0.5452 - val_loss: 0.7610 - val_accuracy: 0.5253\n",
      "Epoch 777/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7397 - accuracy: 0.5523 - val_loss: 0.8852 - val_accuracy: 0.5475\n",
      "Epoch 778/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.7363 - accuracy: 0.5705 - val_loss: 0.8425 - val_accuracy: 0.5665\n",
      "Epoch 779/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7344 - accuracy: 0.5761 - val_loss: 0.7453 - val_accuracy: 0.5633\n",
      "Epoch 780/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.7341 - accuracy: 0.5610 - val_loss: 0.7543 - val_accuracy: 0.5696\n",
      "Epoch 781/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.7394 - accuracy: 0.5721 - val_loss: 0.9100 - val_accuracy: 0.5601\n",
      "Epoch 782/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7299 - accuracy: 0.5824 - val_loss: 0.9229 - val_accuracy: 0.5759\n",
      "Epoch 783/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7241 - accuracy: 0.5975 - val_loss: 0.9650 - val_accuracy: 0.5759\n",
      "Epoch 784/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.7217 - accuracy: 0.6062 - val_loss: 0.9741 - val_accuracy: 0.5759\n",
      "Epoch 785/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.7228 - accuracy: 0.6086 - val_loss: 0.9557 - val_accuracy: 0.5918\n",
      "Epoch 786/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.7093 - accuracy: 0.6189 - val_loss: 0.9661 - val_accuracy: 0.5949\n",
      "Epoch 787/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.6999 - accuracy: 0.6260 - val_loss: 0.9829 - val_accuracy: 0.5886\n",
      "Epoch 788/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.6931 - accuracy: 0.6300 - val_loss: 0.9258 - val_accuracy: 0.5886\n",
      "Epoch 789/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7440 - accuracy: 0.6236 - val_loss: 1.0233 - val_accuracy: 0.5886\n",
      "Epoch 790/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.7357 - accuracy: 0.5499 - val_loss: 1.0839 - val_accuracy: 0.5886\n",
      "Epoch 791/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7332 - accuracy: 0.5650 - val_loss: 1.5195 - val_accuracy: 0.5886\n",
      "Epoch 792/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.7269 - accuracy: 0.5816 - val_loss: 1.5828 - val_accuracy: 0.5443\n",
      "Epoch 793/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7258 - accuracy: 0.5880 - val_loss: 1.4878 - val_accuracy: 0.5854\n",
      "Epoch 794/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7189 - accuracy: 0.5872 - val_loss: 1.2590 - val_accuracy: 0.5886\n",
      "Epoch 795/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.7108 - accuracy: 0.6117 - val_loss: 1.0827 - val_accuracy: 0.5886\n",
      "Epoch 796/2000\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.7004 - accuracy: 0.6094 - val_loss: 0.9605 - val_accuracy: 0.5886\n",
      "Epoch 797/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.7463 - accuracy: 0.5491 - val_loss: 7.1854 - val_accuracy: 0.0000e+00\n",
      "Epoch 798/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7400 - accuracy: 0.5174 - val_loss: 7.1854 - val_accuracy: 0.0000e+00\n",
      "Epoch 799/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7445 - accuracy: 0.5396 - val_loss: 7.1869 - val_accuracy: 0.0000e+00\n",
      "Epoch 800/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.7460 - accuracy: 0.5293 - val_loss: 7.1899 - val_accuracy: 0.0000e+00\n",
      "Epoch 801/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7539 - accuracy: 0.5341 - val_loss: 7.1870 - val_accuracy: 0.0000e+00\n",
      "Epoch 802/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.7438 - accuracy: 0.5277 - val_loss: 7.0746 - val_accuracy: 0.0063\n",
      "Epoch 803/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7431 - accuracy: 0.5230 - val_loss: 5.3905 - val_accuracy: 0.1487\n",
      "Epoch 804/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.7405 - accuracy: 0.5372 - val_loss: 4.1462 - val_accuracy: 0.2025\n",
      "Epoch 805/2000\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 0.7443 - accuracy: 0.5428 - val_loss: 2.5736 - val_accuracy: 0.3165\n",
      "Epoch 806/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7387 - accuracy: 0.5571 - val_loss: 1.7788 - val_accuracy: 0.3576\n",
      "Epoch 807/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.7365 - accuracy: 0.5571 - val_loss: 1.3218 - val_accuracy: 0.3671\n",
      "Epoch 808/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.7476 - accuracy: 0.5602 - val_loss: 1.1278 - val_accuracy: 0.4241\n",
      "Epoch 809/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.7383 - accuracy: 0.5586 - val_loss: 1.0012 - val_accuracy: 0.5158\n",
      "Epoch 810/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7350 - accuracy: 0.5816 - val_loss: 1.0023 - val_accuracy: 0.4589\n",
      "Epoch 811/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.7276 - accuracy: 0.5816 - val_loss: 1.0077 - val_accuracy: 0.5633\n",
      "Epoch 812/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.7239 - accuracy: 0.5848 - val_loss: 0.9235 - val_accuracy: 0.5823\n",
      "Epoch 813/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7217 - accuracy: 0.5990 - val_loss: 0.8069 - val_accuracy: 0.5886\n",
      "Epoch 814/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7560 - accuracy: 0.5990 - val_loss: 1.2587 - val_accuracy: 0.5854\n",
      "Epoch 815/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7685 - accuracy: 0.5911 - val_loss: 1.5465 - val_accuracy: 0.5886\n",
      "Epoch 816/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7417 - accuracy: 0.5777 - val_loss: 1.8635 - val_accuracy: 0.5886\n",
      "Epoch 817/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7331 - accuracy: 0.5880 - val_loss: 1.8126 - val_accuracy: 0.5886\n",
      "Epoch 818/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7269 - accuracy: 0.5959 - val_loss: 1.6396 - val_accuracy: 0.5886\n",
      "Epoch 819/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7141 - accuracy: 0.6070 - val_loss: 1.3838 - val_accuracy: 0.5886\n",
      "Epoch 820/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7485 - accuracy: 0.5523 - val_loss: 1.1592 - val_accuracy: 0.5063\n",
      "Epoch 821/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7605 - accuracy: 0.5309 - val_loss: 1.0037 - val_accuracy: 0.4810\n",
      "Epoch 822/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7486 - accuracy: 0.5396 - val_loss: 0.9436 - val_accuracy: 0.4241\n",
      "Epoch 823/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7443 - accuracy: 0.5357 - val_loss: 0.8887 - val_accuracy: 0.4114\n",
      "Epoch 824/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7441 - accuracy: 0.5428 - val_loss: 0.8862 - val_accuracy: 0.4114\n",
      "Epoch 825/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.7395 - accuracy: 0.5412 - val_loss: 0.8667 - val_accuracy: 0.4114\n",
      "Epoch 826/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7444 - accuracy: 0.5452 - val_loss: 0.8289 - val_accuracy: 0.4082\n",
      "Epoch 827/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7387 - accuracy: 0.5634 - val_loss: 0.8314 - val_accuracy: 0.4114\n",
      "Epoch 828/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7438 - accuracy: 0.5586 - val_loss: 1.1174 - val_accuracy: 0.4114\n",
      "Epoch 829/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.7502 - accuracy: 0.5753 - val_loss: 2.1158 - val_accuracy: 0.5886\n",
      "Epoch 830/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7431 - accuracy: 0.5674 - val_loss: 3.0567 - val_accuracy: 0.5886\n",
      "Epoch 831/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.7432 - accuracy: 0.5800 - val_loss: 3.6478 - val_accuracy: 0.5886\n",
      "Epoch 832/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7369 - accuracy: 0.5967 - val_loss: 3.7626 - val_accuracy: 0.5886\n",
      "Epoch 833/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.7256 - accuracy: 0.6038 - val_loss: 3.8804 - val_accuracy: 0.5886\n",
      "Epoch 834/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7265 - accuracy: 0.5998 - val_loss: 4.1825 - val_accuracy: 0.5886\n",
      "Epoch 835/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7091 - accuracy: 0.6165 - val_loss: 4.2208 - val_accuracy: 0.5886\n",
      "Epoch 836/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7096 - accuracy: 0.6086 - val_loss: 4.2568 - val_accuracy: 0.5886\n",
      "Epoch 837/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.6875 - accuracy: 0.6403 - val_loss: 3.9052 - val_accuracy: 0.5886\n",
      "Epoch 838/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6818 - accuracy: 0.6656 - val_loss: 3.8051 - val_accuracy: 0.5886\n",
      "Epoch 839/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.6937 - accuracy: 0.6450 - val_loss: 4.3994 - val_accuracy: 0.4114\n",
      "Epoch 840/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7528 - accuracy: 0.5610 - val_loss: 3.1637 - val_accuracy: 0.4114\n",
      "Epoch 841/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.7439 - accuracy: 0.5238 - val_loss: 3.1709 - val_accuracy: 0.4114\n",
      "Epoch 842/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.7525 - accuracy: 0.5190 - val_loss: 3.5491 - val_accuracy: 0.4114\n",
      "Epoch 843/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7433 - accuracy: 0.5198 - val_loss: 3.5236 - val_accuracy: 0.4114\n",
      "Epoch 844/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7411 - accuracy: 0.5238 - val_loss: 3.3527 - val_accuracy: 0.4114\n",
      "Epoch 845/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7449 - accuracy: 0.5222 - val_loss: 3.1885 - val_accuracy: 0.4082\n",
      "Epoch 846/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.7388 - accuracy: 0.5301 - val_loss: 2.9745 - val_accuracy: 0.4082\n",
      "Epoch 847/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7451 - accuracy: 0.5277 - val_loss: 2.7450 - val_accuracy: 0.4082\n",
      "Epoch 848/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7380 - accuracy: 0.5515 - val_loss: 2.4635 - val_accuracy: 0.4082\n",
      "Epoch 849/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7369 - accuracy: 0.5650 - val_loss: 2.2938 - val_accuracy: 0.4146\n",
      "Epoch 850/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7336 - accuracy: 0.5705 - val_loss: 2.0395 - val_accuracy: 0.5696\n",
      "Epoch 851/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7292 - accuracy: 0.5824 - val_loss: 1.7131 - val_accuracy: 0.5823\n",
      "Epoch 852/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7244 - accuracy: 0.5895 - val_loss: 1.5033 - val_accuracy: 0.5886\n",
      "Epoch 853/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7161 - accuracy: 0.6070 - val_loss: 1.2018 - val_accuracy: 0.5886\n",
      "Epoch 854/2000\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.7137 - accuracy: 0.6260 - val_loss: 1.2861 - val_accuracy: 0.5886\n",
      "Epoch 855/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7027 - accuracy: 0.6307 - val_loss: 1.2581 - val_accuracy: 0.5886\n",
      "Epoch 856/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6936 - accuracy: 0.6434 - val_loss: 1.6642 - val_accuracy: 0.5886\n",
      "Epoch 857/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7139 - accuracy: 0.6307 - val_loss: 1.9521 - val_accuracy: 0.5696\n",
      "Epoch 858/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.6999 - accuracy: 0.6236 - val_loss: 1.8953 - val_accuracy: 0.5886\n",
      "Epoch 859/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6842 - accuracy: 0.6482 - val_loss: 2.6416 - val_accuracy: 0.4146\n",
      "Epoch 860/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6958 - accuracy: 0.6426 - val_loss: 1.5416 - val_accuracy: 0.5886\n",
      "Epoch 861/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6903 - accuracy: 0.6561 - val_loss: 1.3063 - val_accuracy: 0.5886\n",
      "Epoch 862/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7124 - accuracy: 0.6506 - val_loss: 5.6185 - val_accuracy: 0.5886\n",
      "Epoch 863/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7142 - accuracy: 0.6387 - val_loss: 2.7310 - val_accuracy: 0.2468\n",
      "Epoch 864/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7090 - accuracy: 0.6244 - val_loss: 2.9460 - val_accuracy: 0.3987\n",
      "Epoch 865/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7059 - accuracy: 0.6284 - val_loss: 7.3057 - val_accuracy: 0.4747\n",
      "Epoch 866/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7293 - accuracy: 0.5666 - val_loss: 7.4770 - val_accuracy: 0.5791\n",
      "Epoch 867/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7315 - accuracy: 0.5792 - val_loss: 7.4847 - val_accuracy: 0.5759\n",
      "Epoch 868/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7250 - accuracy: 0.6133 - val_loss: 7.6038 - val_accuracy: 0.5854\n",
      "Epoch 869/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6970 - accuracy: 0.6331 - val_loss: 7.9494 - val_accuracy: 0.5854\n",
      "Epoch 870/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.7285 - accuracy: 0.6537 - val_loss: 7.6224 - val_accuracy: 0.5886\n",
      "Epoch 871/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6816 - accuracy: 0.6656 - val_loss: 7.3537 - val_accuracy: 0.5918\n",
      "Epoch 872/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7337 - accuracy: 0.6458 - val_loss: 4.2885 - val_accuracy: 0.5886\n",
      "Epoch 873/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7447 - accuracy: 0.5571 - val_loss: 1.3164 - val_accuracy: 0.5380\n",
      "Epoch 874/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.7510 - accuracy: 0.5388 - val_loss: 1.4357 - val_accuracy: 0.5316\n",
      "Epoch 875/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.7420 - accuracy: 0.5341 - val_loss: 1.4489 - val_accuracy: 0.5443\n",
      "Epoch 876/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7363 - accuracy: 0.5396 - val_loss: 1.3595 - val_accuracy: 0.5348\n",
      "Epoch 877/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7330 - accuracy: 0.5555 - val_loss: 1.4435 - val_accuracy: 0.4778\n",
      "Epoch 878/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.7315 - accuracy: 0.5705 - val_loss: 1.3311 - val_accuracy: 0.5506\n",
      "Epoch 879/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.7268 - accuracy: 0.5761 - val_loss: 1.1921 - val_accuracy: 0.5411\n",
      "Epoch 880/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7280 - accuracy: 0.5887 - val_loss: 1.2562 - val_accuracy: 0.5538\n",
      "Epoch 881/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7191 - accuracy: 0.5959 - val_loss: 1.2025 - val_accuracy: 0.5506\n",
      "Epoch 882/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7100 - accuracy: 0.6125 - val_loss: 1.0789 - val_accuracy: 0.5570\n",
      "Epoch 883/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7057 - accuracy: 0.6220 - val_loss: 1.0826 - val_accuracy: 0.5538\n",
      "Epoch 884/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6912 - accuracy: 0.6323 - val_loss: 0.9161 - val_accuracy: 0.5601\n",
      "Epoch 885/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.6878 - accuracy: 0.6363 - val_loss: 0.8974 - val_accuracy: 0.5601\n",
      "Epoch 886/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6771 - accuracy: 0.6395 - val_loss: 0.9162 - val_accuracy: 0.5823\n",
      "Epoch 887/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.6655 - accuracy: 0.6712 - val_loss: 0.7864 - val_accuracy: 0.5791\n",
      "Epoch 888/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6653 - accuracy: 0.6506 - val_loss: 0.9032 - val_accuracy: 0.5791\n",
      "Epoch 889/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6429 - accuracy: 0.6862 - val_loss: 2.4520 - val_accuracy: 0.5854\n",
      "Epoch 890/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6652 - accuracy: 0.6759 - val_loss: 5.9699 - val_accuracy: 0.5886\n",
      "Epoch 891/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.6811 - accuracy: 0.6442 - val_loss: 7.9844 - val_accuracy: 0.5886\n",
      "Epoch 892/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6400 - accuracy: 0.6973 - val_loss: 7.6087 - val_accuracy: 0.4620\n",
      "Epoch 893/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6520 - accuracy: 0.6965 - val_loss: 7.4358 - val_accuracy: 0.5886\n",
      "Epoch 894/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6139 - accuracy: 0.7068 - val_loss: 4.7968 - val_accuracy: 0.5570\n",
      "Epoch 895/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.8433 - accuracy: 0.6070 - val_loss: 1.4917 - val_accuracy: 0.5728\n",
      "Epoch 896/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.7423 - accuracy: 0.5618 - val_loss: 2.5293 - val_accuracy: 0.5759\n",
      "Epoch 897/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7383 - accuracy: 0.5317 - val_loss: 2.5006 - val_accuracy: 0.5570\n",
      "Epoch 898/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7348 - accuracy: 0.5602 - val_loss: 1.1735 - val_accuracy: 0.5506\n",
      "Epoch 899/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.7604 - accuracy: 0.5721 - val_loss: 1.5367 - val_accuracy: 0.5538\n",
      "Epoch 900/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7443 - accuracy: 0.5578 - val_loss: 1.6067 - val_accuracy: 0.1487\n",
      "Epoch 901/2000\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 0.7404 - accuracy: 0.5523 - val_loss: 1.7902 - val_accuracy: 0.0886\n",
      "Epoch 902/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.7426 - accuracy: 0.5650 - val_loss: 1.8715 - val_accuracy: 0.3196\n",
      "Epoch 903/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7430 - accuracy: 0.5571 - val_loss: 1.9991 - val_accuracy: 0.0000e+00\n",
      "Epoch 904/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.7326 - accuracy: 0.5634 - val_loss: 2.0022 - val_accuracy: 0.0063\n",
      "Epoch 905/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.7310 - accuracy: 0.5563 - val_loss: 1.8799 - val_accuracy: 0.1772\n",
      "Epoch 906/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.7305 - accuracy: 0.5792 - val_loss: 1.7493 - val_accuracy: 0.5791\n",
      "Epoch 907/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7261 - accuracy: 0.5824 - val_loss: 1.5766 - val_accuracy: 0.5696\n",
      "Epoch 908/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7216 - accuracy: 0.5967 - val_loss: 1.5631 - val_accuracy: 0.5411\n",
      "Epoch 909/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.7162 - accuracy: 0.5998 - val_loss: 1.6151 - val_accuracy: 0.4778\n",
      "Epoch 910/2000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.7051 - accuracy: 0.6189 - val_loss: 1.5531 - val_accuracy: 0.4873\n",
      "Epoch 911/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7141 - accuracy: 0.6228 - val_loss: 0.6933 - val_accuracy: 0.5886\n",
      "Epoch 912/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7055 - accuracy: 0.6395 - val_loss: 0.6999 - val_accuracy: 0.5886\n",
      "Epoch 913/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.7138 - accuracy: 0.6521 - val_loss: 0.6953 - val_accuracy: 0.5886\n",
      "Epoch 914/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6750 - accuracy: 0.6585 - val_loss: 0.8468 - val_accuracy: 0.5886\n",
      "Epoch 915/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.6529 - accuracy: 0.6727 - val_loss: 1.0218 - val_accuracy: 0.5886\n",
      "Epoch 916/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.6371 - accuracy: 0.6838 - val_loss: 0.9656 - val_accuracy: 0.5949\n",
      "Epoch 917/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.6488 - accuracy: 0.6791 - val_loss: 0.9764 - val_accuracy: 0.5380\n",
      "Epoch 918/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.6457 - accuracy: 0.6751 - val_loss: 1.0259 - val_accuracy: 0.4525\n",
      "Epoch 919/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.6517 - accuracy: 0.6727 - val_loss: 1.0157 - val_accuracy: 0.4335\n",
      "Epoch 920/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.6786 - accuracy: 0.6197 - val_loss: 0.9452 - val_accuracy: 0.4652\n",
      "Epoch 921/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6754 - accuracy: 0.6363 - val_loss: 1.3295 - val_accuracy: 0.5316\n",
      "Epoch 922/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.6652 - accuracy: 0.6648 - val_loss: 1.6608 - val_accuracy: 0.5949\n",
      "Epoch 923/2000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.6505 - accuracy: 0.6640 - val_loss: 2.1130 - val_accuracy: 0.0095\n",
      "Epoch 924/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6116 - accuracy: 0.7155 - val_loss: 1.9348 - val_accuracy: 0.0190\n",
      "Epoch 925/2000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.5813 - accuracy: 0.7052 - val_loss: 1.9172 - val_accuracy: 0.2184\n",
      "Epoch 926/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.5825 - accuracy: 0.7147 - val_loss: 1.7181 - val_accuracy: 0.4209\n",
      "Epoch 927/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.7541 - accuracy: 0.6601 - val_loss: 0.9941 - val_accuracy: 0.4114\n",
      "Epoch 928/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7120 - accuracy: 0.6712 - val_loss: 1.4459 - val_accuracy: 0.4114\n",
      "Epoch 929/2000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.6808 - accuracy: 0.6878 - val_loss: 4.4720 - val_accuracy: 0.5918\n",
      "Epoch 930/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7029 - accuracy: 0.6823 - val_loss: 4.4011 - val_accuracy: 0.5222\n",
      "Epoch 931/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7258 - accuracy: 0.6292 - val_loss: 1.8825 - val_accuracy: 0.4082\n",
      "Epoch 932/2000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.7124 - accuracy: 0.6094 - val_loss: 1.1401 - val_accuracy: 0.4082\n",
      "Epoch 933/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7021 - accuracy: 0.6181 - val_loss: 0.8658 - val_accuracy: 0.5222\n",
      "Epoch 934/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6836 - accuracy: 0.6387 - val_loss: 0.9709 - val_accuracy: 0.5000\n",
      "Epoch 935/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.6819 - accuracy: 0.6403 - val_loss: 1.2069 - val_accuracy: 0.5222\n",
      "Epoch 936/2000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.6897 - accuracy: 0.6268 - val_loss: 2.3812 - val_accuracy: 0.4114\n",
      "Epoch 937/2000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.6713 - accuracy: 0.6355 - val_loss: 1.6847 - val_accuracy: 0.4430\n",
      "Epoch 938/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6508 - accuracy: 0.6426 - val_loss: 1.6092 - val_accuracy: 0.4747\n",
      "Epoch 939/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.6683 - accuracy: 0.6830 - val_loss: 1.3986 - val_accuracy: 0.5222\n",
      "Epoch 940/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.6408 - accuracy: 0.6656 - val_loss: 2.7073 - val_accuracy: 0.4241\n",
      "Epoch 941/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.6358 - accuracy: 0.6981 - val_loss: 1.8838 - val_accuracy: 0.1930\n",
      "Epoch 942/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.6061 - accuracy: 0.6965 - val_loss: 1.3078 - val_accuracy: 0.5759\n",
      "Epoch 943/2000\n",
      "10/10 [==============================] - 3s 344ms/step - loss: 0.6164 - accuracy: 0.7076 - val_loss: 1.1486 - val_accuracy: 0.5759\n",
      "Epoch 944/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.5776 - accuracy: 0.7195 - val_loss: 1.2917 - val_accuracy: 0.5570\n",
      "Epoch 945/2000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.5447 - accuracy: 0.7417 - val_loss: 1.2146 - val_accuracy: 0.5791\n",
      "Epoch 946/2000\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.6685 - accuracy: 0.6989 - val_loss: 1.2990 - val_accuracy: 0.5854\n",
      "Epoch 947/2000\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.6255 - accuracy: 0.7029 - val_loss: 1.5313 - val_accuracy: 0.5380\n",
      "Epoch 948/2000\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.6391 - accuracy: 0.6815 - val_loss: 1.6240 - val_accuracy: 0.5759\n",
      "Epoch 949/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.6982 - accuracy: 0.6418 - val_loss: 1.4216 - val_accuracy: 0.4589\n",
      "Epoch 950/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7158 - accuracy: 0.6212 - val_loss: 1.1737 - val_accuracy: 0.5063\n",
      "Epoch 951/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.6988 - accuracy: 0.6204 - val_loss: 1.1630 - val_accuracy: 0.5063\n",
      "Epoch 952/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.6714 - accuracy: 0.6410 - val_loss: 1.3252 - val_accuracy: 0.5348\n",
      "Epoch 953/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7182 - accuracy: 0.5697 - val_loss: 1.1447 - val_accuracy: 0.5601\n",
      "Epoch 954/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7261 - accuracy: 0.5697 - val_loss: 1.2934 - val_accuracy: 0.4652\n",
      "Epoch 955/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7166 - accuracy: 0.5911 - val_loss: 1.2448 - val_accuracy: 0.4810\n",
      "Epoch 956/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.6916 - accuracy: 0.6109 - val_loss: 1.3555 - val_accuracy: 0.3861\n",
      "Epoch 957/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.6808 - accuracy: 0.6379 - val_loss: 1.8699 - val_accuracy: 0.3165\n",
      "Epoch 958/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.6596 - accuracy: 0.6513 - val_loss: 2.1495 - val_accuracy: 0.0506\n",
      "Epoch 959/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.6298 - accuracy: 0.6712 - val_loss: 4.5390 - val_accuracy: 0.1646\n",
      "Epoch 960/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.6524 - accuracy: 0.6719 - val_loss: 2.6015 - val_accuracy: 0.3196\n",
      "Epoch 961/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.6859 - accuracy: 0.6403 - val_loss: 2.5200 - val_accuracy: 0.2975\n",
      "Epoch 962/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.6901 - accuracy: 0.6212 - val_loss: 3.0960 - val_accuracy: 0.2722\n",
      "Epoch 963/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.6720 - accuracy: 0.6529 - val_loss: 4.0659 - val_accuracy: 0.2532\n",
      "Epoch 964/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.6397 - accuracy: 0.6846 - val_loss: 5.7616 - val_accuracy: 0.2342\n",
      "Epoch 965/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.6180 - accuracy: 0.6989 - val_loss: 6.3748 - val_accuracy: 0.1899\n",
      "Epoch 966/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.5798 - accuracy: 0.7013 - val_loss: 8.0571 - val_accuracy: 0.3608\n",
      "Epoch 967/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.5768 - accuracy: 0.7258 - val_loss: 7.2720 - val_accuracy: 0.4367\n",
      "Epoch 968/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.5624 - accuracy: 0.7425 - val_loss: 6.9583 - val_accuracy: 0.4082\n",
      "Epoch 969/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.5950 - accuracy: 0.7013 - val_loss: 5.1454 - val_accuracy: 0.4494\n",
      "Epoch 970/2000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.5708 - accuracy: 0.7306 - val_loss: 3.5425 - val_accuracy: 0.4810\n",
      "Epoch 971/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.5146 - accuracy: 0.7686 - val_loss: 2.7320 - val_accuracy: 0.4968\n",
      "Epoch 972/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.5219 - accuracy: 0.7662 - val_loss: 3.5216 - val_accuracy: 0.5759\n",
      "Epoch 973/2000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.5552 - accuracy: 0.7726 - val_loss: 2.8071 - val_accuracy: 0.5570\n",
      "Epoch 974/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.5153 - accuracy: 0.7813 - val_loss: 1.8130 - val_accuracy: 0.5443\n",
      "Epoch 975/2000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.5504 - accuracy: 0.7797 - val_loss: 2.7869 - val_accuracy: 0.5316\n",
      "Epoch 976/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7613 - accuracy: 0.6347 - val_loss: 1.2855 - val_accuracy: 0.4114\n",
      "Epoch 977/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7350 - accuracy: 0.5689 - val_loss: 1.0011 - val_accuracy: 0.4114\n",
      "Epoch 978/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.7372 - accuracy: 0.5642 - val_loss: 0.8412 - val_accuracy: 0.4114\n",
      "Epoch 979/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7390 - accuracy: 0.5531 - val_loss: 0.8156 - val_accuracy: 0.4114\n",
      "Epoch 980/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7387 - accuracy: 0.5626 - val_loss: 0.8074 - val_accuracy: 0.4114\n",
      "Epoch 981/2000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.7824 - accuracy: 0.5658 - val_loss: 2.0738 - val_accuracy: 0.4620\n",
      "Epoch 982/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.7348 - accuracy: 0.5547 - val_loss: 2.5659 - val_accuracy: 0.5032\n",
      "Epoch 983/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7331 - accuracy: 0.5650 - val_loss: 2.6136 - val_accuracy: 0.4399\n",
      "Epoch 984/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7315 - accuracy: 0.5816 - val_loss: 2.6217 - val_accuracy: 0.4272\n",
      "Epoch 985/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7261 - accuracy: 0.5990 - val_loss: 2.4403 - val_accuracy: 0.4146\n",
      "Epoch 986/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7263 - accuracy: 0.5895 - val_loss: 2.3375 - val_accuracy: 0.4304\n",
      "Epoch 987/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.7235 - accuracy: 0.5990 - val_loss: 2.3036 - val_accuracy: 0.4367\n",
      "Epoch 988/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.7217 - accuracy: 0.6109 - val_loss: 2.3665 - val_accuracy: 0.4367\n",
      "Epoch 989/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7098 - accuracy: 0.6086 - val_loss: 1.8581 - val_accuracy: 0.4399\n",
      "Epoch 990/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.7002 - accuracy: 0.6323 - val_loss: 1.9457 - val_accuracy: 0.4272\n",
      "Epoch 991/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.6913 - accuracy: 0.6315 - val_loss: 1.4499 - val_accuracy: 0.4937\n",
      "Epoch 992/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6784 - accuracy: 0.6458 - val_loss: 1.8355 - val_accuracy: 0.4146\n",
      "Epoch 993/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.6714 - accuracy: 0.6632 - val_loss: 1.4739 - val_accuracy: 0.4177\n",
      "Epoch 994/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.6601 - accuracy: 0.6775 - val_loss: 1.0310 - val_accuracy: 0.5854\n",
      "Epoch 995/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.7246 - accuracy: 0.6220 - val_loss: 1.1071 - val_accuracy: 0.5886\n",
      "Epoch 996/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7281 - accuracy: 0.5959 - val_loss: 1.3771 - val_accuracy: 0.5886\n",
      "Epoch 997/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7269 - accuracy: 0.6220 - val_loss: 1.3643 - val_accuracy: 0.5886\n",
      "Epoch 998/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7027 - accuracy: 0.6355 - val_loss: 2.0077 - val_accuracy: 0.5886\n",
      "Epoch 999/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.6951 - accuracy: 0.6442 - val_loss: 1.7778 - val_accuracy: 0.5886\n",
      "Epoch 1000/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.6752 - accuracy: 0.6632 - val_loss: 2.6959 - val_accuracy: 0.5570\n",
      "Epoch 1001/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7015 - accuracy: 0.6133 - val_loss: 7.6628 - val_accuracy: 0.5728\n",
      "Epoch 1002/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6987 - accuracy: 0.6165 - val_loss: 2.4492 - val_accuracy: 0.5886\n",
      "Epoch 1003/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6807 - accuracy: 0.6498 - val_loss: 1.9934 - val_accuracy: 0.5886\n",
      "Epoch 1004/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.6597 - accuracy: 0.6537 - val_loss: 1.7610 - val_accuracy: 0.5886\n",
      "Epoch 1005/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.6641 - accuracy: 0.6609 - val_loss: 1.5722 - val_accuracy: 0.5886\n",
      "Epoch 1006/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.6473 - accuracy: 0.6672 - val_loss: 1.5662 - val_accuracy: 0.5949\n",
      "Epoch 1007/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6460 - accuracy: 0.6862 - val_loss: 1.5673 - val_accuracy: 0.5823\n",
      "Epoch 1008/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.6605 - accuracy: 0.6799 - val_loss: 1.4526 - val_accuracy: 0.5886\n",
      "Epoch 1009/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.6497 - accuracy: 0.6846 - val_loss: 2.6989 - val_accuracy: 0.2278\n",
      "Epoch 1010/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6405 - accuracy: 0.6981 - val_loss: 2.6104 - val_accuracy: 0.4399\n",
      "Epoch 1011/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6437 - accuracy: 0.6823 - val_loss: 3.1351 - val_accuracy: 0.4873\n",
      "Epoch 1012/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6242 - accuracy: 0.7163 - val_loss: 4.8746 - val_accuracy: 0.5728\n",
      "Epoch 1013/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.5962 - accuracy: 0.7345 - val_loss: 3.6950 - val_accuracy: 0.5570\n",
      "Epoch 1014/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.6003 - accuracy: 0.7250 - val_loss: 5.2335 - val_accuracy: 0.5759\n",
      "Epoch 1015/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.5955 - accuracy: 0.7171 - val_loss: 4.2120 - val_accuracy: 0.3608\n",
      "Epoch 1016/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.5725 - accuracy: 0.7464 - val_loss: 6.3510 - val_accuracy: 0.4778\n",
      "Epoch 1017/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.5505 - accuracy: 0.7631 - val_loss: 3.9830 - val_accuracy: 0.5316\n",
      "Epoch 1018/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.6001 - accuracy: 0.7314 - val_loss: 1.8317 - val_accuracy: 0.5158\n",
      "Epoch 1019/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.5620 - accuracy: 0.7575 - val_loss: 2.1064 - val_accuracy: 0.1772\n",
      "Epoch 1020/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.5483 - accuracy: 0.7615 - val_loss: 4.7012 - val_accuracy: 0.5190\n",
      "Epoch 1021/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.5419 - accuracy: 0.7678 - val_loss: 5.0042 - val_accuracy: 0.5032\n",
      "Epoch 1022/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.6049 - accuracy: 0.7266 - val_loss: 1.5127 - val_accuracy: 0.5032\n",
      "Epoch 1023/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6145 - accuracy: 0.7100 - val_loss: 1.4077 - val_accuracy: 0.5759\n",
      "Epoch 1024/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.5556 - accuracy: 0.7567 - val_loss: 1.4247 - val_accuracy: 0.5791\n",
      "Epoch 1025/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.5109 - accuracy: 0.7853 - val_loss: 1.2395 - val_accuracy: 0.5696\n",
      "Epoch 1026/2000\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.4826 - accuracy: 0.8082 - val_loss: 1.4941 - val_accuracy: 0.5823\n",
      "Epoch 1027/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.5001 - accuracy: 0.8059 - val_loss: 1.3654 - val_accuracy: 0.5728\n",
      "Epoch 1028/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.5273 - accuracy: 0.7948 - val_loss: 1.9073 - val_accuracy: 0.5570\n",
      "Epoch 1029/2000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.5343 - accuracy: 0.7670 - val_loss: 2.1609 - val_accuracy: 0.3766\n",
      "Epoch 1030/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.6618 - accuracy: 0.6648 - val_loss: 1.4304 - val_accuracy: 0.4652\n",
      "Epoch 1031/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7447 - accuracy: 0.5515 - val_loss: 1.2324 - val_accuracy: 0.4114\n",
      "Epoch 1032/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7471 - accuracy: 0.5468 - val_loss: 1.6301 - val_accuracy: 0.4114\n",
      "Epoch 1033/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7488 - accuracy: 0.5380 - val_loss: 2.2513 - val_accuracy: 0.4114\n",
      "Epoch 1034/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.7452 - accuracy: 0.5317 - val_loss: 2.4612 - val_accuracy: 0.1392\n",
      "Epoch 1035/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.7382 - accuracy: 0.5499 - val_loss: 2.4697 - val_accuracy: 0.3956\n",
      "Epoch 1036/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7347 - accuracy: 0.5547 - val_loss: 2.3242 - val_accuracy: 0.3829\n",
      "Epoch 1037/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7440 - accuracy: 0.5626 - val_loss: 3.1569 - val_accuracy: 0.2658\n",
      "Epoch 1038/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7333 - accuracy: 0.5769 - val_loss: 2.5049 - val_accuracy: 0.2880\n",
      "Epoch 1039/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.7273 - accuracy: 0.5840 - val_loss: 2.1410 - val_accuracy: 0.3797\n",
      "Epoch 1040/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7235 - accuracy: 0.5848 - val_loss: 2.1032 - val_accuracy: 0.3639\n",
      "Epoch 1041/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7152 - accuracy: 0.6109 - val_loss: 2.2645 - val_accuracy: 0.2152\n",
      "Epoch 1042/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7209 - accuracy: 0.5959 - val_loss: 2.8413 - val_accuracy: 0.2278\n",
      "Epoch 1043/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.7096 - accuracy: 0.6117 - val_loss: 4.4958 - val_accuracy: 0.1234\n",
      "Epoch 1044/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7195 - accuracy: 0.5856 - val_loss: 5.0922 - val_accuracy: 0.0316\n",
      "Epoch 1045/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7142 - accuracy: 0.6022 - val_loss: 3.5502 - val_accuracy: 0.4082\n",
      "Epoch 1046/2000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.7060 - accuracy: 0.6046 - val_loss: 2.7663 - val_accuracy: 0.4114\n",
      "Epoch 1047/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7058 - accuracy: 0.6086 - val_loss: 2.5376 - val_accuracy: 0.4114\n",
      "Epoch 1048/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7021 - accuracy: 0.6165 - val_loss: 2.1136 - val_accuracy: 0.4209\n",
      "Epoch 1049/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6842 - accuracy: 0.6339 - val_loss: 1.7389 - val_accuracy: 0.4462\n",
      "Epoch 1050/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6654 - accuracy: 0.6529 - val_loss: 1.5269 - val_accuracy: 0.4684\n",
      "Epoch 1051/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.6548 - accuracy: 0.6601 - val_loss: 1.7279 - val_accuracy: 0.5443\n",
      "Epoch 1052/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.7218 - accuracy: 0.5943 - val_loss: 2.4342 - val_accuracy: 0.5886\n",
      "Epoch 1053/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7231 - accuracy: 0.5887 - val_loss: 1.8684 - val_accuracy: 0.5538\n",
      "Epoch 1054/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7281 - accuracy: 0.5761 - val_loss: 1.6295 - val_accuracy: 0.4019\n",
      "Epoch 1055/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.7245 - accuracy: 0.5808 - val_loss: 1.9357 - val_accuracy: 0.0000e+00\n",
      "Epoch 1056/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.7161 - accuracy: 0.5975 - val_loss: 2.5401 - val_accuracy: 0.0000e+00\n",
      "Epoch 1057/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7000 - accuracy: 0.6347 - val_loss: 2.4399 - val_accuracy: 0.4114\n",
      "Epoch 1058/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.6920 - accuracy: 0.6228 - val_loss: 3.1763 - val_accuracy: 0.2120\n",
      "Epoch 1059/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.6902 - accuracy: 0.6307 - val_loss: 2.6671 - val_accuracy: 0.4684\n",
      "Epoch 1060/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.6655 - accuracy: 0.6569 - val_loss: 2.1643 - val_accuracy: 0.4367\n",
      "Epoch 1061/2000\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.6550 - accuracy: 0.6569 - val_loss: 2.0451 - val_accuracy: 0.3449\n",
      "Epoch 1062/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.6338 - accuracy: 0.6815 - val_loss: 1.8829 - val_accuracy: 0.5190\n",
      "Epoch 1063/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.6654 - accuracy: 0.6688 - val_loss: 1.5026 - val_accuracy: 0.5949\n",
      "Epoch 1064/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7137 - accuracy: 0.6070 - val_loss: 1.3143 - val_accuracy: 0.4241\n",
      "Epoch 1065/2000\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.7222 - accuracy: 0.5737 - val_loss: 0.9485 - val_accuracy: 0.4937\n",
      "Epoch 1066/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.7312 - accuracy: 0.5531 - val_loss: 1.0998 - val_accuracy: 0.5222\n",
      "Epoch 1067/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.7227 - accuracy: 0.5864 - val_loss: 1.6202 - val_accuracy: 0.2532\n",
      "Epoch 1068/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7156 - accuracy: 0.5959 - val_loss: 1.6646 - val_accuracy: 0.4272\n",
      "Epoch 1069/2000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 0.7193 - accuracy: 0.5975 - val_loss: 1.3771 - val_accuracy: 0.4241\n",
      "Epoch 1070/2000\n",
      "10/10 [==============================] - 3s 307ms/step - loss: 0.6957 - accuracy: 0.6006 - val_loss: 1.4681 - val_accuracy: 0.2184\n",
      "Epoch 1071/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6840 - accuracy: 0.6165 - val_loss: 1.6365 - val_accuracy: 0.1076\n",
      "Epoch 1072/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.6622 - accuracy: 0.6498 - val_loss: 1.7303 - val_accuracy: 0.0918\n",
      "Epoch 1073/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.6484 - accuracy: 0.6648 - val_loss: 1.5964 - val_accuracy: 0.1456\n",
      "Epoch 1074/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.6570 - accuracy: 0.6751 - val_loss: 1.3284 - val_accuracy: 0.4494\n",
      "Epoch 1075/2000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.6280 - accuracy: 0.6735 - val_loss: 1.2432 - val_accuracy: 0.4652\n",
      "Epoch 1076/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.6313 - accuracy: 0.6862 - val_loss: 1.3918 - val_accuracy: 0.5348\n",
      "Epoch 1077/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.6122 - accuracy: 0.6894 - val_loss: 1.7776 - val_accuracy: 0.0633\n",
      "Epoch 1078/2000\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.6125 - accuracy: 0.6989 - val_loss: 1.7805 - val_accuracy: 0.0475\n",
      "Epoch 1079/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.5981 - accuracy: 0.7100 - val_loss: 1.7468 - val_accuracy: 0.3671\n",
      "Epoch 1080/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.6014 - accuracy: 0.6957 - val_loss: 1.9783 - val_accuracy: 0.4241\n",
      "Epoch 1081/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.6665 - accuracy: 0.6775 - val_loss: 1.7621 - val_accuracy: 0.4177\n",
      "Epoch 1082/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7645 - accuracy: 0.5729 - val_loss: 1.4770 - val_accuracy: 0.4968\n",
      "Epoch 1083/2000\n",
      "10/10 [==============================] - 3s 305ms/step - loss: 0.7467 - accuracy: 0.5444 - val_loss: 1.5501 - val_accuracy: 0.5032\n",
      "Epoch 1084/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7477 - accuracy: 0.5412 - val_loss: 1.5412 - val_accuracy: 0.4937\n",
      "Epoch 1085/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7438 - accuracy: 0.5539 - val_loss: 1.3726 - val_accuracy: 0.4842\n",
      "Epoch 1086/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7484 - accuracy: 0.5523 - val_loss: 2.0597 - val_accuracy: 0.4525\n",
      "Epoch 1087/2000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.7532 - accuracy: 0.5460 - val_loss: 2.6994 - val_accuracy: 0.4209\n",
      "Epoch 1088/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7409 - accuracy: 0.5365 - val_loss: 2.8204 - val_accuracy: 0.4146\n",
      "Epoch 1089/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7418 - accuracy: 0.5372 - val_loss: 2.1628 - val_accuracy: 0.4842\n",
      "Epoch 1090/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7368 - accuracy: 0.5468 - val_loss: 2.3186 - val_accuracy: 0.4937\n",
      "Epoch 1091/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.7377 - accuracy: 0.5586 - val_loss: 2.0122 - val_accuracy: 0.3734\n",
      "Epoch 1092/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7447 - accuracy: 0.5483 - val_loss: 1.8957 - val_accuracy: 0.3703\n",
      "Epoch 1093/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7342 - accuracy: 0.5578 - val_loss: 1.7075 - val_accuracy: 0.4051\n",
      "Epoch 1094/2000\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.7364 - accuracy: 0.5642 - val_loss: 1.7280 - val_accuracy: 0.4051\n",
      "Epoch 1095/2000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.7345 - accuracy: 0.5674 - val_loss: 1.5509 - val_accuracy: 0.4304\n",
      "Epoch 1096/2000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.7299 - accuracy: 0.5769 - val_loss: 3.2971 - val_accuracy: 0.5095\n",
      "Epoch 1097/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7356 - accuracy: 0.5737 - val_loss: 3.6437 - val_accuracy: 0.5127\n",
      "Epoch 1098/2000\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.7338 - accuracy: 0.5563 - val_loss: 2.6890 - val_accuracy: 0.5158\n",
      "Epoch 1099/2000\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 0.7319 - accuracy: 0.5681 - val_loss: 2.1368 - val_accuracy: 0.5190\n",
      "Epoch 1100/2000\n",
      "10/10 [==============================] - 3s 348ms/step - loss: 0.7345 - accuracy: 0.5880 - val_loss: 4.4666 - val_accuracy: 0.1582\n",
      "Epoch 1101/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.7315 - accuracy: 0.5721 - val_loss: 4.5512 - val_accuracy: 0.0728\n",
      "Epoch 1102/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7299 - accuracy: 0.5777 - val_loss: 4.3729 - val_accuracy: 0.2120\n",
      "Epoch 1103/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.7272 - accuracy: 0.5895 - val_loss: 3.4128 - val_accuracy: 0.5696\n",
      "Epoch 1104/2000\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 0.7258 - accuracy: 0.5792 - val_loss: 2.5851 - val_accuracy: 0.5791\n",
      "Epoch 1105/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.7203 - accuracy: 0.5856 - val_loss: 1.5348 - val_accuracy: 0.5854\n",
      "Epoch 1106/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7156 - accuracy: 0.5959 - val_loss: 1.2670 - val_accuracy: 0.5823\n",
      "Epoch 1107/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7148 - accuracy: 0.5967 - val_loss: 1.4315 - val_accuracy: 0.5759\n",
      "Epoch 1108/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.7115 - accuracy: 0.6070 - val_loss: 1.4445 - val_accuracy: 0.5696\n",
      "Epoch 1109/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.7008 - accuracy: 0.6276 - val_loss: 1.3111 - val_accuracy: 0.5759\n",
      "Epoch 1110/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.6938 - accuracy: 0.6403 - val_loss: 6.3853 - val_accuracy: 0.0316\n",
      "Epoch 1111/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.6971 - accuracy: 0.6371 - val_loss: 6.7755 - val_accuracy: 0.0253\n",
      "Epoch 1112/2000\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 0.6808 - accuracy: 0.6506 - val_loss: 6.6437 - val_accuracy: 0.0285\n",
      "Epoch 1113/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.6696 - accuracy: 0.6672 - val_loss: 6.0223 - val_accuracy: 0.0728\n",
      "Epoch 1114/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.6724 - accuracy: 0.6632 - val_loss: 5.0657 - val_accuracy: 0.5411\n",
      "Epoch 1115/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.6511 - accuracy: 0.6767 - val_loss: 4.8416 - val_accuracy: 0.2880\n",
      "Epoch 1116/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.6409 - accuracy: 0.6910 - val_loss: 4.3852 - val_accuracy: 0.5633\n",
      "Epoch 1117/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.6402 - accuracy: 0.6894 - val_loss: 2.9869 - val_accuracy: 0.5918\n",
      "Epoch 1118/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.6300 - accuracy: 0.7036 - val_loss: 3.0724 - val_accuracy: 0.5918\n",
      "Epoch 1119/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.6116 - accuracy: 0.7100 - val_loss: 3.2425 - val_accuracy: 0.5601\n",
      "Epoch 1120/2000\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.6223 - accuracy: 0.7060 - val_loss: 5.3140 - val_accuracy: 0.1266\n",
      "Epoch 1121/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.6171 - accuracy: 0.6997 - val_loss: 5.3661 - val_accuracy: 0.1741\n",
      "Epoch 1122/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.5919 - accuracy: 0.7330 - val_loss: 4.6960 - val_accuracy: 0.5253\n",
      "Epoch 1123/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.5917 - accuracy: 0.7227 - val_loss: 4.3350 - val_accuracy: 0.5854\n",
      "Epoch 1124/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.6095 - accuracy: 0.7219 - val_loss: 4.4030 - val_accuracy: 0.5570\n",
      "Epoch 1125/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.5847 - accuracy: 0.7290 - val_loss: 4.4545 - val_accuracy: 0.5886\n",
      "Epoch 1126/2000\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.5570 - accuracy: 0.7575 - val_loss: 4.2033 - val_accuracy: 0.5886\n",
      "Epoch 1127/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.5590 - accuracy: 0.7456 - val_loss: 3.3131 - val_accuracy: 0.5823\n",
      "Epoch 1128/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.5319 - accuracy: 0.7631 - val_loss: 3.9658 - val_accuracy: 0.5918\n",
      "Epoch 1129/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.5458 - accuracy: 0.7512 - val_loss: 3.1717 - val_accuracy: 0.5886\n",
      "Epoch 1130/2000\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 0.5627 - accuracy: 0.7441 - val_loss: 1.3639 - val_accuracy: 0.5886\n",
      "Epoch 1131/2000\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 0.5793 - accuracy: 0.7353 - val_loss: 2.5753 - val_accuracy: 0.5791\n",
      "Epoch 1132/2000\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.5833 - accuracy: 0.7448 - val_loss: 2.5445 - val_accuracy: 0.5633\n",
      "Epoch 1133/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.5942 - accuracy: 0.7179 - val_loss: 2.0183 - val_accuracy: 0.5791\n",
      "Epoch 1134/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.5446 - accuracy: 0.7718 - val_loss: 1.9730 - val_accuracy: 0.5665\n",
      "Epoch 1135/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.5190 - accuracy: 0.7837 - val_loss: 2.1825 - val_accuracy: 0.5823\n",
      "Epoch 1136/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.5413 - accuracy: 0.7544 - val_loss: 2.9638 - val_accuracy: 0.4241\n",
      "Epoch 1137/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.5380 - accuracy: 0.7861 - val_loss: 2.9838 - val_accuracy: 0.1361\n",
      "Epoch 1138/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.5122 - accuracy: 0.7948 - val_loss: 2.3586 - val_accuracy: 0.3544\n",
      "Epoch 1139/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.4914 - accuracy: 0.8003 - val_loss: 2.2204 - val_accuracy: 0.5506\n",
      "Epoch 1140/2000\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 0.4814 - accuracy: 0.8233 - val_loss: 2.6036 - val_accuracy: 0.5665\n",
      "Epoch 1141/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.5124 - accuracy: 0.8154 - val_loss: 2.9745 - val_accuracy: 0.5759\n",
      "Epoch 1142/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.5280 - accuracy: 0.7742 - val_loss: 1.4340 - val_accuracy: 0.5570\n",
      "Epoch 1143/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.5252 - accuracy: 0.7837 - val_loss: 1.2665 - val_accuracy: 0.5316\n",
      "Epoch 1144/2000\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.5045 - accuracy: 0.7773 - val_loss: 0.7152 - val_accuracy: 0.5348\n",
      "Epoch 1145/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.6423 - accuracy: 0.7171 - val_loss: 0.7817 - val_accuracy: 0.5316\n",
      "Epoch 1146/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.5626 - accuracy: 0.7433 - val_loss: 0.7589 - val_accuracy: 0.5222\n",
      "Epoch 1147/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.5530 - accuracy: 0.7409 - val_loss: 0.7806 - val_accuracy: 0.5095\n",
      "Epoch 1148/2000\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 0.5219 - accuracy: 0.7670 - val_loss: 0.8218 - val_accuracy: 0.5316\n",
      "Epoch 1149/2000\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.5025 - accuracy: 0.7892 - val_loss: 0.7675 - val_accuracy: 0.5285\n",
      "Epoch 1150/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.5826 - accuracy: 0.7750 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 1151/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.6026 - accuracy: 0.7433 - val_loss: 0.6955 - val_accuracy: 0.4462\n",
      "Epoch 1152/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.5833 - accuracy: 0.7330 - val_loss: 0.6932 - val_accuracy: 0.4589\n",
      "Epoch 1153/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.5813 - accuracy: 0.7448 - val_loss: 0.6947 - val_accuracy: 0.4335\n",
      "Epoch 1154/2000\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 0.5722 - accuracy: 0.7544 - val_loss: 1.0918 - val_accuracy: 0.4177\n",
      "Epoch 1155/2000\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.5208 - accuracy: 0.7868 - val_loss: 1.2961 - val_accuracy: 0.4367\n",
      "Epoch 1156/2000\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 0.4772 - accuracy: 0.8011 - val_loss: 1.5288 - val_accuracy: 0.4146\n",
      "Epoch 1157/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.5781 - accuracy: 0.7623 - val_loss: 1.7418 - val_accuracy: 0.4146\n",
      "Epoch 1158/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.5926 - accuracy: 0.7520 - val_loss: 1.3204 - val_accuracy: 0.4209\n",
      "Epoch 1159/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.5104 - accuracy: 0.7821 - val_loss: 1.5250 - val_accuracy: 0.4620\n",
      "Epoch 1160/2000\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.5164 - accuracy: 0.8027 - val_loss: 1.6549 - val_accuracy: 0.3259\n",
      "Epoch 1161/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.5342 - accuracy: 0.7979 - val_loss: 1.5848 - val_accuracy: 0.3829\n",
      "Epoch 1162/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.6840 - accuracy: 0.6815 - val_loss: 1.4273 - val_accuracy: 0.4146\n",
      "Epoch 1163/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.6869 - accuracy: 0.6498 - val_loss: 1.2308 - val_accuracy: 0.4241\n",
      "Epoch 1164/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.6776 - accuracy: 0.6537 - val_loss: 1.1200 - val_accuracy: 0.4399\n",
      "Epoch 1165/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.6815 - accuracy: 0.6601 - val_loss: 1.0610 - val_accuracy: 0.4335\n",
      "Epoch 1166/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.6889 - accuracy: 0.6395 - val_loss: 1.1614 - val_accuracy: 0.4367\n",
      "Epoch 1167/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.6723 - accuracy: 0.6616 - val_loss: 0.9758 - val_accuracy: 0.4430\n",
      "Epoch 1168/2000\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.6445 - accuracy: 0.6933 - val_loss: 1.1510 - val_accuracy: 0.4019\n",
      "Epoch 1169/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.6416 - accuracy: 0.6949 - val_loss: 1.7046 - val_accuracy: 0.0696\n",
      "Epoch 1170/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.6168 - accuracy: 0.7132 - val_loss: 2.6591 - val_accuracy: 0.0443\n",
      "Epoch 1171/2000\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.5948 - accuracy: 0.7472 - val_loss: 2.7961 - val_accuracy: 0.0570\n",
      "Epoch 1172/2000\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.5599 - accuracy: 0.7623 - val_loss: 1.7499 - val_accuracy: 0.4051\n",
      "Epoch 1173/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.5811 - accuracy: 0.7544 - val_loss: 3.6249 - val_accuracy: 0.5728\n",
      "Epoch 1174/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.5344 - accuracy: 0.7631 - val_loss: 5.7511 - val_accuracy: 0.4810\n",
      "Epoch 1175/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.5523 - accuracy: 0.7599 - val_loss: 6.3158 - val_accuracy: 0.1519\n",
      "Epoch 1176/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.6129 - accuracy: 0.7076 - val_loss: 5.6982 - val_accuracy: 0.4905\n",
      "Epoch 1177/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.5956 - accuracy: 0.7163 - val_loss: 4.8789 - val_accuracy: 0.5095\n",
      "Epoch 1178/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.5301 - accuracy: 0.7686 - val_loss: 3.2036 - val_accuracy: 0.5032\n",
      "Epoch 1179/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.4819 - accuracy: 0.7932 - val_loss: 1.8846 - val_accuracy: 0.4968\n",
      "Epoch 1180/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.4744 - accuracy: 0.7987 - val_loss: 1.3335 - val_accuracy: 0.4810\n",
      "Epoch 1181/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.4973 - accuracy: 0.7773 - val_loss: 1.1768 - val_accuracy: 0.4589\n",
      "Epoch 1182/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.4538 - accuracy: 0.8027 - val_loss: 1.1090 - val_accuracy: 0.4430\n",
      "Epoch 1183/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.4392 - accuracy: 0.8114 - val_loss: 1.3550 - val_accuracy: 0.5000\n",
      "Epoch 1184/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.4489 - accuracy: 0.8312 - val_loss: 1.0374 - val_accuracy: 0.4620\n",
      "Epoch 1185/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.4350 - accuracy: 0.8344 - val_loss: 0.9158 - val_accuracy: 0.4905\n",
      "Epoch 1186/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.5375 - accuracy: 0.8059 - val_loss: 0.7805 - val_accuracy: 0.5316\n",
      "Epoch 1187/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.7049 - accuracy: 0.7266 - val_loss: 0.7746 - val_accuracy: 0.5253\n",
      "Epoch 1188/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.6523 - accuracy: 0.7076 - val_loss: 1.0730 - val_accuracy: 0.4146\n",
      "Epoch 1189/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7250 - accuracy: 0.5808 - val_loss: 0.6950 - val_accuracy: 0.4715\n",
      "Epoch 1190/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7205 - accuracy: 0.6006 - val_loss: 0.7065 - val_accuracy: 0.4051\n",
      "Epoch 1191/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.7307 - accuracy: 0.5848 - val_loss: 0.7494 - val_accuracy: 0.4114\n",
      "Epoch 1192/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.7124 - accuracy: 0.6109 - val_loss: 0.9474 - val_accuracy: 0.4019\n",
      "Epoch 1193/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.7085 - accuracy: 0.6022 - val_loss: 1.0901 - val_accuracy: 0.4177\n",
      "Epoch 1194/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.7012 - accuracy: 0.6276 - val_loss: 1.2246 - val_accuracy: 0.4462\n",
      "Epoch 1195/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.6851 - accuracy: 0.6387 - val_loss: 1.3587 - val_accuracy: 0.4557\n",
      "Epoch 1196/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.6703 - accuracy: 0.6616 - val_loss: 1.6638 - val_accuracy: 0.4146\n",
      "Epoch 1197/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.6553 - accuracy: 0.6862 - val_loss: 1.8793 - val_accuracy: 0.4114\n",
      "Epoch 1198/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.6475 - accuracy: 0.7036 - val_loss: 1.5169 - val_accuracy: 0.5316\n",
      "Epoch 1199/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.6179 - accuracy: 0.7250 - val_loss: 1.5688 - val_accuracy: 0.5063\n",
      "Epoch 1200/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.6259 - accuracy: 0.7353 - val_loss: 1.6304 - val_accuracy: 0.4335\n",
      "Epoch 1201/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.5879 - accuracy: 0.7512 - val_loss: 1.8566 - val_accuracy: 0.2848\n",
      "Epoch 1202/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.6121 - accuracy: 0.7242 - val_loss: 1.6353 - val_accuracy: 0.4430\n",
      "Epoch 1203/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.6037 - accuracy: 0.7298 - val_loss: 1.7651 - val_accuracy: 0.4114\n",
      "Epoch 1204/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.5622 - accuracy: 0.7686 - val_loss: 2.2160 - val_accuracy: 0.2468\n",
      "Epoch 1205/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.5538 - accuracy: 0.7567 - val_loss: 2.2745 - val_accuracy: 0.1487\n",
      "Epoch 1206/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.5154 - accuracy: 0.7892 - val_loss: 2.2095 - val_accuracy: 0.1614\n",
      "Epoch 1207/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.4992 - accuracy: 0.7987 - val_loss: 2.8817 - val_accuracy: 0.2785\n",
      "Epoch 1208/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.4567 - accuracy: 0.8288 - val_loss: 2.9561 - val_accuracy: 0.2120\n",
      "Epoch 1209/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.4588 - accuracy: 0.8296 - val_loss: 1.8716 - val_accuracy: 0.3829\n",
      "Epoch 1210/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.4526 - accuracy: 0.8304 - val_loss: 1.1307 - val_accuracy: 0.4399\n",
      "Epoch 1211/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.4586 - accuracy: 0.8304 - val_loss: 1.1609 - val_accuracy: 0.4494\n",
      "Epoch 1212/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.4871 - accuracy: 0.8193 - val_loss: 0.8082 - val_accuracy: 0.5791\n",
      "Epoch 1213/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.6031 - accuracy: 0.7504 - val_loss: 2.8451 - val_accuracy: 0.5823\n",
      "Epoch 1214/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.5560 - accuracy: 0.7694 - val_loss: 4.3195 - val_accuracy: 0.5823\n",
      "Epoch 1215/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.6671 - accuracy: 0.7758 - val_loss: 3.4243 - val_accuracy: 0.5854\n",
      "Epoch 1216/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.6356 - accuracy: 0.7108 - val_loss: 2.3361 - val_accuracy: 0.5854\n",
      "Epoch 1217/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.6307 - accuracy: 0.7116 - val_loss: 2.9225 - val_accuracy: 0.5886\n",
      "Epoch 1218/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.6267 - accuracy: 0.7361 - val_loss: 1.4561 - val_accuracy: 0.5823\n",
      "Epoch 1219/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.6327 - accuracy: 0.7203 - val_loss: 1.6926 - val_accuracy: 0.5728\n",
      "Epoch 1220/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.6263 - accuracy: 0.7124 - val_loss: 1.8710 - val_accuracy: 0.5759\n",
      "Epoch 1221/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.6026 - accuracy: 0.7369 - val_loss: 2.0121 - val_accuracy: 0.5823\n",
      "Epoch 1222/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.5613 - accuracy: 0.7805 - val_loss: 2.2130 - val_accuracy: 0.5665\n",
      "Epoch 1223/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.5448 - accuracy: 0.7876 - val_loss: 2.6683 - val_accuracy: 0.4430\n",
      "Epoch 1224/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.5123 - accuracy: 0.8082 - val_loss: 3.8652 - val_accuracy: 0.4272\n",
      "Epoch 1225/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.5047 - accuracy: 0.8067 - val_loss: 5.0926 - val_accuracy: 0.4272\n",
      "Epoch 1226/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.5443 - accuracy: 0.7710 - val_loss: 7.6620 - val_accuracy: 0.4652\n",
      "Epoch 1227/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.5651 - accuracy: 0.7496 - val_loss: 6.8548 - val_accuracy: 0.3513\n",
      "Epoch 1228/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.5305 - accuracy: 0.7742 - val_loss: 6.7476 - val_accuracy: 0.3418\n",
      "Epoch 1229/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.5039 - accuracy: 0.8003 - val_loss: 7.3531 - val_accuracy: 0.3544\n",
      "Epoch 1230/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.4817 - accuracy: 0.8193 - val_loss: 5.6218 - val_accuracy: 0.2911\n",
      "Epoch 1231/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.4624 - accuracy: 0.8320 - val_loss: 3.8903 - val_accuracy: 0.2184\n",
      "Epoch 1232/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.4804 - accuracy: 0.8281 - val_loss: 3.9044 - val_accuracy: 0.1930\n",
      "Epoch 1233/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.4553 - accuracy: 0.8463 - val_loss: 4.9455 - val_accuracy: 0.3386\n",
      "Epoch 1234/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.4509 - accuracy: 0.8391 - val_loss: 7.9778 - val_accuracy: 0.1361\n",
      "Epoch 1235/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.4767 - accuracy: 0.8344 - val_loss: 1.9110 - val_accuracy: 0.3608\n",
      "Epoch 1236/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.5034 - accuracy: 0.8185 - val_loss: 1.3136 - val_accuracy: 0.5348\n",
      "Epoch 1237/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.4983 - accuracy: 0.8320 - val_loss: 1.8608 - val_accuracy: 0.4937\n",
      "Epoch 1238/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.4637 - accuracy: 0.8518 - val_loss: 2.2140 - val_accuracy: 0.2373\n",
      "Epoch 1239/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.4323 - accuracy: 0.8574 - val_loss: 1.4415 - val_accuracy: 0.5411\n",
      "Epoch 1240/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.4340 - accuracy: 0.8574 - val_loss: 1.4230 - val_accuracy: 0.5032\n",
      "Epoch 1241/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.5165 - accuracy: 0.7837 - val_loss: 1.6875 - val_accuracy: 0.4462\n",
      "Epoch 1242/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.5265 - accuracy: 0.7781 - val_loss: 2.2149 - val_accuracy: 0.4335\n",
      "Epoch 1243/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.4601 - accuracy: 0.8225 - val_loss: 1.6574 - val_accuracy: 0.4367\n",
      "Epoch 1244/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.4376 - accuracy: 0.8439 - val_loss: 1.2177 - val_accuracy: 0.4209\n",
      "Epoch 1245/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.4044 - accuracy: 0.8558 - val_loss: 1.0474 - val_accuracy: 0.4241\n",
      "Epoch 1246/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.4258 - accuracy: 0.8716 - val_loss: 1.2068 - val_accuracy: 0.4304\n",
      "Epoch 1247/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.4333 - accuracy: 0.8637 - val_loss: 1.3082 - val_accuracy: 0.4335\n",
      "Epoch 1248/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.4781 - accuracy: 0.8494 - val_loss: 1.0102 - val_accuracy: 0.4335\n",
      "Epoch 1249/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.4564 - accuracy: 0.8352 - val_loss: 0.7520 - val_accuracy: 0.4114\n",
      "Epoch 1250/2000\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.4749 - accuracy: 0.8368 - val_loss: 0.8833 - val_accuracy: 0.4494\n",
      "Epoch 1251/2000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.4213 - accuracy: 0.8700 - val_loss: 0.9070 - val_accuracy: 0.4905\n",
      "Epoch 1252/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.4237 - accuracy: 0.8494 - val_loss: 1.4191 - val_accuracy: 0.5000\n",
      "Epoch 1253/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.3782 - accuracy: 0.8788 - val_loss: 1.4137 - val_accuracy: 0.4968\n",
      "Epoch 1254/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.4583 - accuracy: 0.8574 - val_loss: 1.2712 - val_accuracy: 0.5095\n",
      "Epoch 1255/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.4020 - accuracy: 0.8685 - val_loss: 4.1728 - val_accuracy: 0.0443\n",
      "Epoch 1256/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.5051 - accuracy: 0.8415 - val_loss: 3.3874 - val_accuracy: 0.0000e+00\n",
      "Epoch 1257/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.4655 - accuracy: 0.8645 - val_loss: 3.6591 - val_accuracy: 0.1076\n",
      "Epoch 1258/2000\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.4046 - accuracy: 0.8645 - val_loss: 2.6472 - val_accuracy: 0.4114\n",
      "Epoch 1259/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.3943 - accuracy: 0.8502 - val_loss: 2.9265 - val_accuracy: 0.3829\n",
      "Epoch 1260/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.3980 - accuracy: 0.8724 - val_loss: 4.6872 - val_accuracy: 0.4051\n",
      "Epoch 1261/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.4064 - accuracy: 0.8764 - val_loss: 4.4067 - val_accuracy: 0.2532\n",
      "Epoch 1262/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.7805 - accuracy: 0.6719 - val_loss: 3.0690 - val_accuracy: 0.5886\n",
      "Epoch 1263/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.7494 - accuracy: 0.5816 - val_loss: 3.2124 - val_accuracy: 0.5886\n",
      "Epoch 1264/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.7214 - accuracy: 0.6046 - val_loss: 3.2298 - val_accuracy: 0.5886\n",
      "Epoch 1265/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.6972 - accuracy: 0.6292 - val_loss: 3.3285 - val_accuracy: 0.5886\n",
      "Epoch 1266/2000\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.6836 - accuracy: 0.6609 - val_loss: 3.5120 - val_accuracy: 0.5886\n",
      "Epoch 1267/2000\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 0.6603 - accuracy: 0.6886 - val_loss: 3.9688 - val_accuracy: 0.5886\n",
      "Epoch 1268/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.6401 - accuracy: 0.6933 - val_loss: 4.5263 - val_accuracy: 0.5886\n",
      "Epoch 1269/2000\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.6059 - accuracy: 0.7393 - val_loss: 4.7557 - val_accuracy: 0.5886\n",
      "Epoch 1270/2000\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.5784 - accuracy: 0.7552 - val_loss: 4.9889 - val_accuracy: 0.4620\n",
      "Epoch 1271/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.5507 - accuracy: 0.7813 - val_loss: 5.1376 - val_accuracy: 0.3323\n",
      "Epoch 1272/2000\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.5541 - accuracy: 0.7734 - val_loss: 4.9227 - val_accuracy: 0.3608\n",
      "Epoch 1273/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.5164 - accuracy: 0.7971 - val_loss: 4.9428 - val_accuracy: 0.3924\n",
      "Epoch 1274/2000\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.4922 - accuracy: 0.8074 - val_loss: 5.1531 - val_accuracy: 0.3165\n",
      "Epoch 1275/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.4921 - accuracy: 0.8035 - val_loss: 4.7117 - val_accuracy: 0.3734\n",
      "Epoch 1276/2000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.4542 - accuracy: 0.8399 - val_loss: 2.5035 - val_accuracy: 0.4272\n",
      "Epoch 1277/2000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.4087 - accuracy: 0.8566 - val_loss: 2.4469 - val_accuracy: 0.4019\n",
      "Epoch 1278/2000\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.4192 - accuracy: 0.8463 - val_loss: 3.2483 - val_accuracy: 0.3323\n",
      "Epoch 1279/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.4126 - accuracy: 0.8479 - val_loss: 2.3234 - val_accuracy: 0.3513\n",
      "Epoch 1280/2000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.4183 - accuracy: 0.8447 - val_loss: 3.5306 - val_accuracy: 0.4715\n",
      "Epoch 1281/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.4072 - accuracy: 0.8518 - val_loss: 2.1905 - val_accuracy: 0.4620\n",
      "Epoch 1282/2000\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.4023 - accuracy: 0.8463 - val_loss: 2.2041 - val_accuracy: 0.5032\n",
      "Epoch 1283/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.3931 - accuracy: 0.8574 - val_loss: 4.3886 - val_accuracy: 0.3766\n",
      "Epoch 1284/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.3741 - accuracy: 0.8590 - val_loss: 4.9577 - val_accuracy: 0.2405\n",
      "Epoch 1285/2000\n",
      "10/10 [==============================] - 3s 321ms/step - loss: 0.3484 - accuracy: 0.8796 - val_loss: 4.5264 - val_accuracy: 0.1835\n",
      "Epoch 1286/2000\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.4152 - accuracy: 0.8431 - val_loss: 2.7345 - val_accuracy: 0.4430\n",
      "Epoch 1287/2000\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.4673 - accuracy: 0.8106 - val_loss: 2.2372 - val_accuracy: 0.4146\n",
      "Epoch 1288/2000\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.4886 - accuracy: 0.8043 - val_loss: 2.9222 - val_accuracy: 0.4494\n",
      "Epoch 1289/2000\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 0.4530 - accuracy: 0.8241 - val_loss: 3.7579 - val_accuracy: 0.4715\n",
      "Epoch 1290/2000\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 0.4002 - accuracy: 0.8597 - val_loss: 2.8926 - val_accuracy: 0.5158\n",
      "Epoch 1291/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.3628 - accuracy: 0.8629 - val_loss: 3.0297 - val_accuracy: 0.4177\n",
      "Epoch 1292/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3650 - accuracy: 0.8637 - val_loss: 5.4730 - val_accuracy: 0.4335\n",
      "Epoch 1293/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3717 - accuracy: 0.8756 - val_loss: 4.2726 - val_accuracy: 0.3861\n",
      "Epoch 1294/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3817 - accuracy: 0.8613 - val_loss: 3.8185 - val_accuracy: 0.4557\n",
      "Epoch 1295/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.3795 - accuracy: 0.8669 - val_loss: 2.4756 - val_accuracy: 0.4114\n",
      "Epoch 1296/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4041 - accuracy: 0.8455 - val_loss: 2.7687 - val_accuracy: 0.0095\n",
      "Epoch 1297/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3211 - accuracy: 0.8788 - val_loss: 2.3390 - val_accuracy: 0.0506\n",
      "Epoch 1298/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4387 - accuracy: 0.8494 - val_loss: 4.0455 - val_accuracy: 0.1044\n",
      "Epoch 1299/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.3661 - accuracy: 0.8661 - val_loss: 4.9868 - val_accuracy: 0.0728\n",
      "Epoch 1300/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3580 - accuracy: 0.8716 - val_loss: 4.9923 - val_accuracy: 0.2089\n",
      "Epoch 1301/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3712 - accuracy: 0.8883 - val_loss: 6.3923 - val_accuracy: 0.3797\n",
      "Epoch 1302/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4515 - accuracy: 0.8471 - val_loss: 1.9896 - val_accuracy: 0.2247\n",
      "Epoch 1303/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4198 - accuracy: 0.8534 - val_loss: 1.8637 - val_accuracy: 0.2880\n",
      "Epoch 1304/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.3885 - accuracy: 0.8693 - val_loss: 2.1579 - val_accuracy: 0.3513\n",
      "Epoch 1305/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3474 - accuracy: 0.8962 - val_loss: 2.8215 - val_accuracy: 0.3386\n",
      "Epoch 1306/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3394 - accuracy: 0.8891 - val_loss: 3.8939 - val_accuracy: 0.2595\n",
      "Epoch 1307/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3318 - accuracy: 0.8954 - val_loss: 5.3727 - val_accuracy: 0.3228\n",
      "Epoch 1308/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.3568 - accuracy: 0.8819 - val_loss: 4.3433 - val_accuracy: 0.3196\n",
      "Epoch 1309/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4925 - accuracy: 0.8637 - val_loss: 2.2000 - val_accuracy: 0.2722\n",
      "Epoch 1310/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4529 - accuracy: 0.8431 - val_loss: 1.4924 - val_accuracy: 0.5032\n",
      "Epoch 1311/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4640 - accuracy: 0.8368 - val_loss: 1.5248 - val_accuracy: 0.4430\n",
      "Epoch 1312/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4074 - accuracy: 0.8605 - val_loss: 1.5016 - val_accuracy: 0.4842\n",
      "Epoch 1313/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.3638 - accuracy: 0.8764 - val_loss: 1.3003 - val_accuracy: 0.5095\n",
      "Epoch 1314/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3336 - accuracy: 0.8851 - val_loss: 1.3241 - val_accuracy: 0.5348\n",
      "Epoch 1315/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.3180 - accuracy: 0.8883 - val_loss: 1.3818 - val_accuracy: 0.5411\n",
      "Epoch 1316/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3319 - accuracy: 0.9010 - val_loss: 2.4209 - val_accuracy: 0.5127\n",
      "Epoch 1317/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.2806 - accuracy: 0.9065 - val_loss: 4.6438 - val_accuracy: 0.2627\n",
      "Epoch 1318/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.2573 - accuracy: 0.9057 - val_loss: 4.9939 - val_accuracy: 0.3006\n",
      "Epoch 1319/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.2411 - accuracy: 0.9176 - val_loss: 5.1484 - val_accuracy: 0.4146\n",
      "Epoch 1320/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.2445 - accuracy: 0.9128 - val_loss: 5.9234 - val_accuracy: 0.4209\n",
      "Epoch 1321/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.2719 - accuracy: 0.9295 - val_loss: 5.7935 - val_accuracy: 0.4620\n",
      "Epoch 1322/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.2692 - accuracy: 0.9231 - val_loss: 7.0857 - val_accuracy: 0.4525\n",
      "Epoch 1323/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3390 - accuracy: 0.9208 - val_loss: 8.3829 - val_accuracy: 0.3639\n",
      "Epoch 1324/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4333 - accuracy: 0.8994 - val_loss: 8.2412 - val_accuracy: 0.1551\n",
      "Epoch 1325/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 1.7687 - accuracy: 0.7013 - val_loss: 1.8700 - val_accuracy: 0.0411\n",
      "Epoch 1326/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7480 - accuracy: 0.5713 - val_loss: 1.5267 - val_accuracy: 0.0000e+00\n",
      "Epoch 1327/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7371 - accuracy: 0.5515 - val_loss: 1.5666 - val_accuracy: 0.0000e+00\n",
      "Epoch 1328/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7271 - accuracy: 0.5626 - val_loss: 1.6039 - val_accuracy: 0.0000e+00\n",
      "Epoch 1329/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7211 - accuracy: 0.5872 - val_loss: 1.6397 - val_accuracy: 0.0000e+00\n",
      "Epoch 1330/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7164 - accuracy: 0.6101 - val_loss: 1.6737 - val_accuracy: 0.0032\n",
      "Epoch 1331/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7216 - accuracy: 0.6109 - val_loss: 1.5828 - val_accuracy: 0.5886\n",
      "Epoch 1332/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7008 - accuracy: 0.6228 - val_loss: 1.4948 - val_accuracy: 0.5886\n",
      "Epoch 1333/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6990 - accuracy: 0.6252 - val_loss: 1.5377 - val_accuracy: 0.5886\n",
      "Epoch 1334/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6923 - accuracy: 0.6244 - val_loss: 1.5229 - val_accuracy: 0.5886\n",
      "Epoch 1335/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.6822 - accuracy: 0.6529 - val_loss: 1.5756 - val_accuracy: 0.5443\n",
      "Epoch 1336/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6758 - accuracy: 0.6458 - val_loss: 1.5063 - val_accuracy: 0.4652\n",
      "Epoch 1337/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6599 - accuracy: 0.6664 - val_loss: 1.4537 - val_accuracy: 0.4715\n",
      "Epoch 1338/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.6503 - accuracy: 0.6704 - val_loss: 1.4091 - val_accuracy: 0.4778\n",
      "Epoch 1339/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.6286 - accuracy: 0.6973 - val_loss: 1.4075 - val_accuracy: 0.5380\n",
      "Epoch 1340/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6171 - accuracy: 0.7076 - val_loss: 1.5704 - val_accuracy: 0.5823\n",
      "Epoch 1341/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5959 - accuracy: 0.7235 - val_loss: 1.7590 - val_accuracy: 0.5886\n",
      "Epoch 1342/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5698 - accuracy: 0.7448 - val_loss: 1.7871 - val_accuracy: 0.5886\n",
      "Epoch 1343/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.5356 - accuracy: 0.7734 - val_loss: 2.0974 - val_accuracy: 0.5886\n",
      "Epoch 1344/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.4977 - accuracy: 0.7932 - val_loss: 1.1809 - val_accuracy: 0.5475\n",
      "Epoch 1345/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4750 - accuracy: 0.8090 - val_loss: 1.1424 - val_accuracy: 0.5601\n",
      "Epoch 1346/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4366 - accuracy: 0.8249 - val_loss: 2.3996 - val_accuracy: 0.5475\n",
      "Epoch 1347/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4188 - accuracy: 0.8304 - val_loss: 3.5901 - val_accuracy: 0.5506\n",
      "Epoch 1348/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.3949 - accuracy: 0.8597 - val_loss: 4.3135 - val_accuracy: 0.5570\n",
      "Epoch 1349/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3760 - accuracy: 0.8851 - val_loss: 4.6404 - val_accuracy: 0.4747\n",
      "Epoch 1350/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6961 - accuracy: 0.6609 - val_loss: 6.9858 - val_accuracy: 0.0000e+00\n",
      "Epoch 1351/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7543 - accuracy: 0.5777 - val_loss: 7.1639 - val_accuracy: 0.0000e+00\n",
      "Epoch 1352/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7301 - accuracy: 0.5880 - val_loss: 7.1647 - val_accuracy: 0.0000e+00\n",
      "Epoch 1353/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7177 - accuracy: 0.6181 - val_loss: 7.0306 - val_accuracy: 0.0032\n",
      "Epoch 1354/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6989 - accuracy: 0.6212 - val_loss: 6.8160 - val_accuracy: 0.0032\n",
      "Epoch 1355/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6802 - accuracy: 0.6513 - val_loss: 6.0447 - val_accuracy: 0.0095\n",
      "Epoch 1356/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6601 - accuracy: 0.6688 - val_loss: 5.8496 - val_accuracy: 0.0158\n",
      "Epoch 1357/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.6264 - accuracy: 0.6965 - val_loss: 6.1844 - val_accuracy: 0.0095\n",
      "Epoch 1358/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6177 - accuracy: 0.6965 - val_loss: 6.1041 - val_accuracy: 0.0190\n",
      "Epoch 1359/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5792 - accuracy: 0.7552 - val_loss: 5.9343 - val_accuracy: 0.0222\n",
      "Epoch 1360/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5506 - accuracy: 0.7670 - val_loss: 5.8481 - val_accuracy: 0.0190\n",
      "Epoch 1361/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.5322 - accuracy: 0.7805 - val_loss: 5.5430 - val_accuracy: 0.0032\n",
      "Epoch 1362/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4814 - accuracy: 0.8162 - val_loss: 5.1642 - val_accuracy: 0.0158\n",
      "Epoch 1363/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4776 - accuracy: 0.8439 - val_loss: 3.9925 - val_accuracy: 0.0886\n",
      "Epoch 1364/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4606 - accuracy: 0.8384 - val_loss: 2.7730 - val_accuracy: 0.4019\n",
      "Epoch 1365/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.4252 - accuracy: 0.8590 - val_loss: 3.3900 - val_accuracy: 0.0506\n",
      "Epoch 1366/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4121 - accuracy: 0.8645 - val_loss: 5.4668 - val_accuracy: 0.1013\n",
      "Epoch 1367/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4043 - accuracy: 0.8732 - val_loss: 6.7547 - val_accuracy: 0.1962\n",
      "Epoch 1368/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3989 - accuracy: 0.8677 - val_loss: 5.4073 - val_accuracy: 0.3544\n",
      "Epoch 1369/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3603 - accuracy: 0.8827 - val_loss: 4.9369 - val_accuracy: 0.3924\n",
      "Epoch 1370/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.3824 - accuracy: 0.8962 - val_loss: 5.6548 - val_accuracy: 0.1487\n",
      "Epoch 1371/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7337 - accuracy: 0.6458 - val_loss: 3.7751 - val_accuracy: 0.2500\n",
      "Epoch 1372/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.8327 - accuracy: 0.5206 - val_loss: 5.2123 - val_accuracy: 0.1582\n",
      "Epoch 1373/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7681 - accuracy: 0.5206 - val_loss: 4.7969 - val_accuracy: 0.2057\n",
      "Epoch 1374/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7580 - accuracy: 0.5174 - val_loss: 3.8648 - val_accuracy: 0.2848\n",
      "Epoch 1375/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7663 - accuracy: 0.5119 - val_loss: 3.1540 - val_accuracy: 0.2722\n",
      "Epoch 1376/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7832 - accuracy: 0.5309 - val_loss: 2.8544 - val_accuracy: 0.3133\n",
      "Epoch 1377/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7492 - accuracy: 0.5349 - val_loss: 2.6117 - val_accuracy: 0.3291\n",
      "Epoch 1378/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7495 - accuracy: 0.5333 - val_loss: 2.3367 - val_accuracy: 0.3481\n",
      "Epoch 1379/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7600 - accuracy: 0.5372 - val_loss: 2.9022 - val_accuracy: 0.0570\n",
      "Epoch 1380/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7477 - accuracy: 0.5428 - val_loss: 3.9444 - val_accuracy: 0.0475\n",
      "Epoch 1381/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7347 - accuracy: 0.5539 - val_loss: 4.2609 - val_accuracy: 0.0570\n",
      "Epoch 1382/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7325 - accuracy: 0.5523 - val_loss: 4.4415 - val_accuracy: 0.0411\n",
      "Epoch 1383/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7400 - accuracy: 0.5515 - val_loss: 4.5391 - val_accuracy: 0.0443\n",
      "Epoch 1384/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7374 - accuracy: 0.5578 - val_loss: 4.5855 - val_accuracy: 0.0316\n",
      "Epoch 1385/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7288 - accuracy: 0.5563 - val_loss: 2.1498 - val_accuracy: 0.0285\n",
      "Epoch 1386/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.7305 - accuracy: 0.5586 - val_loss: 2.0506 - val_accuracy: 0.0506\n",
      "Epoch 1387/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.7363 - accuracy: 0.5547 - val_loss: 2.5122 - val_accuracy: 0.0570\n",
      "Epoch 1388/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7486 - accuracy: 0.5475 - val_loss: 2.5350 - val_accuracy: 0.0285\n",
      "Epoch 1389/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7314 - accuracy: 0.5507 - val_loss: 2.4397 - val_accuracy: 0.0222\n",
      "Epoch 1390/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7307 - accuracy: 0.5650 - val_loss: 2.3492 - val_accuracy: 0.0253\n",
      "Epoch 1391/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7311 - accuracy: 0.5460 - val_loss: 2.2268 - val_accuracy: 0.0285\n",
      "Epoch 1392/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.7287 - accuracy: 0.5499 - val_loss: 2.1251 - val_accuracy: 0.0411\n",
      "Epoch 1393/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7259 - accuracy: 0.5594 - val_loss: 2.1717 - val_accuracy: 0.0633\n",
      "Epoch 1394/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7267 - accuracy: 0.5658 - val_loss: 2.0855 - val_accuracy: 0.1646\n",
      "Epoch 1395/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.7248 - accuracy: 0.5666 - val_loss: 1.9868 - val_accuracy: 0.3418\n",
      "Epoch 1396/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7223 - accuracy: 0.5792 - val_loss: 1.8763 - val_accuracy: 0.5095\n",
      "Epoch 1397/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7242 - accuracy: 0.5721 - val_loss: 2.1171 - val_accuracy: 0.5285\n",
      "Epoch 1398/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7260 - accuracy: 0.5586 - val_loss: 2.8982 - val_accuracy: 0.0158\n",
      "Epoch 1399/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.7245 - accuracy: 0.5666 - val_loss: 2.9763 - val_accuracy: 0.0158\n",
      "Epoch 1400/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7215 - accuracy: 0.5808 - val_loss: 2.8806 - val_accuracy: 0.0253\n",
      "Epoch 1401/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.7259 - accuracy: 0.5856 - val_loss: 2.0939 - val_accuracy: 0.0854\n",
      "Epoch 1402/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7181 - accuracy: 0.6014 - val_loss: 2.0781 - val_accuracy: 0.0190\n",
      "Epoch 1403/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7153 - accuracy: 0.5887 - val_loss: 2.0701 - val_accuracy: 0.0158\n",
      "Epoch 1404/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7134 - accuracy: 0.5998 - val_loss: 2.1397 - val_accuracy: 0.0380\n",
      "Epoch 1405/2000\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.7178 - accuracy: 0.5983 - val_loss: 2.0874 - val_accuracy: 0.0886\n",
      "Epoch 1406/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7039 - accuracy: 0.6133 - val_loss: 1.9973 - val_accuracy: 0.1139\n",
      "Epoch 1407/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7000 - accuracy: 0.6141 - val_loss: 1.7518 - val_accuracy: 0.4968\n",
      "Epoch 1408/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6904 - accuracy: 0.6284 - val_loss: 1.5886 - val_accuracy: 0.4905\n",
      "Epoch 1409/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.6829 - accuracy: 0.6442 - val_loss: 1.4435 - val_accuracy: 0.5032\n",
      "Epoch 1410/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.6747 - accuracy: 0.6434 - val_loss: 1.2099 - val_accuracy: 0.4968\n",
      "Epoch 1411/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6624 - accuracy: 0.6593 - val_loss: 0.9956 - val_accuracy: 0.4968\n",
      "Epoch 1412/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6576 - accuracy: 0.6664 - val_loss: 0.9179 - val_accuracy: 0.4937\n",
      "Epoch 1413/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6448 - accuracy: 0.6815 - val_loss: 0.8697 - val_accuracy: 0.4937\n",
      "Epoch 1414/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.6305 - accuracy: 0.6997 - val_loss: 0.8716 - val_accuracy: 0.4620\n",
      "Epoch 1415/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6184 - accuracy: 0.7179 - val_loss: 1.0262 - val_accuracy: 0.5190\n",
      "Epoch 1416/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5981 - accuracy: 0.7338 - val_loss: 1.7980 - val_accuracy: 0.0253\n",
      "Epoch 1417/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5850 - accuracy: 0.7520 - val_loss: 2.8243 - val_accuracy: 0.0253\n",
      "Epoch 1418/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.5784 - accuracy: 0.7575 - val_loss: 1.5964 - val_accuracy: 0.2057\n",
      "Epoch 1419/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5643 - accuracy: 0.7647 - val_loss: 2.1584 - val_accuracy: 0.1994\n",
      "Epoch 1420/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5489 - accuracy: 0.7797 - val_loss: 3.0703 - val_accuracy: 0.2563\n",
      "Epoch 1421/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5536 - accuracy: 0.7710 - val_loss: 2.8608 - val_accuracy: 0.5032\n",
      "Epoch 1422/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5206 - accuracy: 0.7995 - val_loss: 7.5977 - val_accuracy: 0.0348\n",
      "Epoch 1423/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.4838 - accuracy: 0.8265 - val_loss: 7.9849 - val_accuracy: 0.0222\n",
      "Epoch 1424/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4815 - accuracy: 0.8296 - val_loss: 8.0978 - val_accuracy: 0.0222\n",
      "Epoch 1425/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7146 - accuracy: 0.6680 - val_loss: 6.8511 - val_accuracy: 0.0000e+00\n",
      "Epoch 1426/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7151 - accuracy: 0.6181 - val_loss: 7.3502 - val_accuracy: 0.0000e+00\n",
      "Epoch 1427/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.7551 - accuracy: 0.6117 - val_loss: 8.3434 - val_accuracy: 0.0000e+00\n",
      "Epoch 1428/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6824 - accuracy: 0.6513 - val_loss: 7.6827 - val_accuracy: 0.0253\n",
      "Epoch 1429/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6664 - accuracy: 0.6743 - val_loss: 8.7866 - val_accuracy: 0.0633\n",
      "Epoch 1430/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6507 - accuracy: 0.6910 - val_loss: 9.9796 - val_accuracy: 0.1171\n",
      "Epoch 1431/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.6335 - accuracy: 0.6886 - val_loss: 9.7835 - val_accuracy: 0.1234\n",
      "Epoch 1432/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6103 - accuracy: 0.6941 - val_loss: 9.5063 - val_accuracy: 0.1329\n",
      "Epoch 1433/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5746 - accuracy: 0.7488 - val_loss: 9.4022 - val_accuracy: 0.0411\n",
      "Epoch 1434/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5455 - accuracy: 0.7655 - val_loss: 9.1341 - val_accuracy: 0.0063\n",
      "Epoch 1435/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5456 - accuracy: 0.7631 - val_loss: 9.2011 - val_accuracy: 0.0158\n",
      "Epoch 1436/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.5790 - accuracy: 0.7821 - val_loss: 5.8266 - val_accuracy: 0.0665\n",
      "Epoch 1437/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5213 - accuracy: 0.7916 - val_loss: 5.4728 - val_accuracy: 0.0190\n",
      "Epoch 1438/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5173 - accuracy: 0.7876 - val_loss: 6.4023 - val_accuracy: 0.0222\n",
      "Epoch 1439/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4820 - accuracy: 0.8201 - val_loss: 6.2333 - val_accuracy: 0.0095\n",
      "Epoch 1440/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.4427 - accuracy: 0.8455 - val_loss: 7.4383 - val_accuracy: 0.0158\n",
      "Epoch 1441/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4718 - accuracy: 0.8082 - val_loss: 10.5034 - val_accuracy: 0.0000e+00\n",
      "Epoch 1442/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4411 - accuracy: 0.8281 - val_loss: 11.2640 - val_accuracy: 0.1139\n",
      "Epoch 1443/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4512 - accuracy: 0.8209 - val_loss: 10.3280 - val_accuracy: 0.0791\n",
      "Epoch 1444/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.4412 - accuracy: 0.8328 - val_loss: 9.7247 - val_accuracy: 0.0981\n",
      "Epoch 1445/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3825 - accuracy: 0.8494 - val_loss: 10.2393 - val_accuracy: 0.1013\n",
      "Epoch 1446/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3986 - accuracy: 0.8542 - val_loss: 8.9640 - val_accuracy: 0.1930\n",
      "Epoch 1447/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3454 - accuracy: 0.8740 - val_loss: 3.5851 - val_accuracy: 0.2785\n",
      "Epoch 1448/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4527 - accuracy: 0.8233 - val_loss: 2.0665 - val_accuracy: 0.0570\n",
      "Epoch 1449/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.5182 - accuracy: 0.7734 - val_loss: 1.6560 - val_accuracy: 0.0633\n",
      "Epoch 1450/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4750 - accuracy: 0.8082 - val_loss: 1.5875 - val_accuracy: 0.0823\n",
      "Epoch 1451/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4225 - accuracy: 0.8391 - val_loss: 1.7281 - val_accuracy: 0.1709\n",
      "Epoch 1452/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3727 - accuracy: 0.8637 - val_loss: 1.5258 - val_accuracy: 0.4525\n",
      "Epoch 1453/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.3434 - accuracy: 0.8819 - val_loss: 1.4954 - val_accuracy: 0.3228\n",
      "Epoch 1454/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3369 - accuracy: 0.8859 - val_loss: 1.4986 - val_accuracy: 0.3608\n",
      "Epoch 1455/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3797 - accuracy: 0.8835 - val_loss: 1.2781 - val_accuracy: 0.4146\n",
      "Epoch 1456/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.9463 - accuracy: 0.5713 - val_loss: 1.3478 - val_accuracy: 0.4177\n",
      "Epoch 1457/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.8662 - accuracy: 0.5055 - val_loss: 3.6778 - val_accuracy: 0.3196\n",
      "Epoch 1458/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.8840 - accuracy: 0.5071 - val_loss: 2.2055 - val_accuracy: 0.4019\n",
      "Epoch 1459/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7764 - accuracy: 0.5277 - val_loss: 1.5744 - val_accuracy: 0.4494\n",
      "Epoch 1460/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.7902 - accuracy: 0.5341 - val_loss: 1.3563 - val_accuracy: 0.4335\n",
      "Epoch 1461/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.7646 - accuracy: 0.5254 - val_loss: 1.4268 - val_accuracy: 0.4146\n",
      "Epoch 1462/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.7479 - accuracy: 0.5269 - val_loss: 1.4471 - val_accuracy: 0.4114\n",
      "Epoch 1463/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7504 - accuracy: 0.5254 - val_loss: 1.5793 - val_accuracy: 0.4114\n",
      "Epoch 1464/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7820 - accuracy: 0.5071 - val_loss: 1.8157 - val_accuracy: 0.4114\n",
      "Epoch 1465/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7426 - accuracy: 0.5285 - val_loss: 2.9618 - val_accuracy: 0.0000e+00\n",
      "Epoch 1466/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.7455 - accuracy: 0.5317 - val_loss: 3.1591 - val_accuracy: 0.0000e+00\n",
      "Epoch 1467/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7440 - accuracy: 0.5380 - val_loss: 3.2124 - val_accuracy: 0.0000e+00\n",
      "Epoch 1468/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7450 - accuracy: 0.5357 - val_loss: 3.2507 - val_accuracy: 0.4114\n",
      "Epoch 1469/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7417 - accuracy: 0.5404 - val_loss: 3.1514 - val_accuracy: 0.4114\n",
      "Epoch 1470/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.7392 - accuracy: 0.5412 - val_loss: 3.0611 - val_accuracy: 0.4114\n",
      "Epoch 1471/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7376 - accuracy: 0.5365 - val_loss: 2.8138 - val_accuracy: 0.4114\n",
      "Epoch 1472/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7369 - accuracy: 0.5460 - val_loss: 2.4343 - val_accuracy: 0.4114\n",
      "Epoch 1473/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7395 - accuracy: 0.5388 - val_loss: 2.2010 - val_accuracy: 0.4114\n",
      "Epoch 1474/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.7429 - accuracy: 0.5388 - val_loss: 2.2212 - val_accuracy: 0.0000e+00\n",
      "Epoch 1475/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7401 - accuracy: 0.5388 - val_loss: 2.1475 - val_accuracy: 0.0000e+00\n",
      "Epoch 1476/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7374 - accuracy: 0.5372 - val_loss: 2.2556 - val_accuracy: 0.0000e+00\n",
      "Epoch 1477/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7362 - accuracy: 0.5586 - val_loss: 1.9995 - val_accuracy: 0.0000e+00\n",
      "Epoch 1478/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.7358 - accuracy: 0.5571 - val_loss: 1.7176 - val_accuracy: 0.0000e+00\n",
      "Epoch 1479/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7378 - accuracy: 0.5436 - val_loss: 1.5358 - val_accuracy: 0.0570\n",
      "Epoch 1480/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7327 - accuracy: 0.5571 - val_loss: 1.4368 - val_accuracy: 0.4241\n",
      "Epoch 1481/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7394 - accuracy: 0.5555 - val_loss: 1.4456 - val_accuracy: 0.4430\n",
      "Epoch 1482/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.7347 - accuracy: 0.5571 - val_loss: 1.9089 - val_accuracy: 0.0000e+00\n",
      "Epoch 1483/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.7351 - accuracy: 0.5689 - val_loss: 1.9766 - val_accuracy: 0.0000e+00\n",
      "Epoch 1484/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.7323 - accuracy: 0.5531 - val_loss: 1.9452 - val_accuracy: 0.0000e+00\n",
      "Epoch 1485/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7337 - accuracy: 0.5578 - val_loss: 1.8348 - val_accuracy: 0.0000e+00\n",
      "Epoch 1486/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7279 - accuracy: 0.5681 - val_loss: 1.8819 - val_accuracy: 0.0000e+00\n",
      "Epoch 1487/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7288 - accuracy: 0.5721 - val_loss: 1.8427 - val_accuracy: 0.0000e+00\n",
      "Epoch 1488/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7292 - accuracy: 0.5800 - val_loss: 1.6952 - val_accuracy: 0.0000e+00\n",
      "Epoch 1489/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7317 - accuracy: 0.5697 - val_loss: 1.5247 - val_accuracy: 0.0063\n",
      "Epoch 1490/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7256 - accuracy: 0.5745 - val_loss: 1.4155 - val_accuracy: 0.0348\n",
      "Epoch 1491/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7221 - accuracy: 0.5816 - val_loss: 1.3629 - val_accuracy: 0.1297\n",
      "Epoch 1492/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.7220 - accuracy: 0.5824 - val_loss: 1.2816 - val_accuracy: 0.4430\n",
      "Epoch 1493/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7195 - accuracy: 0.5769 - val_loss: 1.4472 - val_accuracy: 0.4842\n",
      "Epoch 1494/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7168 - accuracy: 0.5856 - val_loss: 1.6268 - val_accuracy: 0.4810\n",
      "Epoch 1495/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7267 - accuracy: 0.5697 - val_loss: 2.4602 - val_accuracy: 0.1329\n",
      "Epoch 1496/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7286 - accuracy: 0.5705 - val_loss: 3.9706 - val_accuracy: 0.1456\n",
      "Epoch 1497/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.7267 - accuracy: 0.5713 - val_loss: 4.7085 - val_accuracy: 0.0000e+00\n",
      "Epoch 1498/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7185 - accuracy: 0.5848 - val_loss: 5.1002 - val_accuracy: 0.0000e+00\n",
      "Epoch 1499/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7266 - accuracy: 0.5745 - val_loss: 5.6365 - val_accuracy: 0.0000e+00\n",
      "Epoch 1500/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7297 - accuracy: 0.5705 - val_loss: 5.4618 - val_accuracy: 0.0000e+00\n",
      "Epoch 1501/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 1.5544 - accuracy: 0.4952 - val_loss: 6.9155 - val_accuracy: 0.0095\n",
      "Epoch 1502/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.8384 - accuracy: 0.4889 - val_loss: 6.6476 - val_accuracy: 0.0253\n",
      "Epoch 1503/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7631 - accuracy: 0.5198 - val_loss: 6.9915 - val_accuracy: 0.0127\n",
      "Epoch 1504/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7769 - accuracy: 0.5127 - val_loss: 7.0604 - val_accuracy: 0.0000e+00\n",
      "Epoch 1505/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7623 - accuracy: 0.5404 - val_loss: 7.0060 - val_accuracy: 0.0032\n",
      "Epoch 1506/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.7521 - accuracy: 0.5372 - val_loss: 6.8548 - val_accuracy: 0.0158\n",
      "Epoch 1507/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7705 - accuracy: 0.5198 - val_loss: 6.6929 - val_accuracy: 0.0190\n",
      "Epoch 1508/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7504 - accuracy: 0.5293 - val_loss: 6.4310 - val_accuracy: 0.0127\n",
      "Epoch 1509/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7444 - accuracy: 0.5380 - val_loss: 6.1077 - val_accuracy: 0.0095\n",
      "Epoch 1510/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7376 - accuracy: 0.5420 - val_loss: 5.6864 - val_accuracy: 0.0253\n",
      "Epoch 1511/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.7506 - accuracy: 0.5555 - val_loss: 5.5563 - val_accuracy: 0.0063\n",
      "Epoch 1512/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7391 - accuracy: 0.5483 - val_loss: 12.1529 - val_accuracy: 0.0190\n",
      "Epoch 1513/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7458 - accuracy: 0.5475 - val_loss: 11.4574 - val_accuracy: 0.1519\n",
      "Epoch 1514/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.7377 - accuracy: 0.5539 - val_loss: 10.9968 - val_accuracy: 0.4114\n",
      "Epoch 1515/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7332 - accuracy: 0.5618 - val_loss: 10.3284 - val_accuracy: 0.4082\n",
      "Epoch 1516/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7403 - accuracy: 0.5618 - val_loss: 9.9584 - val_accuracy: 0.4114\n",
      "Epoch 1517/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7371 - accuracy: 0.5761 - val_loss: 9.7984 - val_accuracy: 0.4114\n",
      "Epoch 1518/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7316 - accuracy: 0.5681 - val_loss: 9.7117 - val_accuracy: 0.4114\n",
      "Epoch 1519/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7261 - accuracy: 0.5697 - val_loss: 9.6587 - val_accuracy: 0.4114\n",
      "Epoch 1520/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7346 - accuracy: 0.5792 - val_loss: 9.6271 - val_accuracy: 0.4114\n",
      "Epoch 1521/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7323 - accuracy: 0.5872 - val_loss: 9.5289 - val_accuracy: 0.4114\n",
      "Epoch 1522/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7176 - accuracy: 0.5983 - val_loss: 7.7424 - val_accuracy: 0.4114\n",
      "Epoch 1523/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.7232 - accuracy: 0.5824 - val_loss: 5.2047 - val_accuracy: 0.4114\n",
      "Epoch 1524/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.7146 - accuracy: 0.5927 - val_loss: 2.9784 - val_accuracy: 0.4114\n",
      "Epoch 1525/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7135 - accuracy: 0.5792 - val_loss: 2.9812 - val_accuracy: 0.0000e+00\n",
      "Epoch 1526/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7476 - accuracy: 0.5840 - val_loss: 2.3803 - val_accuracy: 0.4146\n",
      "Epoch 1527/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7315 - accuracy: 0.5848 - val_loss: 1.8301 - val_accuracy: 0.4114\n",
      "Epoch 1528/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.7233 - accuracy: 0.5856 - val_loss: 1.5356 - val_accuracy: 0.4146\n",
      "Epoch 1529/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7184 - accuracy: 0.5911 - val_loss: 1.3736 - val_accuracy: 0.4146\n",
      "Epoch 1530/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7154 - accuracy: 0.5864 - val_loss: 1.3064 - val_accuracy: 0.4051\n",
      "Epoch 1531/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7080 - accuracy: 0.6101 - val_loss: 1.1753 - val_accuracy: 0.4146\n",
      "Epoch 1532/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7121 - accuracy: 0.6046 - val_loss: 1.0980 - val_accuracy: 0.4114\n",
      "Epoch 1533/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7020 - accuracy: 0.6165 - val_loss: 1.0163 - val_accuracy: 0.4272\n",
      "Epoch 1534/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.7056 - accuracy: 0.6094 - val_loss: 1.4988 - val_accuracy: 0.0032\n",
      "Epoch 1535/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.6993 - accuracy: 0.6276 - val_loss: 1.8338 - val_accuracy: 0.0032\n",
      "Epoch 1536/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.6882 - accuracy: 0.6355 - val_loss: 1.8343 - val_accuracy: 0.0032\n",
      "Epoch 1537/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.7173 - accuracy: 0.6157 - val_loss: 0.8268 - val_accuracy: 0.5949\n",
      "Epoch 1538/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7019 - accuracy: 0.6268 - val_loss: 0.7725 - val_accuracy: 0.5886\n",
      "Epoch 1539/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6903 - accuracy: 0.6363 - val_loss: 0.7440 - val_accuracy: 0.5886\n",
      "Epoch 1540/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6848 - accuracy: 0.6395 - val_loss: 0.7535 - val_accuracy: 0.5886\n",
      "Epoch 1541/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.6918 - accuracy: 0.6434 - val_loss: 0.7491 - val_accuracy: 0.5886\n",
      "Epoch 1542/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.7056 - accuracy: 0.6212 - val_loss: 0.7342 - val_accuracy: 0.5886\n",
      "Epoch 1543/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6967 - accuracy: 0.6418 - val_loss: 0.7406 - val_accuracy: 0.5886\n",
      "Epoch 1544/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6963 - accuracy: 0.6212 - val_loss: 0.7353 - val_accuracy: 0.5886\n",
      "Epoch 1545/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.6854 - accuracy: 0.6410 - val_loss: 0.8888 - val_accuracy: 0.5886\n",
      "Epoch 1546/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.6800 - accuracy: 0.6426 - val_loss: 1.0533 - val_accuracy: 0.5886\n",
      "Epoch 1547/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6658 - accuracy: 0.6648 - val_loss: 1.1045 - val_accuracy: 0.5886\n",
      "Epoch 1548/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6704 - accuracy: 0.6704 - val_loss: 1.1064 - val_accuracy: 0.5886\n",
      "Epoch 1549/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6505 - accuracy: 0.6696 - val_loss: 1.0995 - val_accuracy: 0.5791\n",
      "Epoch 1550/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.6466 - accuracy: 0.6807 - val_loss: 1.0057 - val_accuracy: 0.5886\n",
      "Epoch 1551/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.6468 - accuracy: 0.6830 - val_loss: 1.5913 - val_accuracy: 0.0728\n",
      "Epoch 1552/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6344 - accuracy: 0.7060 - val_loss: 1.6625 - val_accuracy: 0.0190\n",
      "Epoch 1553/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6221 - accuracy: 0.7092 - val_loss: 1.5407 - val_accuracy: 0.0475\n",
      "Epoch 1554/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.6132 - accuracy: 0.7187 - val_loss: 1.4676 - val_accuracy: 0.0949\n",
      "Epoch 1555/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.6294 - accuracy: 0.7116 - val_loss: 1.8641 - val_accuracy: 0.0032\n",
      "Epoch 1556/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6321 - accuracy: 0.6981 - val_loss: 2.1239 - val_accuracy: 0.0063\n",
      "Epoch 1557/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.6319 - accuracy: 0.7219 - val_loss: 2.3767 - val_accuracy: 0.0253\n",
      "Epoch 1558/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6255 - accuracy: 0.7203 - val_loss: 2.5767 - val_accuracy: 0.1013\n",
      "Epoch 1559/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.6419 - accuracy: 0.7139 - val_loss: 2.5323 - val_accuracy: 0.3323\n",
      "Epoch 1560/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6247 - accuracy: 0.7171 - val_loss: 2.2927 - val_accuracy: 0.3228\n",
      "Epoch 1561/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.6091 - accuracy: 0.7242 - val_loss: 2.0273 - val_accuracy: 0.3228\n",
      "Epoch 1562/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5921 - accuracy: 0.7369 - val_loss: 2.0192 - val_accuracy: 0.4051\n",
      "Epoch 1563/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.5967 - accuracy: 0.7433 - val_loss: 1.6741 - val_accuracy: 0.5886\n",
      "Epoch 1564/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5895 - accuracy: 0.7425 - val_loss: 1.6728 - val_accuracy: 0.5886\n",
      "Epoch 1565/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.5759 - accuracy: 0.7591 - val_loss: 1.7637 - val_accuracy: 0.1424\n",
      "Epoch 1566/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5683 - accuracy: 0.7631 - val_loss: 1.5184 - val_accuracy: 0.5886\n",
      "Epoch 1567/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.5866 - accuracy: 0.7448 - val_loss: 0.9601 - val_accuracy: 0.5886\n",
      "Epoch 1568/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6003 - accuracy: 0.7338 - val_loss: 1.1468 - val_accuracy: 0.5886\n",
      "Epoch 1569/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.5916 - accuracy: 0.7472 - val_loss: 1.2548 - val_accuracy: 0.5886\n",
      "Epoch 1570/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5940 - accuracy: 0.7369 - val_loss: 1.2815 - val_accuracy: 0.5886\n",
      "Epoch 1571/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6404 - accuracy: 0.6973 - val_loss: 1.2624 - val_accuracy: 0.5886\n",
      "Epoch 1572/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.6401 - accuracy: 0.6894 - val_loss: 1.4228 - val_accuracy: 0.1582\n",
      "Epoch 1573/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.6922 - accuracy: 0.6846 - val_loss: 1.4061 - val_accuracy: 0.1297\n",
      "Epoch 1574/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.6325 - accuracy: 0.7163 - val_loss: 1.6744 - val_accuracy: 0.5886\n",
      "Epoch 1575/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6135 - accuracy: 0.7314 - val_loss: 2.2942 - val_accuracy: 0.1044\n",
      "Epoch 1576/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.5928 - accuracy: 0.7433 - val_loss: 2.8581 - val_accuracy: 0.1519\n",
      "Epoch 1577/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6063 - accuracy: 0.7203 - val_loss: 3.1774 - val_accuracy: 0.1361\n",
      "Epoch 1578/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6037 - accuracy: 0.7211 - val_loss: 3.2701 - val_accuracy: 0.1203\n",
      "Epoch 1579/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5809 - accuracy: 0.7504 - val_loss: 3.2460 - val_accuracy: 0.1867\n",
      "Epoch 1580/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.5781 - accuracy: 0.7369 - val_loss: 3.3382 - val_accuracy: 0.1551\n",
      "Epoch 1581/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5658 - accuracy: 0.7567 - val_loss: 3.1043 - val_accuracy: 0.0759\n",
      "Epoch 1582/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5495 - accuracy: 0.7662 - val_loss: 3.1621 - val_accuracy: 0.0633\n",
      "Epoch 1583/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5514 - accuracy: 0.7567 - val_loss: 3.1449 - val_accuracy: 0.1108\n",
      "Epoch 1584/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.5481 - accuracy: 0.7559 - val_loss: 3.0548 - val_accuracy: 0.1139\n",
      "Epoch 1585/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.5441 - accuracy: 0.7647 - val_loss: 2.9607 - val_accuracy: 0.1614\n",
      "Epoch 1586/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5537 - accuracy: 0.7528 - val_loss: 2.7299 - val_accuracy: 0.1804\n",
      "Epoch 1587/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5286 - accuracy: 0.7726 - val_loss: 2.8323 - val_accuracy: 0.1392\n",
      "Epoch 1588/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4960 - accuracy: 0.7979 - val_loss: 3.0970 - val_accuracy: 0.1171\n",
      "Epoch 1589/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.4968 - accuracy: 0.7924 - val_loss: 3.2192 - val_accuracy: 0.1677\n",
      "Epoch 1590/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.4947 - accuracy: 0.7987 - val_loss: 2.3329 - val_accuracy: 0.2690\n",
      "Epoch 1591/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.5114 - accuracy: 0.7868 - val_loss: 2.7702 - val_accuracy: 0.0665\n",
      "Epoch 1592/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.5109 - accuracy: 0.7884 - val_loss: 2.6299 - val_accuracy: 0.0981\n",
      "Epoch 1593/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4981 - accuracy: 0.8011 - val_loss: 2.4678 - val_accuracy: 0.1013\n",
      "Epoch 1594/2000\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.5042 - accuracy: 0.7932 - val_loss: 3.0027 - val_accuracy: 0.1108\n",
      "Epoch 1595/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5016 - accuracy: 0.7853 - val_loss: 3.7129 - val_accuracy: 0.0823\n",
      "Epoch 1596/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4902 - accuracy: 0.7876 - val_loss: 6.0188 - val_accuracy: 0.0949\n",
      "Epoch 1597/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4644 - accuracy: 0.8035 - val_loss: 6.4506 - val_accuracy: 0.2405\n",
      "Epoch 1598/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.4563 - accuracy: 0.8114 - val_loss: 6.6673 - val_accuracy: 0.2880\n",
      "Epoch 1599/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4366 - accuracy: 0.8249 - val_loss: 2.1797 - val_accuracy: 0.3734\n",
      "Epoch 1600/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.4832 - accuracy: 0.8122 - val_loss: 2.7171 - val_accuracy: 0.2247\n",
      "Epoch 1601/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.4887 - accuracy: 0.8090 - val_loss: 2.5111 - val_accuracy: 0.1013\n",
      "Epoch 1602/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.7081 - accuracy: 0.6434 - val_loss: 2.4959 - val_accuracy: 0.0000e+00\n",
      "Epoch 1603/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.7405 - accuracy: 0.6442 - val_loss: 2.1492 - val_accuracy: 0.0095\n",
      "Epoch 1604/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6654 - accuracy: 0.6537 - val_loss: 2.3691 - val_accuracy: 0.2373\n",
      "Epoch 1605/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6396 - accuracy: 0.6965 - val_loss: 2.5425 - val_accuracy: 0.2437\n",
      "Epoch 1606/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6158 - accuracy: 0.7282 - val_loss: 2.8710 - val_accuracy: 0.2184\n",
      "Epoch 1607/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.5802 - accuracy: 0.7583 - val_loss: 3.3635 - val_accuracy: 0.2152\n",
      "Epoch 1608/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5712 - accuracy: 0.7813 - val_loss: 4.2348 - val_accuracy: 0.2278\n",
      "Epoch 1609/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5477 - accuracy: 0.8051 - val_loss: 9.1912 - val_accuracy: 0.0759\n",
      "Epoch 1610/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5361 - accuracy: 0.8003 - val_loss: 9.3127 - val_accuracy: 0.0633\n",
      "Epoch 1611/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.5290 - accuracy: 0.8082 - val_loss: 9.0345 - val_accuracy: 0.1582\n",
      "Epoch 1612/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5152 - accuracy: 0.8090 - val_loss: 7.2768 - val_accuracy: 0.2025\n",
      "Epoch 1613/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5080 - accuracy: 0.8162 - val_loss: 4.2623 - val_accuracy: 0.2500\n",
      "Epoch 1614/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4954 - accuracy: 0.8177 - val_loss: 3.9894 - val_accuracy: 0.2184\n",
      "Epoch 1615/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.5291 - accuracy: 0.7948 - val_loss: 3.6028 - val_accuracy: 0.1930\n",
      "Epoch 1616/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.5533 - accuracy: 0.7726 - val_loss: 3.1840 - val_accuracy: 0.2880\n",
      "Epoch 1617/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.5430 - accuracy: 0.7813 - val_loss: 2.9809 - val_accuracy: 0.1930\n",
      "Epoch 1618/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5863 - accuracy: 0.7512 - val_loss: 2.6346 - val_accuracy: 0.2975\n",
      "Epoch 1619/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6099 - accuracy: 0.7322 - val_loss: 2.4747 - val_accuracy: 0.4304\n",
      "Epoch 1620/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.5860 - accuracy: 0.7425 - val_loss: 2.5852 - val_accuracy: 0.5538\n",
      "Epoch 1621/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5691 - accuracy: 0.7552 - val_loss: 2.9005 - val_accuracy: 0.4810\n",
      "Epoch 1622/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.5386 - accuracy: 0.7813 - val_loss: 3.1520 - val_accuracy: 0.4494\n",
      "Epoch 1623/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5310 - accuracy: 0.7797 - val_loss: 2.6628 - val_accuracy: 0.4652\n",
      "Epoch 1624/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5266 - accuracy: 0.7876 - val_loss: 3.9489 - val_accuracy: 0.1867\n",
      "Epoch 1625/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.5398 - accuracy: 0.7742 - val_loss: 6.4909 - val_accuracy: 0.0918\n",
      "Epoch 1626/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.5454 - accuracy: 0.7718 - val_loss: 6.0065 - val_accuracy: 0.0665\n",
      "Epoch 1627/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5458 - accuracy: 0.7726 - val_loss: 3.9753 - val_accuracy: 0.2310\n",
      "Epoch 1628/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5305 - accuracy: 0.7853 - val_loss: 6.8782 - val_accuracy: 0.0696\n",
      "Epoch 1629/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.5185 - accuracy: 0.7876 - val_loss: 7.7967 - val_accuracy: 0.0601\n",
      "Epoch 1630/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4752 - accuracy: 0.8019 - val_loss: 7.3338 - val_accuracy: 0.0696\n",
      "Epoch 1631/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5528 - accuracy: 0.7765 - val_loss: 2.7946 - val_accuracy: 0.0348\n",
      "Epoch 1632/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6213 - accuracy: 0.7139 - val_loss: 2.7312 - val_accuracy: 0.0411\n",
      "Epoch 1633/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.5878 - accuracy: 0.7393 - val_loss: 2.6371 - val_accuracy: 0.0316\n",
      "Epoch 1634/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5573 - accuracy: 0.7726 - val_loss: 2.7235 - val_accuracy: 0.0696\n",
      "Epoch 1635/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5382 - accuracy: 0.7765 - val_loss: 4.3203 - val_accuracy: 0.1013\n",
      "Epoch 1636/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5217 - accuracy: 0.7900 - val_loss: 8.0859 - val_accuracy: 0.1044\n",
      "Epoch 1637/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.5140 - accuracy: 0.7971 - val_loss: 7.3691 - val_accuracy: 0.2848\n",
      "Epoch 1638/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.4909 - accuracy: 0.8043 - val_loss: 7.0175 - val_accuracy: 0.4715\n",
      "Epoch 1639/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.4965 - accuracy: 0.8059 - val_loss: 6.5692 - val_accuracy: 0.4715\n",
      "Epoch 1640/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4907 - accuracy: 0.8059 - val_loss: 6.7934 - val_accuracy: 0.4652\n",
      "Epoch 1641/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.4920 - accuracy: 0.8090 - val_loss: 6.2322 - val_accuracy: 0.4620\n",
      "Epoch 1642/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.4998 - accuracy: 0.8043 - val_loss: 6.1803 - val_accuracy: 0.4462\n",
      "Epoch 1643/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4982 - accuracy: 0.8011 - val_loss: 4.9995 - val_accuracy: 0.4684\n",
      "Epoch 1644/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4933 - accuracy: 0.8003 - val_loss: 5.5895 - val_accuracy: 0.4462\n",
      "Epoch 1645/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5625 - accuracy: 0.7401 - val_loss: 4.7072 - val_accuracy: 0.4810\n",
      "Epoch 1646/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.5729 - accuracy: 0.7425 - val_loss: 6.1693 - val_accuracy: 0.4209\n",
      "Epoch 1647/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.5750 - accuracy: 0.7472 - val_loss: 6.7274 - val_accuracy: 0.4114\n",
      "Epoch 1648/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.5496 - accuracy: 0.7639 - val_loss: 6.8481 - val_accuracy: 0.4082\n",
      "Epoch 1649/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.5169 - accuracy: 0.7868 - val_loss: 6.9077 - val_accuracy: 0.4241\n",
      "Epoch 1650/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4777 - accuracy: 0.8043 - val_loss: 6.1565 - val_accuracy: 0.4367\n",
      "Epoch 1651/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.4636 - accuracy: 0.8177 - val_loss: 6.5623 - val_accuracy: 0.4399\n",
      "Epoch 1652/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4734 - accuracy: 0.8154 - val_loss: 6.4024 - val_accuracy: 0.4430\n",
      "Epoch 1653/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4712 - accuracy: 0.8090 - val_loss: 5.6695 - val_accuracy: 0.4525\n",
      "Epoch 1654/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.5414 - accuracy: 0.7694 - val_loss: 1.9085 - val_accuracy: 0.4494\n",
      "Epoch 1655/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.5516 - accuracy: 0.7472 - val_loss: 1.3873 - val_accuracy: 0.4209\n",
      "Epoch 1656/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5433 - accuracy: 0.7599 - val_loss: 1.8964 - val_accuracy: 0.4304\n",
      "Epoch 1657/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5040 - accuracy: 0.7908 - val_loss: 3.4511 - val_accuracy: 0.4082\n",
      "Epoch 1658/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4709 - accuracy: 0.8114 - val_loss: 6.5819 - val_accuracy: 0.4209\n",
      "Epoch 1659/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.4504 - accuracy: 0.8122 - val_loss: 6.5121 - val_accuracy: 0.4114\n",
      "Epoch 1660/2000\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 0.4225 - accuracy: 0.8288 - val_loss: 6.4409 - val_accuracy: 0.3924\n",
      "Epoch 1661/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4116 - accuracy: 0.8296 - val_loss: 6.6104 - val_accuracy: 0.4051\n",
      "Epoch 1662/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.3998 - accuracy: 0.8328 - val_loss: 6.6661 - val_accuracy: 0.3924\n",
      "Epoch 1663/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4347 - accuracy: 0.8320 - val_loss: 6.9948 - val_accuracy: 0.3956\n",
      "Epoch 1664/2000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.7051 - accuracy: 0.7528 - val_loss: 5.8742 - val_accuracy: 0.4304\n",
      "Epoch 1665/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5924 - accuracy: 0.7401 - val_loss: 1.2016 - val_accuracy: 0.4335\n",
      "Epoch 1666/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5693 - accuracy: 0.7417 - val_loss: 1.4551 - val_accuracy: 0.4335\n",
      "Epoch 1667/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5124 - accuracy: 0.7805 - val_loss: 5.7152 - val_accuracy: 0.4557\n",
      "Epoch 1668/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4664 - accuracy: 0.8059 - val_loss: 6.4412 - val_accuracy: 0.4494\n",
      "Epoch 1669/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.4458 - accuracy: 0.8304 - val_loss: 6.3428 - val_accuracy: 0.4462\n",
      "Epoch 1670/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4808 - accuracy: 0.8114 - val_loss: 6.0498 - val_accuracy: 0.4399\n",
      "Epoch 1671/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5025 - accuracy: 0.8146 - val_loss: 6.1944 - val_accuracy: 0.4241\n",
      "Epoch 1672/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4691 - accuracy: 0.8138 - val_loss: 0.9604 - val_accuracy: 0.4589\n",
      "Epoch 1673/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.4821 - accuracy: 0.8035 - val_loss: 0.7209 - val_accuracy: 0.5190\n",
      "Epoch 1674/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4779 - accuracy: 0.8241 - val_loss: 0.7489 - val_accuracy: 0.5759\n",
      "Epoch 1675/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.4538 - accuracy: 0.8312 - val_loss: 0.7766 - val_accuracy: 0.5222\n",
      "Epoch 1676/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4039 - accuracy: 0.8566 - val_loss: 0.8599 - val_accuracy: 0.4778\n",
      "Epoch 1677/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4095 - accuracy: 0.8645 - val_loss: 1.0321 - val_accuracy: 0.4778\n",
      "Epoch 1678/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.4211 - accuracy: 0.8605 - val_loss: 2.0374 - val_accuracy: 0.4810\n",
      "Epoch 1679/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.4385 - accuracy: 0.8391 - val_loss: 2.7508 - val_accuracy: 0.4494\n",
      "Epoch 1680/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4433 - accuracy: 0.8320 - val_loss: 3.1029 - val_accuracy: 0.3766\n",
      "Epoch 1681/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4587 - accuracy: 0.8209 - val_loss: 3.9490 - val_accuracy: 0.4494\n",
      "Epoch 1682/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.4352 - accuracy: 0.8352 - val_loss: 2.5485 - val_accuracy: 0.4525\n",
      "Epoch 1683/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3891 - accuracy: 0.8574 - val_loss: 3.6250 - val_accuracy: 0.4557\n",
      "Epoch 1684/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3713 - accuracy: 0.8661 - val_loss: 5.6479 - val_accuracy: 0.4399\n",
      "Epoch 1685/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.3768 - accuracy: 0.8819 - val_loss: 6.1541 - val_accuracy: 0.4209\n",
      "Epoch 1686/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.4346 - accuracy: 0.8479 - val_loss: 6.8953 - val_accuracy: 0.0854\n",
      "Epoch 1687/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4684 - accuracy: 0.8051 - val_loss: 5.7111 - val_accuracy: 0.0411\n",
      "Epoch 1688/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4728 - accuracy: 0.8067 - val_loss: 6.1327 - val_accuracy: 0.1139\n",
      "Epoch 1689/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4974 - accuracy: 0.7924 - val_loss: 5.7675 - val_accuracy: 0.1709\n",
      "Epoch 1690/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6484 - accuracy: 0.7068 - val_loss: 1.5653 - val_accuracy: 0.2785\n",
      "Epoch 1691/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.6294 - accuracy: 0.6910 - val_loss: 1.4060 - val_accuracy: 0.3259\n",
      "Epoch 1692/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6131 - accuracy: 0.7147 - val_loss: 1.2888 - val_accuracy: 0.4272\n",
      "Epoch 1693/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6579 - accuracy: 0.6767 - val_loss: 2.3459 - val_accuracy: 0.5127\n",
      "Epoch 1694/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.6672 - accuracy: 0.6632 - val_loss: 2.7399 - val_accuracy: 0.3481\n",
      "Epoch 1695/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.6456 - accuracy: 0.6838 - val_loss: 2.3840 - val_accuracy: 0.2690\n",
      "Epoch 1696/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6308 - accuracy: 0.6997 - val_loss: 2.1261 - val_accuracy: 0.2342\n",
      "Epoch 1697/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6058 - accuracy: 0.7211 - val_loss: 1.9818 - val_accuracy: 0.2437\n",
      "Epoch 1698/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5758 - accuracy: 0.7441 - val_loss: 1.8560 - val_accuracy: 0.2563\n",
      "Epoch 1699/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5522 - accuracy: 0.7655 - val_loss: 1.8370 - val_accuracy: 0.2532\n",
      "Epoch 1700/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.5541 - accuracy: 0.7528 - val_loss: 1.7859 - val_accuracy: 0.3449\n",
      "Epoch 1701/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5547 - accuracy: 0.7512 - val_loss: 1.7389 - val_accuracy: 0.2120\n",
      "Epoch 1702/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.5287 - accuracy: 0.7631 - val_loss: 1.6566 - val_accuracy: 0.3576\n",
      "Epoch 1703/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5111 - accuracy: 0.7876 - val_loss: 2.3171 - val_accuracy: 0.4335\n",
      "Epoch 1704/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.5167 - accuracy: 0.7702 - val_loss: 2.7874 - val_accuracy: 0.4114\n",
      "Epoch 1705/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4971 - accuracy: 0.7829 - val_loss: 5.1741 - val_accuracy: 0.4019\n",
      "Epoch 1706/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5025 - accuracy: 0.7845 - val_loss: 5.4716 - val_accuracy: 0.4082\n",
      "Epoch 1707/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.4786 - accuracy: 0.7971 - val_loss: 6.0396 - val_accuracy: 0.4019\n",
      "Epoch 1708/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.4466 - accuracy: 0.8122 - val_loss: 6.2409 - val_accuracy: 0.3797\n",
      "Epoch 1709/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.4639 - accuracy: 0.8209 - val_loss: 6.7299 - val_accuracy: 0.3861\n",
      "Epoch 1710/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5151 - accuracy: 0.8003 - val_loss: 6.4937 - val_accuracy: 0.4082\n",
      "Epoch 1711/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5306 - accuracy: 0.7694 - val_loss: 5.8167 - val_accuracy: 0.4019\n",
      "Epoch 1712/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4932 - accuracy: 0.7932 - val_loss: 5.4755 - val_accuracy: 0.3987\n",
      "Epoch 1713/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.4537 - accuracy: 0.8146 - val_loss: 5.7699 - val_accuracy: 0.4177\n",
      "Epoch 1714/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4717 - accuracy: 0.8162 - val_loss: 5.9493 - val_accuracy: 0.4146\n",
      "Epoch 1715/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5724 - accuracy: 0.7884 - val_loss: 1.2159 - val_accuracy: 0.4684\n",
      "Epoch 1716/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6050 - accuracy: 0.7179 - val_loss: 0.7395 - val_accuracy: 0.5063\n",
      "Epoch 1717/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.6210 - accuracy: 0.7021 - val_loss: 0.8362 - val_accuracy: 0.5886\n",
      "Epoch 1718/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.6613 - accuracy: 0.6767 - val_loss: 1.6133 - val_accuracy: 0.5633\n",
      "Epoch 1719/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6560 - accuracy: 0.6680 - val_loss: 1.7604 - val_accuracy: 0.5316\n",
      "Epoch 1720/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6197 - accuracy: 0.7132 - val_loss: 1.5279 - val_accuracy: 0.5475\n",
      "Epoch 1721/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5845 - accuracy: 0.7314 - val_loss: 1.4345 - val_accuracy: 0.5538\n",
      "Epoch 1722/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.5577 - accuracy: 0.7599 - val_loss: 1.5882 - val_accuracy: 0.5759\n",
      "Epoch 1723/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.5418 - accuracy: 0.7662 - val_loss: 2.6027 - val_accuracy: 0.5791\n",
      "Epoch 1724/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5183 - accuracy: 0.7750 - val_loss: 4.5919 - val_accuracy: 0.0380\n",
      "Epoch 1725/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5206 - accuracy: 0.7789 - val_loss: 5.0619 - val_accuracy: 0.0190\n",
      "Epoch 1726/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.5165 - accuracy: 0.7948 - val_loss: 5.8891 - val_accuracy: 0.0253\n",
      "Epoch 1727/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5172 - accuracy: 0.7805 - val_loss: 7.1419 - val_accuracy: 0.0222\n",
      "Epoch 1728/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5031 - accuracy: 0.7868 - val_loss: 6.7777 - val_accuracy: 0.0222\n",
      "Epoch 1729/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.5045 - accuracy: 0.7861 - val_loss: 3.3050 - val_accuracy: 0.0759\n",
      "Epoch 1730/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.4769 - accuracy: 0.8154 - val_loss: 3.7726 - val_accuracy: 0.1424\n",
      "Epoch 1731/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4537 - accuracy: 0.8154 - val_loss: 4.3559 - val_accuracy: 0.1930\n",
      "Epoch 1732/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4283 - accuracy: 0.8320 - val_loss: 6.3342 - val_accuracy: 0.0886\n",
      "Epoch 1733/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4829 - accuracy: 0.8011 - val_loss: 6.2166 - val_accuracy: 0.1456\n",
      "Epoch 1734/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4774 - accuracy: 0.7924 - val_loss: 4.7604 - val_accuracy: 0.2532\n",
      "Epoch 1735/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.4652 - accuracy: 0.7995 - val_loss: 4.8364 - val_accuracy: 0.4146\n",
      "Epoch 1736/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.4449 - accuracy: 0.8201 - val_loss: 4.9137 - val_accuracy: 0.4557\n",
      "Epoch 1737/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4478 - accuracy: 0.8201 - val_loss: 2.7001 - val_accuracy: 0.5253\n",
      "Epoch 1738/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4279 - accuracy: 0.8304 - val_loss: 4.4057 - val_accuracy: 0.5032\n",
      "Epoch 1739/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.3714 - accuracy: 0.8574 - val_loss: 4.8835 - val_accuracy: 0.4842\n",
      "Epoch 1740/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4309 - accuracy: 0.8391 - val_loss: 4.9206 - val_accuracy: 0.4715\n",
      "Epoch 1741/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4446 - accuracy: 0.8209 - val_loss: 4.6977 - val_accuracy: 0.4747\n",
      "Epoch 1742/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4357 - accuracy: 0.8154 - val_loss: 5.2297 - val_accuracy: 0.4557\n",
      "Epoch 1743/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4080 - accuracy: 0.8447 - val_loss: 4.6108 - val_accuracy: 0.4589\n",
      "Epoch 1744/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.4383 - accuracy: 0.8352 - val_loss: 4.7817 - val_accuracy: 0.4272\n",
      "Epoch 1745/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3957 - accuracy: 0.8534 - val_loss: 5.3214 - val_accuracy: 0.4620\n",
      "Epoch 1746/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4079 - accuracy: 0.8526 - val_loss: 5.3014 - val_accuracy: 0.4589\n",
      "Epoch 1747/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3670 - accuracy: 0.8716 - val_loss: 4.9653 - val_accuracy: 0.4652\n",
      "Epoch 1748/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.4553 - accuracy: 0.8114 - val_loss: 1.2034 - val_accuracy: 0.4778\n",
      "Epoch 1749/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4092 - accuracy: 0.8447 - val_loss: 1.2704 - val_accuracy: 0.4462\n",
      "Epoch 1750/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3817 - accuracy: 0.8708 - val_loss: 1.3475 - val_accuracy: 0.4557\n",
      "Epoch 1751/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.3521 - accuracy: 0.8677 - val_loss: 1.5404 - val_accuracy: 0.4810\n",
      "Epoch 1752/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.7283 - accuracy: 0.7734 - val_loss: 1.1958 - val_accuracy: 0.4494\n",
      "Epoch 1753/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.7448 - accuracy: 0.6070 - val_loss: 0.8971 - val_accuracy: 0.5095\n",
      "Epoch 1754/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7217 - accuracy: 0.5998 - val_loss: 0.8013 - val_accuracy: 0.5665\n",
      "Epoch 1755/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.7154 - accuracy: 0.5983 - val_loss: 0.7876 - val_accuracy: 0.5823\n",
      "Epoch 1756/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7480 - accuracy: 0.6030 - val_loss: 0.9288 - val_accuracy: 0.5823\n",
      "Epoch 1757/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7296 - accuracy: 0.6101 - val_loss: 1.0502 - val_accuracy: 0.5380\n",
      "Epoch 1758/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7026 - accuracy: 0.6284 - val_loss: 1.2868 - val_accuracy: 0.5127\n",
      "Epoch 1759/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.6954 - accuracy: 0.6236 - val_loss: 1.5083 - val_accuracy: 0.4589\n",
      "Epoch 1760/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6977 - accuracy: 0.6157 - val_loss: 1.6289 - val_accuracy: 0.4146\n",
      "Epoch 1761/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.6806 - accuracy: 0.6363 - val_loss: 1.6315 - val_accuracy: 0.4304\n",
      "Epoch 1762/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6596 - accuracy: 0.6490 - val_loss: 1.5858 - val_accuracy: 0.4335\n",
      "Epoch 1763/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6392 - accuracy: 0.6775 - val_loss: 1.6620 - val_accuracy: 0.4367\n",
      "Epoch 1764/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6315 - accuracy: 0.6846 - val_loss: 1.6925 - val_accuracy: 0.5095\n",
      "Epoch 1765/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6052 - accuracy: 0.7124 - val_loss: 2.9312 - val_accuracy: 0.4905\n",
      "Epoch 1766/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.5958 - accuracy: 0.7195 - val_loss: 3.1607 - val_accuracy: 0.4589\n",
      "Epoch 1767/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5703 - accuracy: 0.7361 - val_loss: 2.6887 - val_accuracy: 0.4715\n",
      "Epoch 1768/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5547 - accuracy: 0.7330 - val_loss: 2.5297 - val_accuracy: 0.4399\n",
      "Epoch 1769/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5595 - accuracy: 0.7290 - val_loss: 2.7550 - val_accuracy: 0.4842\n",
      "Epoch 1770/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.5419 - accuracy: 0.7480 - val_loss: 3.3046 - val_accuracy: 0.4272\n",
      "Epoch 1771/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5483 - accuracy: 0.7409 - val_loss: 5.8747 - val_accuracy: 0.4146\n",
      "Epoch 1772/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5718 - accuracy: 0.7266 - val_loss: 1.7351 - val_accuracy: 0.4146\n",
      "Epoch 1773/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5393 - accuracy: 0.7678 - val_loss: 4.1951 - val_accuracy: 0.4589\n",
      "Epoch 1774/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4974 - accuracy: 0.7678 - val_loss: 5.0596 - val_accuracy: 0.4114\n",
      "Epoch 1775/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.5519 - accuracy: 0.7559 - val_loss: 4.0388 - val_accuracy: 0.4272\n",
      "Epoch 1776/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5085 - accuracy: 0.7647 - val_loss: 1.8660 - val_accuracy: 0.4114\n",
      "Epoch 1777/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5150 - accuracy: 0.7884 - val_loss: 4.0358 - val_accuracy: 0.4177\n",
      "Epoch 1778/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4981 - accuracy: 0.7884 - val_loss: 4.1037 - val_accuracy: 0.4114\n",
      "Epoch 1779/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.4498 - accuracy: 0.8003 - val_loss: 4.0870 - val_accuracy: 0.4146\n",
      "Epoch 1780/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4415 - accuracy: 0.8051 - val_loss: 4.0599 - val_accuracy: 0.4241\n",
      "Epoch 1781/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4254 - accuracy: 0.8082 - val_loss: 4.1131 - val_accuracy: 0.4177\n",
      "Epoch 1782/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4542 - accuracy: 0.8090 - val_loss: 3.5325 - val_accuracy: 0.4778\n",
      "Epoch 1783/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.4849 - accuracy: 0.7694 - val_loss: 1.0296 - val_accuracy: 0.5158\n",
      "Epoch 1784/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.4627 - accuracy: 0.7742 - val_loss: 1.0362 - val_accuracy: 0.5032\n",
      "Epoch 1785/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5046 - accuracy: 0.7987 - val_loss: 1.2438 - val_accuracy: 0.4241\n",
      "Epoch 1786/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5171 - accuracy: 0.7900 - val_loss: 1.2601 - val_accuracy: 0.4272\n",
      "Epoch 1787/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4380 - accuracy: 0.7964 - val_loss: 1.2950 - val_accuracy: 0.4399\n",
      "Epoch 1788/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.4378 - accuracy: 0.8312 - val_loss: 1.6181 - val_accuracy: 0.4494\n",
      "Epoch 1789/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4034 - accuracy: 0.8320 - val_loss: 1.9113 - val_accuracy: 0.4589\n",
      "Epoch 1790/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3698 - accuracy: 0.8439 - val_loss: 4.0334 - val_accuracy: 0.4272\n",
      "Epoch 1791/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4152 - accuracy: 0.8162 - val_loss: 1.7022 - val_accuracy: 0.4747\n",
      "Epoch 1792/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.7306 - accuracy: 0.6616 - val_loss: 1.0471 - val_accuracy: 0.5823\n",
      "Epoch 1793/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6677 - accuracy: 0.6823 - val_loss: 0.7306 - val_accuracy: 0.6013\n",
      "Epoch 1794/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6355 - accuracy: 0.7052 - val_loss: 0.8018 - val_accuracy: 0.5949\n",
      "Epoch 1795/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6123 - accuracy: 0.7195 - val_loss: 0.9692 - val_accuracy: 0.5886\n",
      "Epoch 1796/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.5913 - accuracy: 0.7322 - val_loss: 3.2964 - val_accuracy: 0.5886\n",
      "Epoch 1797/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.5674 - accuracy: 0.7567 - val_loss: 3.9066 - val_accuracy: 0.5886\n",
      "Epoch 1798/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.5534 - accuracy: 0.7575 - val_loss: 2.8284 - val_accuracy: 0.4367\n",
      "Epoch 1799/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.5194 - accuracy: 0.7813 - val_loss: 4.1250 - val_accuracy: 0.4494\n",
      "Epoch 1800/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5070 - accuracy: 0.7781 - val_loss: 4.3411 - val_accuracy: 0.4525\n",
      "Epoch 1801/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.5133 - accuracy: 0.7718 - val_loss: 3.5388 - val_accuracy: 0.4525\n",
      "Epoch 1802/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4679 - accuracy: 0.7932 - val_loss: 3.3539 - val_accuracy: 0.3892\n",
      "Epoch 1803/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4683 - accuracy: 0.7900 - val_loss: 3.8728 - val_accuracy: 0.3671\n",
      "Epoch 1804/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4833 - accuracy: 0.8074 - val_loss: 3.6832 - val_accuracy: 0.4557\n",
      "Epoch 1805/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4426 - accuracy: 0.8074 - val_loss: 2.8869 - val_accuracy: 0.5475\n",
      "Epoch 1806/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.4667 - accuracy: 0.7884 - val_loss: 3.1286 - val_accuracy: 0.5316\n",
      "Epoch 1807/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6421 - accuracy: 0.7100 - val_loss: 0.7241 - val_accuracy: 0.5886\n",
      "Epoch 1808/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6864 - accuracy: 0.6624 - val_loss: 0.7827 - val_accuracy: 0.5601\n",
      "Epoch 1809/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6758 - accuracy: 0.6854 - val_loss: 0.8322 - val_accuracy: 0.5570\n",
      "Epoch 1810/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.6410 - accuracy: 0.7092 - val_loss: 0.8556 - val_accuracy: 0.5506\n",
      "Epoch 1811/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6181 - accuracy: 0.7219 - val_loss: 0.8900 - val_accuracy: 0.5728\n",
      "Epoch 1812/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6018 - accuracy: 0.7417 - val_loss: 0.9250 - val_accuracy: 0.5823\n",
      "Epoch 1813/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5881 - accuracy: 0.7480 - val_loss: 0.9412 - val_accuracy: 0.5949\n",
      "Epoch 1814/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.5819 - accuracy: 0.7536 - val_loss: 0.9651 - val_accuracy: 0.5854\n",
      "Epoch 1815/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.5748 - accuracy: 0.7559 - val_loss: 0.9043 - val_accuracy: 0.5949\n",
      "Epoch 1816/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5549 - accuracy: 0.7789 - val_loss: 0.9882 - val_accuracy: 0.5886\n",
      "Epoch 1817/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5408 - accuracy: 0.7900 - val_loss: 1.1226 - val_accuracy: 0.5665\n",
      "Epoch 1818/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5353 - accuracy: 0.7892 - val_loss: 1.4747 - val_accuracy: 0.5633\n",
      "Epoch 1819/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.5157 - accuracy: 0.7995 - val_loss: 2.9167 - val_accuracy: 0.5633\n",
      "Epoch 1820/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5070 - accuracy: 0.8051 - val_loss: 7.3738 - val_accuracy: 0.5570\n",
      "Epoch 1821/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4998 - accuracy: 0.8122 - val_loss: 7.6821 - val_accuracy: 0.5222\n",
      "Epoch 1822/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4891 - accuracy: 0.8241 - val_loss: 7.7153 - val_accuracy: 0.5158\n",
      "Epoch 1823/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.4973 - accuracy: 0.8051 - val_loss: 7.7988 - val_accuracy: 0.3797\n",
      "Epoch 1824/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4602 - accuracy: 0.8201 - val_loss: 7.9807 - val_accuracy: 0.3734\n",
      "Epoch 1825/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4560 - accuracy: 0.8296 - val_loss: 8.2123 - val_accuracy: 0.3608\n",
      "Epoch 1826/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.4470 - accuracy: 0.8336 - val_loss: 8.2124 - val_accuracy: 0.2785\n",
      "Epoch 1827/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4517 - accuracy: 0.8344 - val_loss: 8.1273 - val_accuracy: 0.3038\n",
      "Epoch 1828/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.4179 - accuracy: 0.8455 - val_loss: 7.4811 - val_accuracy: 0.0601\n",
      "Epoch 1829/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.4369 - accuracy: 0.8423 - val_loss: 6.2458 - val_accuracy: 0.0791\n",
      "Epoch 1830/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4400 - accuracy: 0.8233 - val_loss: 7.1839 - val_accuracy: 0.2278\n",
      "Epoch 1831/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7708 - accuracy: 0.6355 - val_loss: 6.6586 - val_accuracy: 0.1835\n",
      "Epoch 1832/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.7298 - accuracy: 0.6371 - val_loss: 4.8792 - val_accuracy: 0.0316\n",
      "Epoch 1833/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6919 - accuracy: 0.6490 - val_loss: 4.2226 - val_accuracy: 0.0918\n",
      "Epoch 1834/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6850 - accuracy: 0.6276 - val_loss: 4.9892 - val_accuracy: 0.2753\n",
      "Epoch 1835/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6733 - accuracy: 0.6498 - val_loss: 7.0797 - val_accuracy: 0.3703\n",
      "Epoch 1836/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6548 - accuracy: 0.6870 - val_loss: 7.9023 - val_accuracy: 0.0316\n",
      "Epoch 1837/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.6523 - accuracy: 0.6910 - val_loss: 7.7105 - val_accuracy: 0.0127\n",
      "Epoch 1838/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6373 - accuracy: 0.6973 - val_loss: 7.7234 - val_accuracy: 0.0696\n",
      "Epoch 1839/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6621 - accuracy: 0.6791 - val_loss: 6.8542 - val_accuracy: 0.0728\n",
      "Epoch 1840/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.6381 - accuracy: 0.7060 - val_loss: 3.6048 - val_accuracy: 0.0411\n",
      "Epoch 1841/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.6413 - accuracy: 0.7036 - val_loss: 3.4047 - val_accuracy: 0.1203\n",
      "Epoch 1842/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6152 - accuracy: 0.7211 - val_loss: 7.0338 - val_accuracy: 0.0000e+00\n",
      "Epoch 1843/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6006 - accuracy: 0.7441 - val_loss: 7.9680 - val_accuracy: 0.0000e+00\n",
      "Epoch 1844/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5967 - accuracy: 0.7345 - val_loss: 8.0810 - val_accuracy: 0.0032\n",
      "Epoch 1845/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.5755 - accuracy: 0.7631 - val_loss: 8.0797 - val_accuracy: 0.0000e+00\n",
      "Epoch 1846/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5588 - accuracy: 0.7718 - val_loss: 7.2953 - val_accuracy: 0.0601\n",
      "Epoch 1847/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5481 - accuracy: 0.7932 - val_loss: 4.3779 - val_accuracy: 0.1361\n",
      "Epoch 1848/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5265 - accuracy: 0.8027 - val_loss: 4.2823 - val_accuracy: 0.1835\n",
      "Epoch 1849/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.7004 - accuracy: 0.7908 - val_loss: 7.6751 - val_accuracy: 0.0063\n",
      "Epoch 1850/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.6397 - accuracy: 0.7187 - val_loss: 8.1787 - val_accuracy: 0.0000e+00\n",
      "Epoch 1851/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6185 - accuracy: 0.7385 - val_loss: 2.8495 - val_accuracy: 0.4019\n",
      "Epoch 1852/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5835 - accuracy: 0.7631 - val_loss: 1.9983 - val_accuracy: 0.4177\n",
      "Epoch 1853/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5423 - accuracy: 0.7781 - val_loss: 1.8534 - val_accuracy: 0.4272\n",
      "Epoch 1854/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.5247 - accuracy: 0.8019 - val_loss: 1.8084 - val_accuracy: 0.4209\n",
      "Epoch 1855/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5018 - accuracy: 0.8146 - val_loss: 1.7412 - val_accuracy: 0.4114\n",
      "Epoch 1856/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4941 - accuracy: 0.8122 - val_loss: 1.6171 - val_accuracy: 0.4146\n",
      "Epoch 1857/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4802 - accuracy: 0.8249 - val_loss: 1.4695 - val_accuracy: 0.4304\n",
      "Epoch 1858/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4806 - accuracy: 0.8114 - val_loss: 1.2343 - val_accuracy: 0.4241\n",
      "Epoch 1859/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.5112 - accuracy: 0.8090 - val_loss: 1.7118 - val_accuracy: 0.4272\n",
      "Epoch 1860/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4882 - accuracy: 0.8090 - val_loss: 6.3264 - val_accuracy: 0.0316\n",
      "Epoch 1861/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4890 - accuracy: 0.7995 - val_loss: 6.4020 - val_accuracy: 0.1234\n",
      "Epoch 1862/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4789 - accuracy: 0.8090 - val_loss: 6.4391 - val_accuracy: 0.1804\n",
      "Epoch 1863/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.4480 - accuracy: 0.8312 - val_loss: 4.1019 - val_accuracy: 0.3639\n",
      "Epoch 1864/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4254 - accuracy: 0.8447 - val_loss: 3.4103 - val_accuracy: 0.2468\n",
      "Epoch 1865/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4361 - accuracy: 0.8613 - val_loss: 2.9072 - val_accuracy: 0.2595\n",
      "Epoch 1866/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4163 - accuracy: 0.8590 - val_loss: 1.5063 - val_accuracy: 0.4399\n",
      "Epoch 1867/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.4114 - accuracy: 0.8558 - val_loss: 1.3519 - val_accuracy: 0.4241\n",
      "Epoch 1868/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4111 - accuracy: 0.8391 - val_loss: 1.3641 - val_accuracy: 0.4778\n",
      "Epoch 1869/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3925 - accuracy: 0.8582 - val_loss: 5.0082 - val_accuracy: 0.4304\n",
      "Epoch 1870/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4045 - accuracy: 0.8518 - val_loss: 4.8114 - val_accuracy: 0.4715\n",
      "Epoch 1871/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3735 - accuracy: 0.8550 - val_loss: 4.6445 - val_accuracy: 0.4430\n",
      "Epoch 1872/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.3519 - accuracy: 0.8621 - val_loss: 4.4893 - val_accuracy: 0.4557\n",
      "Epoch 1873/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3395 - accuracy: 0.8661 - val_loss: 1.7801 - val_accuracy: 0.4620\n",
      "Epoch 1874/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3028 - accuracy: 0.8875 - val_loss: 2.4108 - val_accuracy: 0.4589\n",
      "Epoch 1875/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3197 - accuracy: 0.8835 - val_loss: 2.3740 - val_accuracy: 0.4557\n",
      "Epoch 1876/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.3506 - accuracy: 0.8621 - val_loss: 2.1847 - val_accuracy: 0.4715\n",
      "Epoch 1877/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4054 - accuracy: 0.8621 - val_loss: 4.6865 - val_accuracy: 0.4557\n",
      "Epoch 1878/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4613 - accuracy: 0.8082 - val_loss: 1.4249 - val_accuracy: 0.4652\n",
      "Epoch 1879/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5919 - accuracy: 0.7179 - val_loss: 1.0669 - val_accuracy: 0.4430\n",
      "Epoch 1880/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.5838 - accuracy: 0.7306 - val_loss: 0.9891 - val_accuracy: 0.4620\n",
      "Epoch 1881/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5403 - accuracy: 0.7750 - val_loss: 1.0347 - val_accuracy: 0.4399\n",
      "Epoch 1882/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4935 - accuracy: 0.8035 - val_loss: 1.0518 - val_accuracy: 0.4430\n",
      "Epoch 1883/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4593 - accuracy: 0.8185 - val_loss: 1.1508 - val_accuracy: 0.4430\n",
      "Epoch 1884/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4277 - accuracy: 0.8415 - val_loss: 1.3157 - val_accuracy: 0.4399\n",
      "Epoch 1885/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.4109 - accuracy: 0.8463 - val_loss: 1.4581 - val_accuracy: 0.4335\n",
      "Epoch 1886/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4091 - accuracy: 0.8407 - val_loss: 1.6002 - val_accuracy: 0.4399\n",
      "Epoch 1887/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4010 - accuracy: 0.8487 - val_loss: 2.1417 - val_accuracy: 0.4494\n",
      "Epoch 1888/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4269 - accuracy: 0.8439 - val_loss: 4.9583 - val_accuracy: 0.4557\n",
      "Epoch 1889/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.4037 - accuracy: 0.8621 - val_loss: 5.6197 - val_accuracy: 0.4146\n",
      "Epoch 1890/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4526 - accuracy: 0.8209 - val_loss: 5.5419 - val_accuracy: 0.4652\n",
      "Epoch 1891/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4852 - accuracy: 0.8019 - val_loss: 5.2222 - val_accuracy: 0.4430\n",
      "Epoch 1892/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4756 - accuracy: 0.7956 - val_loss: 5.1025 - val_accuracy: 0.4557\n",
      "Epoch 1893/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4579 - accuracy: 0.8074 - val_loss: 5.2818 - val_accuracy: 0.4715\n",
      "Epoch 1894/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.4306 - accuracy: 0.8257 - val_loss: 5.2729 - val_accuracy: 0.4715\n",
      "Epoch 1895/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4130 - accuracy: 0.8479 - val_loss: 5.8337 - val_accuracy: 0.4589\n",
      "Epoch 1896/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4021 - accuracy: 0.8471 - val_loss: 1.3663 - val_accuracy: 0.4937\n",
      "Epoch 1897/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3990 - accuracy: 0.8494 - val_loss: 1.2003 - val_accuracy: 0.4810\n",
      "Epoch 1898/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.3764 - accuracy: 0.8582 - val_loss: 1.3207 - val_accuracy: 0.4842\n",
      "Epoch 1899/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3724 - accuracy: 0.8637 - val_loss: 1.5698 - val_accuracy: 0.4747\n",
      "Epoch 1900/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3838 - accuracy: 0.8526 - val_loss: 1.7742 - val_accuracy: 0.5063\n",
      "Epoch 1901/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4312 - accuracy: 0.8471 - val_loss: 2.0942 - val_accuracy: 0.4968\n",
      "Epoch 1902/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.3837 - accuracy: 0.8621 - val_loss: 2.5508 - val_accuracy: 0.4905\n",
      "Epoch 1903/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3925 - accuracy: 0.8574 - val_loss: 2.5619 - val_accuracy: 0.5127\n",
      "Epoch 1904/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3995 - accuracy: 0.8463 - val_loss: 1.7010 - val_accuracy: 0.4747\n",
      "Epoch 1905/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4380 - accuracy: 0.8376 - val_loss: 1.6265 - val_accuracy: 0.4684\n",
      "Epoch 1906/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4277 - accuracy: 0.8304 - val_loss: 1.5027 - val_accuracy: 0.4684\n",
      "Epoch 1907/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.4010 - accuracy: 0.8447 - val_loss: 1.9801 - val_accuracy: 0.4684\n",
      "Epoch 1908/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4007 - accuracy: 0.8550 - val_loss: 5.2511 - val_accuracy: 0.4525\n",
      "Epoch 1909/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3485 - accuracy: 0.8661 - val_loss: 3.0809 - val_accuracy: 0.4589\n",
      "Epoch 1910/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3678 - accuracy: 0.8613 - val_loss: 3.7866 - val_accuracy: 0.4905\n",
      "Epoch 1911/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.3501 - accuracy: 0.8708 - val_loss: 4.1118 - val_accuracy: 0.4968\n",
      "Epoch 1912/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3514 - accuracy: 0.8677 - val_loss: 6.5438 - val_accuracy: 0.5095\n",
      "Epoch 1913/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3422 - accuracy: 0.8724 - val_loss: 6.7874 - val_accuracy: 0.4778\n",
      "Epoch 1914/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3371 - accuracy: 0.8780 - val_loss: 6.5939 - val_accuracy: 0.4652\n",
      "Epoch 1915/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.3728 - accuracy: 0.8827 - val_loss: 4.0038 - val_accuracy: 0.4810\n",
      "Epoch 1916/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3127 - accuracy: 0.8867 - val_loss: 4.0399 - val_accuracy: 0.4272\n",
      "Epoch 1917/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3209 - accuracy: 0.8906 - val_loss: 4.4404 - val_accuracy: 0.4241\n",
      "Epoch 1918/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3273 - accuracy: 0.8875 - val_loss: 5.6137 - val_accuracy: 0.2690\n",
      "Epoch 1919/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.3498 - accuracy: 0.8835 - val_loss: 2.1552 - val_accuracy: 0.2690\n",
      "Epoch 1920/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.3489 - accuracy: 0.8811 - val_loss: 2.3802 - val_accuracy: 0.2975\n",
      "Epoch 1921/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3146 - accuracy: 0.8835 - val_loss: 5.6347 - val_accuracy: 0.3038\n",
      "Epoch 1922/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.3451 - accuracy: 0.8851 - val_loss: 5.5677 - val_accuracy: 0.3354\n",
      "Epoch 1923/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3387 - accuracy: 0.8867 - val_loss: 5.3657 - val_accuracy: 0.2405\n",
      "Epoch 1924/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.3819 - accuracy: 0.8780 - val_loss: 5.5250 - val_accuracy: 0.2563\n",
      "Epoch 1925/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3822 - accuracy: 0.8859 - val_loss: 5.7004 - val_accuracy: 0.2785\n",
      "Epoch 1926/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3652 - accuracy: 0.8875 - val_loss: 5.8797 - val_accuracy: 0.3070\n",
      "Epoch 1927/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3178 - accuracy: 0.8906 - val_loss: 5.6377 - val_accuracy: 0.3228\n",
      "Epoch 1928/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.3346 - accuracy: 0.8867 - val_loss: 5.3905 - val_accuracy: 0.3165\n",
      "Epoch 1929/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.3790 - accuracy: 0.8685 - val_loss: 4.2747 - val_accuracy: 0.4019\n",
      "Epoch 1930/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.3164 - accuracy: 0.8899 - val_loss: 4.3805 - val_accuracy: 0.4399\n",
      "Epoch 1931/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3024 - accuracy: 0.8954 - val_loss: 4.7521 - val_accuracy: 0.4399\n",
      "Epoch 1932/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3243 - accuracy: 0.8819 - val_loss: 4.6042 - val_accuracy: 0.4146\n",
      "Epoch 1933/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.3001 - accuracy: 0.8891 - val_loss: 4.4614 - val_accuracy: 0.4430\n",
      "Epoch 1934/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.3344 - accuracy: 0.8875 - val_loss: 4.6797 - val_accuracy: 0.5032\n",
      "Epoch 1935/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.3373 - accuracy: 0.8962 - val_loss: 4.3380 - val_accuracy: 0.4842\n",
      "Epoch 1936/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6379 - accuracy: 0.8376 - val_loss: 3.7603 - val_accuracy: 0.4525\n",
      "Epoch 1937/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.5446 - accuracy: 0.7623 - val_loss: 1.8789 - val_accuracy: 0.4241\n",
      "Epoch 1938/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.6054 - accuracy: 0.7203 - val_loss: 2.5703 - val_accuracy: 0.4335\n",
      "Epoch 1939/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6050 - accuracy: 0.7345 - val_loss: 1.6635 - val_accuracy: 0.4304\n",
      "Epoch 1940/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5643 - accuracy: 0.7544 - val_loss: 1.6083 - val_accuracy: 0.4241\n",
      "Epoch 1941/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5294 - accuracy: 0.7853 - val_loss: 1.6741 - val_accuracy: 0.4272\n",
      "Epoch 1942/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.5138 - accuracy: 0.8035 - val_loss: 2.0128 - val_accuracy: 0.4335\n",
      "Epoch 1943/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4941 - accuracy: 0.8193 - val_loss: 4.8887 - val_accuracy: 0.4367\n",
      "Epoch 1944/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5647 - accuracy: 0.7789 - val_loss: 4.7836 - val_accuracy: 0.4399\n",
      "Epoch 1945/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.5643 - accuracy: 0.7845 - val_loss: 4.8021 - val_accuracy: 0.4367\n",
      "Epoch 1946/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.5503 - accuracy: 0.7940 - val_loss: 4.6205 - val_accuracy: 0.4177\n",
      "Epoch 1947/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5176 - accuracy: 0.8177 - val_loss: 4.6749 - val_accuracy: 0.4367\n",
      "Epoch 1948/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5030 - accuracy: 0.8320 - val_loss: 4.8085 - val_accuracy: 0.4399\n",
      "Epoch 1949/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4818 - accuracy: 0.8431 - val_loss: 4.7651 - val_accuracy: 0.4177\n",
      "Epoch 1950/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.5579 - accuracy: 0.8003 - val_loss: 0.9692 - val_accuracy: 0.4146\n",
      "Epoch 1951/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5484 - accuracy: 0.8067 - val_loss: 0.9285 - val_accuracy: 0.4114\n",
      "Epoch 1952/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6550 - accuracy: 0.7021 - val_loss: 0.9376 - val_accuracy: 0.4114\n",
      "Epoch 1953/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6380 - accuracy: 0.7060 - val_loss: 1.0340 - val_accuracy: 0.4114\n",
      "Epoch 1954/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.6145 - accuracy: 0.7211 - val_loss: 1.1456 - val_accuracy: 0.4114\n",
      "Epoch 1955/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.5820 - accuracy: 0.7536 - val_loss: 1.2949 - val_accuracy: 0.4114\n",
      "Epoch 1956/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5645 - accuracy: 0.7655 - val_loss: 4.4410 - val_accuracy: 0.4114\n",
      "Epoch 1957/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.5472 - accuracy: 0.7876 - val_loss: 5.7152 - val_accuracy: 0.4114\n",
      "Epoch 1958/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5379 - accuracy: 0.7861 - val_loss: 5.1206 - val_accuracy: 0.4241\n",
      "Epoch 1959/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.5261 - accuracy: 0.7979 - val_loss: 5.0711 - val_accuracy: 0.4367\n",
      "Epoch 1960/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.5055 - accuracy: 0.8074 - val_loss: 5.3824 - val_accuracy: 0.4399\n",
      "Epoch 1961/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4886 - accuracy: 0.8217 - val_loss: 5.5094 - val_accuracy: 0.4494\n",
      "Epoch 1962/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4807 - accuracy: 0.8265 - val_loss: 5.3860 - val_accuracy: 0.4430\n",
      "Epoch 1963/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.4554 - accuracy: 0.8455 - val_loss: 5.1782 - val_accuracy: 0.4209\n",
      "Epoch 1964/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4538 - accuracy: 0.8487 - val_loss: 5.4255 - val_accuracy: 0.4462\n",
      "Epoch 1965/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4495 - accuracy: 0.8534 - val_loss: 5.7723 - val_accuracy: 0.4462\n",
      "Epoch 1966/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4627 - accuracy: 0.8399 - val_loss: 5.2119 - val_accuracy: 0.4589\n",
      "Epoch 1967/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.4366 - accuracy: 0.8487 - val_loss: 5.8709 - val_accuracy: 0.4241\n",
      "Epoch 1968/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.4188 - accuracy: 0.8669 - val_loss: 6.1279 - val_accuracy: 0.4146\n",
      "Epoch 1969/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4801 - accuracy: 0.8613 - val_loss: 6.3498 - val_accuracy: 0.4272\n",
      "Epoch 1970/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3953 - accuracy: 0.8740 - val_loss: 6.6247 - val_accuracy: 0.3449\n",
      "Epoch 1971/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3819 - accuracy: 0.8835 - val_loss: 6.5746 - val_accuracy: 0.3924\n",
      "Epoch 1972/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.4063 - accuracy: 0.8716 - val_loss: 5.9981 - val_accuracy: 0.4335\n",
      "Epoch 1973/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3992 - accuracy: 0.8574 - val_loss: 5.9666 - val_accuracy: 0.3449\n",
      "Epoch 1974/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.4246 - accuracy: 0.8518 - val_loss: 5.9355 - val_accuracy: 0.3861\n",
      "Epoch 1975/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3800 - accuracy: 0.8685 - val_loss: 5.9340 - val_accuracy: 0.4335\n",
      "Epoch 1976/2000\n",
      "10/10 [==============================] - 3s 288ms/step - loss: 0.4064 - accuracy: 0.8700 - val_loss: 5.6188 - val_accuracy: 0.4209\n",
      "Epoch 1977/2000\n",
      "10/10 [==============================] - 3s 287ms/step - loss: 0.4187 - accuracy: 0.8756 - val_loss: 5.9506 - val_accuracy: 0.4304\n",
      "Epoch 1978/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.4051 - accuracy: 0.8867 - val_loss: 5.8483 - val_accuracy: 0.4367\n",
      "Epoch 1979/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3928 - accuracy: 0.8891 - val_loss: 5.2410 - val_accuracy: 0.4557\n",
      "Epoch 1980/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3973 - accuracy: 0.8740 - val_loss: 5.0381 - val_accuracy: 0.4589\n",
      "Epoch 1981/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.4082 - accuracy: 0.8819 - val_loss: 5.6351 - val_accuracy: 0.4589\n",
      "Epoch 1982/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3947 - accuracy: 0.8756 - val_loss: 1.2657 - val_accuracy: 0.4430\n",
      "Epoch 1983/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3528 - accuracy: 0.8930 - val_loss: 0.9063 - val_accuracy: 0.4557\n",
      "Epoch 1984/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3328 - accuracy: 0.8899 - val_loss: 1.2355 - val_accuracy: 0.4589\n",
      "Epoch 1985/2000\n",
      "10/10 [==============================] - 3s 291ms/step - loss: 0.3678 - accuracy: 0.8708 - val_loss: 1.4812 - val_accuracy: 0.4335\n",
      "Epoch 1986/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3613 - accuracy: 0.8764 - val_loss: 1.9138 - val_accuracy: 0.4399\n",
      "Epoch 1987/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3471 - accuracy: 0.8835 - val_loss: 1.2271 - val_accuracy: 0.4557\n",
      "Epoch 1988/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3679 - accuracy: 0.8859 - val_loss: 1.2889 - val_accuracy: 0.3671\n",
      "Epoch 1989/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3776 - accuracy: 0.8708 - val_loss: 1.3503 - val_accuracy: 0.2468\n",
      "Epoch 1990/2000\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 0.3464 - accuracy: 0.8938 - val_loss: 1.4989 - val_accuracy: 0.2627\n",
      "Epoch 1991/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.3406 - accuracy: 0.8914 - val_loss: 1.5682 - val_accuracy: 0.3513\n",
      "Epoch 1992/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3307 - accuracy: 0.8891 - val_loss: 1.6828 - val_accuracy: 0.4715\n",
      "Epoch 1993/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.3120 - accuracy: 0.9105 - val_loss: 1.6478 - val_accuracy: 0.4747\n",
      "Epoch 1994/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.3207 - accuracy: 0.9176 - val_loss: 1.4824 - val_accuracy: 0.4715\n",
      "Epoch 1995/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.2913 - accuracy: 0.9152 - val_loss: 1.8460 - val_accuracy: 0.4778\n",
      "Epoch 1996/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.2750 - accuracy: 0.9223 - val_loss: 1.5995 - val_accuracy: 0.4810\n",
      "Epoch 1997/2000\n",
      "10/10 [==============================] - 3s 285ms/step - loss: 0.2509 - accuracy: 0.9279 - val_loss: 1.4349 - val_accuracy: 0.4684\n",
      "Epoch 1998/2000\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.2698 - accuracy: 0.9295 - val_loss: 1.0208 - val_accuracy: 0.4620\n",
      "Epoch 1999/2000\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.2792 - accuracy: 0.9358 - val_loss: 0.9704 - val_accuracy: 0.4715\n",
      "Epoch 2000/2000\n",
      "10/10 [==============================] - 3s 284ms/step - loss: 0.2423 - accuracy: 0.9406 - val_loss: 0.9817 - val_accuracy: 0.4557\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.applications.ResNet50(include_top=False, weights=None, input_shape=(32, 32, 3), pooling=\"max\")\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "epochs=2000\n",
    "history = model.fit(\n",
    "  x_train,\n",
    "  y_train,\n",
    "  epochs=epochs,\n",
    "  batch_size = 128,\n",
    "  validation_split = 0.2,\n",
    "  verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_history = pd.DataFrame(history.history)\n",
    "df_history.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_history[[\"accuracy\", \"val_accuracy\"]].plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test)\n",
    "test_results = []\n",
    "for idx, pred in enumerate(preds):\n",
    "    this_label = y_test[idx]\n",
    "    this_predict = np.argmax(pred)\n",
    "    acc = 0\n",
    "    if this_label == this_predict:\n",
    "        acc = 1\n",
    "    test_results.append({\"label\" : this_label, \"predict\" : this_predict, \"acc\" : acc})\n",
    "\n",
    "test_results = pd.DataFrame(test_results)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ratio = test_results[\"acc\"].sum() / len(test_results)\n",
    "print(\"테스트 정확도 : {}/{} ({:.2f})\".format(test_results[\"acc\"].sum(), len(test_results), acc_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최근 날짜로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler_pred = Crawler(crawl_page_max=1, perPage=100) #이전 추세도 볼겸 넉넉히 수집\n",
    "crawler_pred.crawlData(cols)\n",
    "df_crawled_pred = crawler_pred.removeNan()\n",
    "df_crawled_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#아래는 예측을 위한 전처리\n",
    "dpp_pred = DataPreprocessor(df_crawled_pred.loc[:100], cols, scale_method, model_save_path)\n",
    "dpp_pred.sortByDate()\n",
    "dpp_pred.makeDiffRatio()\n",
    "dpp_pred.scalingForPredict()\n",
    "dpp_pred.makeAR(0, len_x_ARMA)\n",
    "dpp_pred.makeMA(2, len_x_ARMA)\n",
    "dpp_pred.cutoffData(len_x_ARMA, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpp_pred.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred_list, label_pred_list, date_list, _ = makeImage2D(dpp_pred.df, cut_latest_data=False)\n",
    "len(img_pred_list), len(label_pred_list), len(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_day = 1\n",
    "img_pred = np.array([img_pred_list[-before_day]])\n",
    "pred = model.predict(img_pred)\n",
    "test_results = []\n",
    "predict = np.argmax(pred)\n",
    "print(\"{} predict : {}, real : {}\".format(date_list[-before_day], predict, label_pred_list[-before_day]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(img_list, y_list, test_size=0.2, shuffle=False, random_state=8699)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Input(shape=(24, 20, 1)),\n",
    "  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dense(20, activation=\"relu\")\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "epochs=5000\n",
    "history = model.fit(\n",
    "  x_train,\n",
    "  y_train,\n",
    "  epochs=epochs,\n",
    "  validation_split = 0.1,\n",
    "  verbose = 1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aaf533d5ae3a3d7a7fcdd7d995dbe2f3fcb3d854cc4805079aca601e58923c31"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv_tf_3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
